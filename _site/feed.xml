<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Masutangu</title>
    <description>也許我這一生　始終在追逐那顆九號球</description>
    <link>http://masutangu.com/</link>
    <atom:link href="http://masutangu.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 03 Dec 2017 15:24:22 +0800</pubDate>
    <lastBuildDate>Sun, 03 Dec 2017 15:24:22 +0800</lastBuildDate>
    <generator>Jekyll v3.1.1</generator>
    
      <item>
        <title>MIT 6.824 学习笔记（三）</title>
        <description>&lt;p&gt;本系列文章是对 &lt;a href=&quot;https://pdos.csail.mit.edu/6.824/schedule.html&quot;&gt;MIT 6.824&lt;/a&gt; 课程的学习笔记。&lt;/p&gt;

&lt;h1&gt;Spinnaker&lt;/h1&gt;

&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Spinnaker is an experimental datastore that is designed to run on a large cluster of commodity servers in a single datacenter. This paper describes Spinnaker’s Paxos-based replication protocol. The use of Paxos ensures that a data partition in Spinnaker will be available for reads and writes as long a majority of its replicas are alive.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;实现持续可用性的一个解决方案是&lt;strong&gt;主从复制&lt;/strong&gt;，但主从复制存在以下缺陷：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-3/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在上图的例子中，主从节点都从 LSN=10 开始（a），之后 slave 节点挂了（b），master 节点继续接收写请求，一直到 LSN=20。之后 master 节点也挂了（c），之后 slave 节点恢复（d），然而，在此时 slave 节点不能接收任何读写请求因为它缺失了 LSN=11 到LSN＝20 之间的记录。如果要避免这种情况，只有在任意节点挂掉的时候，都阻塞写请求。但这样就降低了整个系统的 availability。&lt;/p&gt;

&lt;p&gt;分布式系统中，&lt;strong&gt;一致性模型描述了如何使不同的 relicas 保持同步&lt;/strong&gt;。&lt;strong&gt;强一致性&lt;/strong&gt;保证了所有的 replicas 都是一致的，但要实现强一致性需要牺牲 availability 或网络分区容忍性。CAP 理论提出 &lt;strong&gt;Consistency&lt;/strong&gt;、&lt;strong&gt;Availability&lt;/strong&gt; 和 &lt;strong&gt;Partition tolerance&lt;/strong&gt; 三者最多只能同时满足两项。&lt;/p&gt;

&lt;p&gt;比如 Dynamo 这样的系统，使用&lt;strong&gt;最终一致性&lt;/strong&gt;模型来提供高可用性和分区容忍性。Dynamo 是一个 AP 系统，牺牲了 Consistency。&lt;/p&gt;

&lt;p&gt;Spinnaker 使用基于 Paxos 的协议来实现日志提交和故障恢复。Paxos 确保了系统在大多数节点存活的情况下可以运作。Spinnaker 是一个 CA 系统，用于单一的 datacenter，并使用另外的 replication strategy 来保证跨 datacenter 的容错性。 &lt;/p&gt;

&lt;h2&gt;Related work&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Two-phase commit (2PC)&lt;/strong&gt; 是保持 replicas 一致的一种方式。但 2PC 更偏向于将每个 participant 当作一个独立的资源管理者，而不仅仅是 replica。使用 2PC 来实现 replication 有些 overkill，并且还有不少缺陷。首先单一节点失败会导致系统 abort。其次每个 transaction 都发起 2PC 会导致极差的性能。每次 2PC 都需要两次磁盘强制写和传输两条信息的时延。最后，2PC 在 coordinator 挂掉时无法运作。&lt;/p&gt;

&lt;p&gt;Amazon 的 Dynamo 通过&lt;strong&gt;分布式时钟&lt;/strong&gt;来解决最终一致性的问题。&lt;/p&gt;

&lt;p&gt;Google 的 Bigtable 提供了强一致性，和 spinnaker 不同的是，Bigtable 依赖 GFS 来存储数据和日志，还有实现 replication。这样每个 transaction 的 workload 就加重了（需要和 gfs 的 master 交互）。&lt;/p&gt;

&lt;h2&gt;Architecture&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Like Bigtable and PNUTS, Spinnaker distributes the rows of a table across its cluster using range partitioning. Each node is assigned a base key range, which is replicated on the next N − 1 nodes (N = 3 by default).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-3/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Each group of nodes involved in replicating a key range is denoted as a &lt;strong&gt;cohort&lt;/strong&gt;. Note that cohorts overlap.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;每个日志由一个 LSN 唯一的标记。Commit queue 是在内存的数据结构，用于存放 pending writes。写操作只有在接收到大多数 cohort 的 ack 之后才能提交。在此之前都存放在 commit queue 中。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-3/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;已经提交的写操作存于 memtable 中，并被定期刷到被称为 SSTable 的 immutable disk structure。SSTable 会被定期合并以提升读性能并删除不需要的数据。&lt;/p&gt;

&lt;h2&gt;The replication protocol&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-3/illustration-4.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;提交一个写操作需要三次日志强制写和四条信息交互，不过大多数操作都是重叠的（可以并行）。&lt;/p&gt;

&lt;h2&gt;Recovery&lt;/h2&gt;

&lt;p&gt;Follower 的恢复需要两个阶段：&lt;strong&gt;local recovery&lt;/strong&gt; 和 &lt;strong&gt;catch up&lt;/strong&gt;。定义 f.cmt 表示 follower 的最后一个提交日志的 LSN，f.lst 表示 follower 的最后一个日志的 LSN。Local recovery 阶段，follower 从最近一次 checkpoint 开始重新执行日志直到 f.cmt，之后进入 catch up 阶段。Catch up 阶段，follower 通知 leader 自己的 f.cmt，leader 回复 f.cmt 之后所有的 commit writes。Leader 将会阻塞所有新的写请求直到 follower 已经跟上。&lt;/p&gt;

&lt;p&gt;当 leader 挂掉，新的 leader 将被选举，并且会确保新的 leader 会包含所有已提交的写操作。在老的 leader 挂掉时，有可能其提交的写操作在某些 followers 还处于 pending 的状态。新 leader 将使用下图的算法，继续提交所有 unresolved 写操作。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-3/illustration-5.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Leader election&lt;/h2&gt;

&lt;p&gt;选举算法如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-3/illustration-6.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 02 Dec 2017 15:19:31 +0800</pubDate>
        <link>http://masutangu.com/2017/12/mit-6824-note-3/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/12/mit-6824-note-3/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>MIT 6.824 学习笔记（二）</title>
        <description>&lt;p&gt;本系列文章是对 &lt;a href=&quot;https://pdos.csail.mit.edu/6.824/schedule.html&quot;&gt;MIT 6.824&lt;/a&gt; 课程的学习笔记。&lt;/p&gt;

&lt;h1&gt;Raft&lt;/h1&gt;

&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;Raft 是用于管理复制日志的一致性算法。为了方便理解，Raft 将一致性算法分解为几个关键模块：&lt;strong&gt;Leader 选举&lt;/strong&gt;、&lt;strong&gt;日志复制&lt;/strong&gt;和&lt;strong&gt;安全性&lt;/strong&gt;，同时&lt;strong&gt;通过更强的一致性来减少需要考虑的状态&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;一致性算法允许一组机器像一个整体一样工作，即使其中一些机器挂掉。一致性算法在构建大规模可信赖系统中扮演重要的角色。&lt;/p&gt;

&lt;p&gt;Raft 和许多一致性算法类似，但他也有自己的新特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Strong leader&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Raft 使用比其他一致性算法更强的 leadership 形式。举例来说，log entries 只能从 leader 发往其他 server。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Leader election&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Raft 使用随机 timer 来选举 leader，简洁地解决了冲突的问题。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Membership changes&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Raft 使用 joint consensus 的方式来处理成员变化的问题。在变迁的过程中，两个不同的配置可以共存，以此来实现在变迁过程中集群仍然能持续运转。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Replicated state machines 通常用 replicated log 实现。一致性算法起的作用是保证多个 replicas 上的 replicated log 一致。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;实际系统中使用的一致性算法通常有下列特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;安全性保证&lt;/strong&gt;（绝对不会返回一个错误的结果）&lt;/p&gt;

&lt;p&gt;在非拜占庭错误情况下，网络延迟、分区、丢包、冗余和乱序等错误都可以保证不返回错误的结果。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;可用性&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;集群中只要大多数的机器可运行并且能够相互通信、和客户端通信，服务就可用。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;不依赖时序来保证一致性&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;通常情况下，小部分 slow servers 不会影响系统整体的性能&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Raft basics&lt;/h2&gt;

&lt;blockquote&gt;
&lt;p&gt;Raft implements consensus by first electing a distinguished leader, then giving the leader complete responsibility for managing the replicated log. The leader accepts log entries from clients, replicates them on other servers, and tells servers when it is safe to apply log entries to their state machines&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Raft 在任何时候都保证以下的特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Election Safety&lt;/strong&gt;: at most one leader can be elected in a given term.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Leader Append-Only&lt;/strong&gt;: a leader never overwrites or deletes entries in its log; it only appends new entries. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Log Matching&lt;/strong&gt;: if two logs contain an entry with the same index and term, then the logs are identical in all entries up through the given index. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Leader Completeness&lt;/strong&gt;: if a log entry is committed in a given term, then that entry will be present in the logs of the leaders for all higher-numbered terms. &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;State Machine Safety&lt;/strong&gt;: if a server has applied a log entry at a given index to its state machine, no other server will ever apply a different log entry for the same index.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Raft 中每个 server 在任意时刻都处于 &lt;strong&gt;leader&lt;/strong&gt;、&lt;strong&gt;follower&lt;/strong&gt;、&lt;strong&gt;candidate&lt;/strong&gt; 这三种状态之一。Followers 被动的接收 leader 或 candidate 的请求，leader 处理所有客户端请求，candidate 则起了选举 leader 的角色。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-2/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Raft 把时间划分为&lt;strong&gt;任期（Terms）&lt;/strong&gt;，并保证每个任期内只有一个 leader。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-2/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Terms act as a logical clock in Raft&lt;/strong&gt;, and they allow servers to detect obsolete information such as stale leaders. &lt;strong&gt;Each server stores a current term number, which increases monotonically over time. Current terms are exchanged whenever servers communicate&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Raft 服务器之间使用 RPC 进行通信，&lt;strong&gt;RequestVote RPC 用于选举，AppendEntries 用于 leader 向 followers 复制日志和心跳。&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;Log replication&lt;/h2&gt;

&lt;p&gt;Raft 的日志机制维护下面两个特性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;If two entries in different logs have the same index and term, then they store the same command.&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;If two entries in different logs have the same index and term, then the logs are identical in all preceding entries.&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Safty&lt;/h2&gt;

&lt;p&gt;在任何 leader-based 的一致性算法中，leader 都必须存储所有已经提交的日志条目。Raft 使用了一种简单的办法，保证之前任期中已经提交的日志都会出现在新的 leader 中，不需要将这些日志传给新的 leader。这意味着&lt;strong&gt;日志的传送是单向的从 leader 发往 followers，并且 leader 从不覆盖本地已经存在的日志。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Raft 在投票过程中只允许&lt;strong&gt;包含全部已提交日志的 server 当选 leader&lt;/strong&gt;。Raft 通过比较日志中最后一条日志条目的索引值和任期来判断哪份日志更新。&lt;strong&gt;任期大的日志更加新，如果任期相同，那么日志索引值更大的新。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Leader 不能断定之前任期里的日志条目被保存到大多数服务器上的时候就一定已经提交了。&lt;/strong&gt;（请看论文的 figure 8）Raft 永远不会通过计算副本数目的方式提交一个之前任期内的日志条目。&lt;strong&gt;只有当前任期里的日志条目是通过计算副本数目的方式被提交。&lt;/strong&gt;一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配特性，之前的日志条目也都会被间接的提交。&lt;/p&gt;

&lt;h2&gt;Timing and availability&lt;/h2&gt;

&lt;p&gt;Raft 要求系统满足以下时间限制：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;broadcastTime ≪ electionTimeout ≪ MTBF
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;BroadcastTime 指的是并行发送 RPCs 给集群中的其他服务器并接收到响应的平均时间。MTBF 是单台服务器两次故障之间的平均时间。&lt;/p&gt;

&lt;p&gt;Raft 的 RPCs 通常耗时在 0.5ms 到 20ms 之间。因此 electionTimeout 最好处于 10ms 到 500ms 之间。&lt;/p&gt;

&lt;h2&gt;Cluster membership changes&lt;/h2&gt;

&lt;p&gt;为了保证配置修改机制的安全，在转换的过程中同一个任期中任何一个时间点都不能出现超过一个 leader。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-2/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Raft 使用 two-phase 的方式来保证安全性。集群首先切换到过渡的配置，我们称其为 &lt;strong&gt;joint consensus&lt;/strong&gt;。一旦 joint consensus 被提交，集群再切换到新的配置。&lt;strong&gt;Joint consensus&lt;/strong&gt; 是新老配置的结合：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;日志条目被复制给集群中新、老配置的所有服务器&lt;/li&gt;
&lt;li&gt;新、旧配置的服务器都可以成为领导人&lt;/li&gt;
&lt;li&gt;Agreement (for elections and entry commitment) 需要分别在两种配置上获得大多数的支持&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;集群配置以特殊的日志条目保存在 replicated log 中来存储和通信，下图展示了配置转换的过程。一旦一个服务器将新的配置日志条目添加到本地日志中，它就会用这个配置来做决定（服务器总是使用最新的配置，无论该配置是否已经被提交）。这意味着 leader 要使用 C-old,new 的规则来决定日志条目 C-old,new 什么时候需要被提交。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-2/illustration-4.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一旦 C-old,new 被提交，那么无论是 C-old 还是 C-new 都不能单独做出决定，并且 Leader Completeness 的特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为 leader。这时 leader 创建一条 C-new 配置的日志条目并复制给集群就是安全的了，每个服务器在见到新的配置的时候就会立即生效。当新的配置在 C-new 的规则下被提交，不在新的配置内的服务器就可以关闭了。&lt;/p&gt;

&lt;h2&gt;Client interaction&lt;/h2&gt;

&lt;p&gt;Raft 的目标是要实现 linearizable semantics(each operation appears to execute instantaneously, exactly once, at some point between its invocation and its response) 但 Raft 是可能执行同一条命令多次的。解决方法是&lt;strong&gt;客户端对于每一条指令都赋予一个唯一的序列号，状态机记录每条指令最新的序列号和相应的响应。&lt;/strong&gt;如果接收到一条指令其序列号已经被执行了，那么就立即返回响应，无需重复执行指令。&lt;/p&gt;

&lt;p&gt;只读的操作可以直接处理而不需要写入日志，但可能返回脏数据。Raft 采用额外的机制在不写入日志的情况下保证读操作的正确性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Leader 必须知道最新的被提交日志。Raft 中通过 leader 在任期开始的时候提交一个空白的日志条目到日志中去来实现。&lt;/li&gt;
&lt;li&gt;Leader 在处理只读的请求之前需要检查自己是否已经被废黜了。Raft 中通过让 leader 在响应只读请求之前，先和集群中的大多数节点交换一次心跳信息来处理这个问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Raft makes a few design choices that sacrifice performance for simplicity:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Raft follower rejects out-of-order AppendEntries RPCs&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Rather than saving for use after hole is filled. Might be important if network re-orders packets a lot
And makes leader-&amp;gt;follower RPC pipelining harder&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Snapshotting is wasteful for big slowly-changing states&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;A slow leader may hurt Raft, e.g. in geo-replication&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Experience suggests these have a big effect on performance:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Disk writes for persistence&lt;/li&gt;
&lt;li&gt;Message/packet/RPC overhead&lt;/li&gt;
&lt;li&gt;Need to execute logged commands sequentially&lt;/li&gt;
&lt;li&gt;Fast path for read-only operations&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Appendix&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://thesecretlivesofdata.com/raft/&quot;&gt;http://thesecretlivesofdata.com/raft/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://thesquareplanet.com/blog/students-guide-to-raft/&quot;&gt;https://thesquareplanet.com/blog/students-guide-to-raft/&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 02 Dec 2017 15:19:31 +0800</pubDate>
        <link>http://masutangu.com/2017/12/mit-6824-note-2/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/12/mit-6824-note-2/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>MIT 6.824 学习笔记（一）</title>
        <description>&lt;p&gt;本系列文章是对 &lt;a href=&quot;https://pdos.csail.mit.edu/6.824/schedule.html&quot;&gt;MIT 6.824&lt;/a&gt; 课程的学习笔记。&lt;/p&gt;

&lt;h1&gt;Introduction&lt;/h1&gt;

&lt;p&gt;本课程涵盖以下主题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RPC、线程、并发控制&lt;/li&gt;
&lt;li&gt;性能 &lt;/li&gt;
&lt;li&gt;容灾：&lt;strong&gt;Availability&lt;/strong&gt;, &lt;strong&gt;Durability&lt;/strong&gt;. replicated servers 是不错的选择。&lt;/li&gt;
&lt;li&gt;一致性：replica如何保持一致？ &lt;strong&gt;Consistency&lt;/strong&gt; 和 &lt;strong&gt;Performance&lt;/strong&gt; 不可兼得&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;MapReduce&lt;/h1&gt;

&lt;p&gt;Map funciton 接收 input pair 处理生成一系列的 intermediate key/value pairs。MapReduce 库将相同 intermediate key 的 intermediate values 打包起来传给 Reduce function。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-1/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reduce function 接收 intermediate key 和与其关联的一系列 intermediate values。Reduce function 将这些 intermediate values 合并成更小的 values set。The intermediate values are supplied to the user’s reduce function via an iterator。&lt;/p&gt;

&lt;p&gt;Map Reduce function 的输入输出参数通常如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;map (k1,v1) → list(k2,v2)&lt;/li&gt;
&lt;li&gt;reduce (k2,list(v2)) → list(v2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;容错：worker 挂掉，重跑任务。master挂掉？直接暂停，由用户决定是否重跑。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;MR re-runs just the failed Map()s and Reduce()s. MR requires them to be pure functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;they don&amp;#39;t keep state across calls,&lt;/li&gt;
&lt;li&gt;they don&amp;#39;t read or write files other than expected MR inputs/outputs,&lt;/li&gt;
&lt;li&gt;there&amp;#39;s no hidden communication among tasks.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So re-execution yields the same output.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;重跑如何保持一致：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Rely on atomic commits of map and reduce task outputs 细节？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不确定性？&lt;/p&gt;

&lt;p&gt;实现一个精简map reduce&lt;/p&gt;

&lt;h1&gt;RPC&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Better RPC behavior: &amp;quot;at most once&amp;quot;&lt;/p&gt;

&lt;p&gt;idea: server RPC code detects duplicate requests, returns previous reply instead of re-running handler&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;如何检测重复的请求？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Client 在每个请求都带上唯一的 Request ID，重试时使用相同的 Request ID：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;server:
    if seen[xid]:
      r = old[xid]
    else
      r = handler()
      old[xid] = r
      seen[xid] = true
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Request ID 如何保证唯一？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;请求 id 包含客户端 ip，以区分不同客户端&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Server 端何时可以删掉保存的请求 id？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;unique client IDs, per-client RPC sequence numbers, client includes &amp;quot;seen all replies &amp;lt;= X&amp;quot; with every RPC, much like TCP sequence #s and acks （客户端带上 ack_req_id，服务端可以把 &amp;lt;= ack_req_id 的请求 id 都删掉）&lt;/li&gt;
&lt;li&gt;only allow client one outstanding RPC at a time arrival of seq + 1 allows server to discard all &amp;lt;= seq&lt;/li&gt;
&lt;li&gt;client agrees to keep retrying for &amp;lt; 5 minutes, server discards after 5+ minutes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Server 应该把 Dupliate Request 信息写入磁盘，也应该同步到 replica。万一 server crash 或者重启，才不会丢失。&lt;/p&gt;

&lt;h1&gt;GFS&lt;/h1&gt;

&lt;p&gt;GFS 重新审视了传统文件系统的设计，并总结了以下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;组件挂掉是常态事件，因此文件系统必须集成监控、错误侦测、容灾以及自动恢复的机制&lt;/li&gt;
&lt;li&gt;几 GB 的大文件很普遍。&lt;/li&gt;
&lt;li&gt;随机写的场景非常少。一旦写入完成，文件通常只会被顺序读取&lt;/li&gt;
&lt;li&gt;co-designing the applications and the file system API benefits the overall system by increasing our flexibility（不理解，是说简化 API 的设计么？）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GFS 集群由单一 master 和多个 chunkserver 构成，可同时被多个 client 访问。文件被划为固定大小的 chunks。每个 chunk 在创建时由 master 分配一个不可修改且全局唯一的 chunk handle 标记。chunkservers 以 linux 文件形式保存 chunks，读写 chunks 时client 指定 chunk handle 和 byte range。每个 chunk 被复制多份以实现 reliability。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-1/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Master 维护整个文件系统的 metadata，包括命名空间，访问控制，文件到 chunks 的映射和 chunks 所在的位置。Master 还管理系统范围内的活动，例如 chunk 租用管理， orphaned chunk 的回收，以及 chunks 在 chunkservers 之间的迁移。Master 使用心跳信息周期地和每个 chunkserver 通讯，发送指令并收集 chunkserver 的状态信息。&lt;/p&gt;

&lt;p&gt;Client 和 master 的通信只涉及元数据，所有的数据操作都直接和 chunkservers 通信。&lt;/p&gt;

&lt;p&gt;Master 主要保存下面三种元数据：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文件和 chunk 的命名空间&lt;/li&gt;
&lt;li&gt;文件到 chunk 的映射关系&lt;/li&gt;
&lt;li&gt;chunk 复本的位置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前两种通过 logging mutations 持久化。chunk 复本的位置则是启动时 master 向每个 chunkserver 询问的。&lt;/p&gt;

&lt;p&gt;容灾：通过 &lt;strong&gt;snapshot&lt;/strong&gt; 和 &lt;strong&gt;logging mutations&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;一致性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A file region is &lt;strong&gt;consistent&lt;/strong&gt; if all clients will always see the same data, regardless of which replicas they read from. &lt;/li&gt;
&lt;li&gt;A region is &lt;strong&gt;defined&lt;/strong&gt; after a file data mutation if it is consistent and clients will see what the mutation writes in
its entirety.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GFS 通过以下措施确保被修改的文件 region 是已定义的，并且包含最后一次修改操作写入的数据：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;chunk 的所有副本的修改操作顺序保持一致&lt;/li&gt;
&lt;li&gt;使用 chunk 的版本号来检测副本是否有效&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了应对记录追加的 at-least-once 特性，readers 可以使用下面的方法来处理 padding 和重复的 record。Writers （应用层 writer）在每条写入的记录中都包含了额外的信息例如 Checksum，用来验证它的有效性。Reader 使用 Checksum 识别和丢弃额外的 padding 和记录片段。应用程序还可以用记录的唯一标识符来过滤重复 record。 &lt;/p&gt;

&lt;p&gt;GFS 使用租约（lease）来保证多个副本间变更顺序的一致性。Master 节点给其中一个 replica 分配 chunk 租约，该 replica 变成 primary。Mutations 的顺序由 primary 决定。&lt;/p&gt;

&lt;p&gt;Master 维护了每个 chunk 的版本号，用以分辨出过时的 replicas。 每次 master 下发新的 lease 都会提升 chunk 的版本号。当 chunkserver 上报自身 chunk 集合和相关的版本号时，master 就可以检测出失效的 replica。 &lt;/p&gt;

&lt;h1&gt;Fault-Tolerant Virtual Machines&lt;/h1&gt;

&lt;p&gt;实现容错系统最常见的一种方法是主备方法，备机必须与主机保持接近一致。实现主备一致的一个普遍的做法是将主机状态的变化都同步给备机，包括 CPU、内存、I/O，但这种方式需要大量的带宽。另一种方式是将服务器建模成 deterministic state machine，如果输入相同，那最终的状态也会相同。通过同步输入序列的方式，对带宽的要求远低于同步状态的方式。&lt;/p&gt;

&lt;p&gt;Primary VM 的输入将通过 logging channel 同步给 backup VM。backup 的输出会被 hypervisor 丢弃，只有 primary VM 的输出会返回给客户端。&lt;/p&gt;

&lt;p&gt;Log all hardware events into a log: clock interrupts, network interrupts, i/o interrupts, etc.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;For non-deterministic instructions, record additional info&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;e.g., log the value of the time stamp register&lt;/p&gt;

&lt;p&gt;on replay: return the value from the log instead of the actual register&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Replay: delivery inputs in the same order at the same instructions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;if during recording delivered clock interrupt at nth instruction executed
during replay also delivers the clock interrupt at the nth instruction&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Output Requirement&lt;/strong&gt;: if the backup VM ever takes over after a failure of the primary, the backup VM will continu executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;要满足 Output Requirement，所有的输出都必须延迟直到 backup VM 收到和该输出相关联的信息以便其可以回放。确保 Output Requirement 的一个简单的做法是给每个 output 操作创建一个特殊的log entry，当 backup VM 接收并 ack 该 log entry 时 primary VM 才会输出结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-1/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FT 使用 UDP 发送心跳包来检测 server 是否存活。另外 FT 还会通过监控从 primary 发往 backup 的流量的方式来检测。&lt;/p&gt;

&lt;p&gt;为了避免 split-brain 的问题，在切换主的时候，需要在 shared storage 上执行原子的 test-and-set 操作，执行成功的才能升为 primary。&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Nov 2017 15:40:29 +0800</pubDate>
        <link>http://masutangu.com/2017/11/mit-6824-note-1/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/11/mit-6824-note-1/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>游戏开发之状态机</title>
        <description>&lt;p&gt;这阵子工作的内容有用到状态机，感觉挺有意思。正好好久没写博客了，今天也来写一篇总结下。&lt;/p&gt;

&lt;h1&gt;前言&lt;/h1&gt;

&lt;p&gt;用状态机来实现业务模型，有以下几点好处：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不需要写一大坨 if-else 或 switch case。代码逻辑结构清晰，也更便于调试&lt;/li&gt;
&lt;li&gt;代码阅读起来更加友好，方便其他读者理解整个业务逻辑&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;状态机可以划分为下面三个模块：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;状态集&lt;/strong&gt;：总共包括哪些状态&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;事件（条件）&lt;/strong&gt;：事件会触发状态机的状态发生变化&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动作&lt;/strong&gt;：事件发生后执行的动作，可以变迁到新状态，也可以维持当前状态&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;实现&lt;/h1&gt;

&lt;h2&gt;一个简单的状态机的实现&lt;/h2&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 1. simple state machine
// 事件 interface
type Event interface {
  EventId() int64
}

type State int

// 事件处理函数 返回触发事件后的下一个状态 
type Handler func(prevState State, event Event) State

type StateMachine struct {
  currState    State
  handlers map[int64]Handler
}

// 添加事件处理方法 
func (s *StateMachine) AddHandler(eventId int64, handler Handler) {
  s.handlers[eventId] = handler
}

// 事件处理
func (s *StateMachine) Call(event Event)  {
  fmt.Println(&amp;quot;original state: &amp;quot;, s.currState)
  if handler, ok := s.handlers[event.EventId()]; ok {
    s.currState = handler(s.currState, event)  // 调用对应的 handler 更新状态机的状态
  }
  fmt.Println(&amp;quot;new state: &amp;quot;, s.currState)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;Handler&lt;/code&gt; 为事件处理函数，输入参数为当前状态和事件，返回处理后的新状态。状态机根据事件找到对应的&lt;code&gt;Handler&lt;/code&gt;，&lt;code&gt;Handler&lt;/code&gt; 根据当前状态和触发的事件，返回下一个新状态，由状态机更新。&lt;/p&gt;

&lt;p&gt;下面看看一个开关的例子，初始状态为关，按下按钮状态由关变为开，再次按下由开变为关。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 1. simple state machine
const (
  EVENT_PRESS = iota
)

var (
  Off = State(0)  // 定义关闭状态
  On  = State(1)  // 定义开启状态 
)

// 定义 press 事件
type PressEvent struct {
}

func (event *PressEvent) EventId() int64 {
  return EVENT_PRESS
}

// 定义事件 Handler
func PressButton(prevState State, event Event) State {
  if prevState == Off {
    return On
  } else {
    return Off
  }
}

func main() {
  stateMachine := StateMachine{
    currState:    Off,  // 初始状态为关闭
    handlers: make(map[int64]Handler),
  }

  stateMachine.AddHandler(EVENT_PRESS, PressButton)
  stateMachine.Call(&amp;amp;PressEvent{}) // 按下后变成开
  stateMachine.Call(&amp;amp;PressEvent{}) // 再次按下变为关闭
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;程序输出：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;original state:  0
new state:  1
original state:  1
new state:  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这个实现很简单，但不足之处在于状态变迁逻辑都放在&lt;code&gt;Handler&lt;/code&gt;去实现了。对于读代码的人来说，需要读每个Handler的代码，才能整理出整个状态变迁图。&lt;/p&gt;

&lt;h2&gt;一个稍微复杂点的状态机&lt;/h2&gt;

&lt;p&gt;我们希望可以把状态变迁以更直观的方式表现出来，让读者一看就知道状态是如何流转的。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 2. a little more complicate state machine

type Event interface {
  EventId() int64
}

type State int

// 事件处理函数 返回 true 表示可以变迁到下一个状态 返回 false 表示维持当前状态
type Handler func(prevState State, event Event) bool

type StateMachine struct {
  currState    State
  handlers map[int64]Handler
  transitions map[State]map[int64]State
}

// 添加事件处理方法 
func (s *StateMachine) AddHandler(eventId int64, handler Handler) {
  s.handlers[eventId] = handler
}

// 添加状态变迁
func (s *StateMachine) AddTransition(originState State, eventId int64, destState State) {
  if trans, ok := s.transitions[originState]; !ok {
    s.transitions[originState] = map[int64]State{eventId: destState}
  } else {
    trans[eventId] = destState
  }
}

// 事件处理
func (s *StateMachine) Call(event Event) {
  fmt.Println(&amp;quot;original state: &amp;quot;, s.currState)  
  if handler, ok := s.handlers[event.EventId()]; ok { // 首先找到事件的handler
    if handler(s.currState, event) { // 如果事件Handler返回true 则执行状态变迁
      if trans, ok := s.transitions[s.currState]; ok {
        if newState, ok := trans[event.EventId()]; ok { 
          s.currState = newState  // 执行状态变迁
        }
      }
    }
  }
  fmt.Println(&amp;quot;new state: &amp;quot;, s.currState) 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这个状态机用&lt;code&gt;transitions&lt;/code&gt; 结构来记录状态流转的关系。初始化时调用方调用&lt;code&gt;AddTransition&lt;/code&gt;方法来添加状态变迁。请看下面的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 2. a little more complicate state machine

const (
  EVENT_PRESS = iota
)

var (
  Off = State(0)  // 关闭
  On  = State(1)  // 开启 
  COUNT = 0
)


type PressEvent struct {
}

func (event *PressEvent) EventId() int64 {
  return EVENT_PRESS
}

// 定义事件 Handler
func PressButton(prevState State, event Event) bool {
  COUNT += 1
  if COUNT % 2 == 0 { // 按两下才切换到新状态
    return true
  }
  return false // 只按一次维持当前状态
}

func main() {
  stateMachine := StateMachine{
    currState:    Off,  // 初始状态为关闭
    handlers: make(map[int64]Handler),
    transitions: make(map[State]map[int64]State),
  }

  stateMachine.AddHandler(EVENT_PRESS, PressButton)
  stateMachine.AddTransition(Off, EVENT_PRESS, On)
  stateMachine.AddTransition(On, EVENT_PRESS, Off)
  stateMachine.Call(&amp;amp;PressEvent{}) // 按一次状态不变
  stateMachine.Call(&amp;amp;PressEvent{}) // 按两次变成 off 状态
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;通过&lt;code&gt;stateMachine.AddTransition(Off, EVENT_PRESS, On)&lt;/code&gt;就可以清晰的知道 Press 事件可能会让状态 Off 切换到 状态 On，尽管 Press 事件发生后还是有可能维持当前状态不变（当 Handler 返回 false 时）。&lt;/p&gt;

&lt;p&gt;程序输出：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;original state:  0
new state:  0
original state:  0
new state:  1
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;更模块化的状态机&lt;/h2&gt;

&lt;p&gt;最后我们来实现一个更模块化的状态机，把事件和条件这两个逻辑彻底分开。当你在事件触发时，还需要做逻辑判断才能确定是否发生状态变迁时，建议将事件处理和条件判断剥离开来。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 3. more modular state machine

type Event interface {
  EventId() int64
}

type State int

// 事件处理 Handler
type Handler interface {
  Process(prevState State, event Event)  // 只处理事件
  Check() bool                           // 处理完判断下是否应该做状态切换
}

type StateMachine struct {
  currState    State
  handlers          map[int64]Handler
  transitions   map[State]map[int64]State
}

// 添加事件处理方法 
func (s *StateMachine) AddHandler(eventId int64, handler Handler) {
  s.handlers[eventId] = handler
}

// 添加状态变迁
func (s *StateMachine) AddTransition(originState State, eventId int64, destState State) {
  if trans, ok := s.transitions[originState]; !ok {
    s.transitions[originState] = map[int64]State{eventId: destState}
  } else {
    trans[eventId] = destState
  }
}

// 事件处理
func (s *StateMachine) Call(event Event) {
  fmt.Println(&amp;quot;original state: &amp;quot;, s.currState)  
  if handler, ok := s.handlers[event.EventId()]; ok { // 首先找到事件的handler
    handler.Process(s.currState, event) 
    if handler.Check() {
      if trans, ok := s.transitions[s.currState]; ok {
        if newState, ok := trans[event.EventId()]; ok { 
          s.currState = newState  // 执行状态变迁
        }
      }
    }
  }
  fmt.Println(&amp;quot;new state: &amp;quot;, s.currState) 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;定义&lt;code&gt;Handler&lt;/code&gt;结构体，有两个接口：&lt;code&gt;Process&lt;/code&gt;只负责事件引发的逻辑处理， &lt;code&gt;Check&lt;/code&gt;判断逻辑处理后是否应该做状态变迁。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// example 3. more modular state machine

const (
  EVENT_PRESS = iota
)

var (
  Off = State(0)  // 关闭
  On  = State(1)  // 开启 
  COUNT = 0
)

type PressEvent struct {
}

func (event *PressEvent) EventId() int64 {
  return EVENT_PRESS
}

type PressEventHandler struct {}

// Process 只处理事件带来的内部变量的变化
func (h *PressEventHandler) Process(prevState State, event Event) {
  COUNT += 1
}


// Check 判断是否应该做状态切换
func (h *PressEventHandler) Check() bool {
  if COUNT % 2 == 0 { // 按两下才有作用
    return true
  }
  return false
}

func main() {
  stateMachine := StateMachine{
    currState:    Off,  // 初始状态为关闭
    handlers: make(map[int64]Handler),
    transitions: make(map[State]map[int64]State),
  }

  stateMachine.AddHandler(EVENT_PRESS, &amp;amp;PressEventHandler{})
  stateMachine.AddTransition(Off, EVENT_PRESS, On)
  stateMachine.AddTransition(On, EVENT_PRESS, Off)
  stateMachine.Call(&amp;amp;PressEvent{}) // 按一次状态不变
  stateMachine.Call(&amp;amp;PressEvent{}) // 按两次变成 off 状态
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;程序输出：
&lt;code&gt;
original state:  0
new state:  0
original state:  0
new state:  1
&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;一些补充&lt;/h2&gt;

&lt;p&gt;可以把 &lt;code&gt;State&lt;/code&gt; 定义成 interface，提供 &lt;code&gt;Enter&lt;/code&gt; 和 &lt;code&gt;Leave&lt;/code&gt; 接口：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;type State interface {
  Enter() 
  Leave()
}

// 事件处理
func (s *StateMachine) Call(event Event) {
  fmt.Println(&amp;quot;original state: &amp;quot;, s.currState)  
  if handler, ok := s.handlers[event.EventId()]; ok { // 首先找到事件的handler
    handler.Process(s.currState, event) 

    if handler.Check() {
      if trans, ok := s.transitions[s.currState]; ok {
        if newState, ok := trans[event.EventId()]; ok { 
          s.currState.Leave()     // 离开当前状态 调用 Leave 
          s.currState = newState  // 执行状态变迁
          s.currState.Enter()     // 进入新状态 调用 Enter
        }
      }
    } 
  }
  fmt.Println(&amp;quot;new state: &amp;quot;, s.currState) 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;与 goroutine 的结合&lt;/h2&gt;

&lt;p&gt;涉及到多个 goroutine 时，总会面临数据竞争的问题。通过 channel 来传递事件，由状态机处理，可以让代码变得清晰，避免加锁。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;
type Room struct {
  eventCh chan Event // 通过channel 传递事件给状态机
  st *StateMachine
}

func (room *Room) Process() {
  for e := range room.eventCh {
    room.st.Call(e)
  }
}

func (room *Room) DispatchEvent(event Event) {
  room.eventCh &amp;lt;- event
}

func main() {
  stateMachine := StateMachine{
    currState:    Off,  // 初始状态为关闭
    handlers: make(map[int64]Handler),
    transitions: make(map[State]map[int64]State),
  }

  stateMachine.AddHandler(EVENT_PRESS, &amp;amp;PressEventHandler{})
  stateMachine.AddTransition(Off, EVENT_PRESS, On)
  stateMachine.AddTransition(On, EVENT_PRESS, Off)

  room := Room{st: &amp;amp;stateMachine, eventCh: make(chan Event)}

  go room.DispatchEvent(&amp;amp;PressEvent{})
  go room.DispatchEvent(&amp;amp;PressEvent{})
  go room.DispatchEvent(&amp;amp;PressEvent{})

  room.Process()  // just sample code
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;即使是多个 goroutine 并发抛出事件，状态机只从&lt;code&gt;eventCh&lt;/code&gt;中串行的取出事件并处理，处理过程中不需要对数据加锁。 &lt;/p&gt;
</description>
        <pubDate>Wed, 01 Nov 2017 08:33:41 +0800</pubDate>
        <link>http://masutangu.com/2017/11/state-machine/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/11/state-machine/</guid>
        
        
        <category>工作</category>
        
      </item>
    
      <item>
        <title>LevelDB 源码阅读（一）</title>
        <description>&lt;p&gt;这篇文章主要记录 LevelDB 的重要模块、类以及方法。把读写操作和 Compaction 操作的代码串了一遍，并添加了小部分注释。&lt;/p&gt;

&lt;h1&gt;模块&lt;/h1&gt;

&lt;h3&gt;Log 文件&lt;/h3&gt;

&lt;p&gt;客户端的写请求会先 append 到 Log 文件，成功后再写入到 Memtable。如果宕机可以通过 Log 文件来恢复 Memtable。&lt;/p&gt;

&lt;h3&gt;Memtable 和 Immutable Memtable&lt;/h3&gt;

&lt;p&gt;内存数据结构，基于跳表。客户端的读写请求都会由 Memtable 处理。 当 Memtable 占用的内存达到一定阈值，重新生成新的 Memtable 处理客户端请求。原来的 Memtable 转成 Immutable Memtable，等待归并到 SST 文件中。&lt;/p&gt;

&lt;h3&gt;SST 文件&lt;/h3&gt;

&lt;p&gt;落地到磁盘的存储文件。SST 分为不同的 level，具体参考&lt;a href=&quot;https://github.com/google/leveldb/blob/master/doc/impl.md&quot;&gt;文档&lt;/a&gt;。&lt;/p&gt;

&lt;h3&gt;Manifest 文件&lt;/h3&gt;

&lt;p&gt;Manifest 记录不同 level 的 SST 文件，包括每个 SST 文件的 key range、大小等 metadata。&lt;/p&gt;

&lt;h3&gt;Current 文件&lt;/h3&gt;

&lt;p&gt;Current 记录了最新的 Manifest 文件。&lt;/p&gt;

&lt;h1&gt;类成员变量&lt;/h1&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;class DBImpl : public DB {
  private:
    TableCache* table_cache_;
    MemTable* mem_;
    MemTable* imm_;
    WritableFile* logfile_;
    log::Writer* log_;
    std::deque&amp;lt;Writer*&amp;gt; writers_;
    VersionSet* versions_;

    // Set of table files to protect from deletion because they are
    // part of ongoing compactions.
    std::set&amp;lt;uint64_t&amp;gt; pending_outputs_;
};

class MemTable {
  private:
    typedef SkipList&amp;lt;const char*, KeyComparator&amp;gt; Table;
    Arena arena_;  // 内存池
    Table table_;  // 跳表
};

struct FileMetaData {
  int refs;
  int allowed_seek;   // seeks allowed until compaction
  uint64_t number;    // ?? 
  uint64_t file_size;
  InternalKey smallest;
  InternalKey largest;
};

class VersionEdit {
  private:
    typedef std::set&amp;lt; std::pair&amp;lt;int, uint64_t&amp;gt; &amp;gt; DeletedFileSet;

    std::vector&amp;lt; std::pair&amp;lt;int, InternalKey&amp;gt; &amp;gt; compact_pointers_;
    DeletedFileSet deleted_files_;
    std::vector&amp;lt; std::pair&amp;lt;int, FileMetaData&amp;gt; &amp;gt; new_files_;
};

class Version {
  public:
    Status Get(const ReadOptions&amp;amp;, const LookupKey&amp;amp; key, std::string* val, 
               GetStats* stats);
  private:
    VersionSet* vset_;
    Version* next_;
    Version* prev_;

    // list of files per level
    std::vector&amp;lt;FileMetaData*&amp;gt; files_[config::kNumLevels];
};

class TableCache {
  public:
    Status Get(const ReadOptions&amp;amp; options, uint64_t file_number, 
               uint64_t file_size, const Slice&amp;amp; k, void *arg, 
               void (*handle_result)(void*, const Slice&amp;amp;, const Slice&amp;amp;));

  private:
    Cache* cache_;
};

class VersionSet {
  private:
    TableCache* const table_cache_;
    WritableFile* descriptor_file_;
    log::Writer* descriptor_log_;
    Version dummy_versions_;  // Head of circurlar doubly-linked list of versions  
    Version* current_;        // == dummy_versions_.prev_
};

class WriteBatch {
  public:
    class Handler {
    public:
        virtual ~Handler();
        virtual void Put(const Slice&amp;amp; key, const Slice&amp;amp; value) = 0;
        virtual void Delete(const Slice&amp;amp; key) = 0;
    };
  private:
    friend class WriteBatchInternal;
    std::string req_;
}

struct DBImpl::Writer {
  Status status;
  WriteBatch* batch;
  bool sync;
  bool done;
  port::CondVar cv;

  expplicit Writer(port::Mutex* mu) : cv(mu) { }
};

class Compaction {
  private:
    Version* input_version_;
    VersionEdit edit_;

    // Each compaction reads inputs from &amp;quot;level_&amp;quot; and &amp;quot;level_+1&amp;quot;
    std::vector&amp;lt;FileMetaData*&amp;gt; inputs_[2];      // The two sets of inputs

    // State used to check for number of of overlapping grandparent files
    // (parent == level_ + 1, grandparent == level_ + 2)
    std::vector&amp;lt;FileMetaData*&amp;gt; grandparents_;
    size_t grandparent_index_;  // Index in grandparent_starts_
    bool seen_key_;             // Some output key has been seen
    int64_t overlapped_bytes_;  // Bytes of overlap between current output
                                // and grandparent files

    // level_ptrs_ holds indices into input_version_-&amp;gt;levels_: our state
    // is that we are positioned at one of the file ranges for each
    // higher level than the ones involved in this compaction (i.e. for
    // all L &amp;gt;= level_ + 2).
    size_t level_ptrs_[config::kNumLevels];
};

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h1&gt;主要操作&lt;/h1&gt;

&lt;h3&gt;读操作&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status DBImpl::Get(const ReadOptions&amp;amp; options,
                   const Slice&amp;amp; key,
                   std::string* value) {

  MutexLock l(&amp;amp;mutex_);
  MemTable* mem = mem_;
  MemTable* imm = imm_;
  Version* current = versions_-&amp;gt;current();

  bool have_stat_update = false;
  Version::GetStats stats;

  // Unlock while reading from files and memtables
  {
    mutex_.Unlock();
    // First look in the memtable, then in the immutable memtable (if any).
    LookupKey lkey(key, snapshot);
    if (mem-&amp;gt;Get(lkey, value, &amp;amp;s)) {  // 1）先在 MemTable 中查找
      // Done
    } else if (imm != NULL &amp;amp;&amp;amp; imm-&amp;gt;Get(lkey, value, &amp;amp;s)) {  // 2）再在 Imutable MemTable 中查找
      // Done
    } else {
      s = current-&amp;gt;Get(options, lkey, value, &amp;amp;stats);  // 3) 最后在当前 Version 中查找
      have_stat_update = true;
    }
    mutex_.Lock();
  }

  // UpdateStats 减去 allowed_seeks，如果小于等于 0，则设置 file_to_compact_，准备 compaction
  if (have_stat_update &amp;amp;&amp;amp; current-&amp;gt;UpdateStats(stats)) {
    MaybeScheduleCompaction();
  }

  return s;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;// Version 类的 Get 方法
Status Version::Get(const ReadOptions&amp;amp; options,
                    const LookupKey&amp;amp; k,
                    std::string* value,
                    GetStats* stats) {
  Slice ikey = k.internal_key();
  Slice user_key = k.user_key();
  const Comparator* ucmp = vset_-&amp;gt;icmp_.user_comparator();
  Status s;

  stats-&amp;gt;seek_file = NULL;
  stats-&amp;gt;seek_file_level = -1;
  FileMetaData* last_file_read = NULL;
  int last_file_read_level = -1;

  // We can search level-by-level since entries never hop across
  // levels.  Therefore we are guaranteed that if we find data
  // in an smaller level, later levels are irrelevant.
  std::vector&amp;lt;FileMetaData*&amp;gt; tmp;
  FileMetaData* tmp2;
  for (int level = 0; level &amp;lt; config::kNumLevels; level++) {
    size_t num_files = files_[level].size();
    if (num_files == 0) continue;

    // 这里省略一大段代码 files 指向候选文件列表，num_files 为列表的长度。具体实现看源码

    for (uint32_t i = 0; i &amp;lt; num_files; ++i) {
      if (last_file_read != NULL &amp;amp;&amp;amp; stats-&amp;gt;seek_file == NULL) {
        // We have had more than one seek for this read.  Charge the 1st file.
        // last_file_read 保存的其实就是第一个查找未命中的文件，函数返回后会调用 UpdateStats 来减去 allowed_seeks
        stats-&amp;gt;seek_file = last_file_read;
        stats-&amp;gt;seek_file_level = last_file_read_level;
      }

      FileMetaData* f = files[i];
      last_file_read = f;
      last_file_read_level = level;

      Saver saver;
      saver.state = kNotFound;
      saver.ucmp = ucmp;
      saver.user_key = user_key;
      saver.value = value;
      // 从 TableCache 中读取文件内容
      s = vset_-&amp;gt;table_cache_-&amp;gt;Get(options, f-&amp;gt;number, f-&amp;gt;file_size,
                                   ikey, &amp;amp;saver, SaveValue);
      if (!s.ok()) {
        return s;
      }
      switch (saver.state) {
        case kNotFound:
          break;      // Keep searching in other files
        case kFound:
          return s;
        case kDeleted:
          s = Status::NotFound(Slice());  // Use empty error message for speed
          return s;
        case kCorrupt:
          s = Status::Corruption(&amp;quot;corrupted key for &amp;quot;, user_key);
          return s;
      }
    }
  }

  return Status::NotFound(Slice());  // Use an empty error message for speed
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status TableCache::Get(const ReadOptions&amp;amp; options, uint64_t file_number, 
                      uint64_t file_size, const Slice&amp;amp; k, void *arg,
                      void (*saver)(void* const Slice&amp;amp;, const Slice&amp;amp;)) {
  Cache::Handle* handle = NULL;
  Status s = FindTable(file_number, file_size, &amp;amp;handle);
  if (s.ok()) {
    Table* t = reinterpret_cast&amp;lt;TableAndFile*&amp;gt;(cache_-&amp;gt;Value(handle))-&amp;gt;table;
    s = t-&amp;gt;InternalGet(options, k, arg, saver);
    cache_-&amp;gt;Release(handle);
  }
  return s;                        
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;查找顺序如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/leveldb/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;写操作&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status DB::Put(const WriteOptions&amp;amp; opt, const Slice&amp;amp; key, const Slice&amp;amp; value) {
  WriteBatch batch;
  batch.Put(key, value);
  return Write(opt, &amp;amp;batch);
}

Status DBImpl::Write(const WriteOptions&amp;amp; options, WriteBatch* my_batch) {
  Writer w(&amp;amp;mutex_);
  w.batch = my_batch;
  w.sync = options.sync;
  w.done = false;

  MutexLock l(&amp;amp;mutex_);
  writers_.push_back(&amp;amp;w);
  // 生产者消费者模型
  while (!w.done &amp;amp;&amp;amp; &amp;amp;w != writers_.front()) {
    w.cv.Wait();
  }
  // 写操作有可能被合并处理，因此有可能取到的时候写入已经完成。完成的话直接返回
  if (w.done) {
    return w.status;
  }

  // May temporarily unlock and wait.
  // MakeRoomForWrite 判断是非需要归并 memtable
  Status status = MakeRoomForWrite(my_batch == NULL);
  uint64_t last_sequence = versions_-&amp;gt;LastSequence();
  Writer* last_writer = &amp;amp;w;
  if (status.ok() &amp;amp;&amp;amp; my_batch != NULL) {  // NULL batch is for compactions
    WriteBatch* updates = BuildBatchGroup(&amp;amp;last_writer); // 合并写操作
    WriteBatchInternal::SetSequence(updates, last_sequence + 1);
    last_sequence += WriteBatchInternal::Count(updates);

    // Add to log and apply to memtable.  We can release the lock
    // during this phase since &amp;amp;w is currently responsible for logging
    // and protects against concurrent loggers and concurrent writes
    // into mem_.
    {
      mutex_.Unlock();
      status = log_-&amp;gt;AddRecord(WriteBatchInternal::Contents(updates));
      bool sync_error = false;
      if (status.ok() &amp;amp;&amp;amp; options.sync) {
        status = logfile_-&amp;gt;Sync();
        if (!status.ok()) {
          sync_error = true;
        }
      }
      if (status.ok()) {
        status = WriteBatchInternal::InsertInto(updates, mem_);
      }
      mutex_.Lock();
      if (sync_error) {
        // The state of the log file is indeterminate: the log record we
        // just added may or may not show up when the DB is re-opened.
        // So we force the DB into a mode where all future writes fail.
        RecordBackgroundError(status);
      }
    }
    if (updates == tmp_batch_) tmp_batch_-&amp;gt;Clear();

    versions_-&amp;gt;SetLastSequence(last_sequence);
  }

  while (true) {
    Writer* ready = writers_.front();
    writers_.pop_front();
    if (ready != &amp;amp;w) {
      ready-&amp;gt;status = status;
      ready-&amp;gt;done = true;
      ready-&amp;gt;cv.Signal();
    }
    if (ready == last_writer) break;
  }

  // Notify new head of write queue
  if (!writers_.empty()) {
    writers_.front()-&amp;gt;cv.Signal();
  }

  return status;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;// REQUIRES: Writer list must be non-empty
// REQUIRES: First writer must have a non-NULL batch
// 尝试合并写操作
WriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {
  assert(!writers_.empty());
  Writer* first = writers_.front();
  WriteBatch* result = first-&amp;gt;batch;
  assert(result != NULL);

  size_t size = WriteBatchInternal::ByteSize(first-&amp;gt;batch);

  // Allow the group to grow up to a maximum size, but if the
  // original write is small, limit the growth so we do not slow
  // down the small write too much.
  size_t max_size = 1 &amp;lt;&amp;lt; 20;
  if (size &amp;lt;= (128&amp;lt;&amp;lt;10)) {
    max_size = size + (128&amp;lt;&amp;lt;10);
  }

  *last_writer = first;
  std::deque&amp;lt;Writer*&amp;gt;::iterator iter = writers_.begin();
  ++iter;  // Advance past &amp;quot;first&amp;quot;
  for (; iter != writers_.end(); ++iter) {
    Writer* w = *iter;
    if (w-&amp;gt;sync &amp;amp;&amp;amp; !first-&amp;gt;sync) {
      // Do not include a sync write into a batch handled by a non-sync write.
      break;
    }

    if (w-&amp;gt;batch != NULL) {
      size += WriteBatchInternal::ByteSize(w-&amp;gt;batch);
      if (size &amp;gt; max_size) {
        // Do not make batch too big
        break;
      }

      // Append to *result
      // 把合并的写请求保存在成员变量 tmp_batch_ 中，避免和调用者的写请求混淆在一起
      if (result == first-&amp;gt;batch) {
        // Switch to temporary batch instead of disturbing caller&amp;#39;s batch
        result = tmp_batch_;
        assert(WriteBatchInternal::Count(result) == 0);
        WriteBatchInternal::Append(result, first-&amp;gt;batch);
      }
      WriteBatchInternal::Append(result, w-&amp;gt;batch);
    }
    *last_writer = w;
  }
  return result;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status WriteBatchInternal::InsertInto(const WriteBatch* b,
                                      MemTable* memtable) {
  MemTableInserter inserter;
  inserter.sequence_ = WriteBatchInternal::Sequence(b);
  inserter.mem_ = memtable;
  return b-&amp;gt;Iterate(&amp;amp;inserter);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status WriteBatch::Iterate(Handler* handler) const {
  Slice input(rep_);
  if (input.size() &amp;lt; kHeader) {
    return Status::Corruption(&amp;quot;malformed WriteBatch (too small)&amp;quot;);
  }

  input.remove_prefix(kHeader);
  Slice key, value;
  int found = 0;
  while (!input.empty()) {
    found++;
    char tag = input[0];
    input.remove_prefix(1);
    switch (tag) {
      case kTypeValue:
        if (GetLengthPrefixedSlice(&amp;amp;input, &amp;amp;key) &amp;amp;&amp;amp;
            GetLengthPrefixedSlice(&amp;amp;input, &amp;amp;value)) {
          handler-&amp;gt;Put(key, value);
        } else {
          return Status::Corruption(&amp;quot;bad WriteBatch Put&amp;quot;);
        }
        break;
      case kTypeDeletion:
        if (GetLengthPrefixedSlice(&amp;amp;input, &amp;amp;key)) {
          handler-&amp;gt;Delete(key);
        } else {
          return Status::Corruption(&amp;quot;bad WriteBatch Delete&amp;quot;);
        }
        break;
      default:
        return Status::Corruption(&amp;quot;unknown WriteBatch tag&amp;quot;);
    }
  }
  if (found != WriteBatchInternal::Count(this)) {
    return Status::Corruption(&amp;quot;WriteBatch has wrong count&amp;quot;);
  } else {
    return Status::OK();
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;Compaction&lt;/h3&gt;

&lt;p&gt;Compaction 触发时机：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Immutable MemTable 不为空&lt;/li&gt;
&lt;li&gt;指定了 Manual Compaction&lt;/li&gt;
&lt;li&gt;VersionSet NeedsCompaction 返回 True

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;compaction_score_&lt;/code&gt; 大于 1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;file_to_compact_&lt;/code&gt; 不为空&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;void DBImpl::MaybeScheduleCompaction() {
  mutex_.AssertHeld();
  if (bg_compaction_scheduled_) {
    // Already scheduled
  } else if (shutting_down_.Acquire_Load()) {
    // DB is being deleted; no more background compactions
  } else if (!bg_error_.ok()) {
    // Already got an error; no more changes
  } else if (imm_ == NULL &amp;amp;&amp;amp;
             manual_compaction_ == NULL &amp;amp;&amp;amp;
             !versions_-&amp;gt;NeedsCompaction()) {
    // No work to be done
  } else {
    bg_compaction_scheduled_ = true;
    env_-&amp;gt;Schedule(&amp;amp;DBImpl::BGWork, this);
  }
}

bool VersionSet::NeedsCompaction() const {
  Version* v = current_;
  return (v-&amp;gt;compaction_score_ &amp;gt;= 1) || (v-&amp;gt;file_to_compact_ != NULL);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;compaction_score_ 的计算如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;void VersionSet::Finalize(Version* v) {
  // Precomputed best level for next compaction
  int best_level = -1;
  double best_score = -1;

  for (int level = 0; level &amp;lt; config::kNumLevels-1; level++) {
    double score;
    if (level == 0) {
      // We treat level-0 specially by bounding the number of files
      // instead of number of bytes for two reasons:
      //
      // (1) With larger write-buffer sizes, it is nice not to do too
      // many level-0 compactions.
      //
      // (2) The files in level-0 are merged on every read and
      // therefore we wish to avoid too many files when the individual
      // file size is small (perhaps because of a small write-buffer
      // setting, or very high compression ratios, or lots of
      // overwrites/deletions).
      score = v-&amp;gt;files_[level].size() /
          static_cast&amp;lt;double&amp;gt;(config::kL0_CompactionTrigger);
    } else {
      // Compute the ratio of current size to size limit.
      const uint64_t level_bytes = TotalFileSize(v-&amp;gt;files_[level]);
      score = static_cast&amp;lt;double&amp;gt;(level_bytes) / MaxBytesForLevel(level);
    }

    if (score &amp;gt; best_score) {
      best_level = level;
      best_score = score;
    }
  }

  v-&amp;gt;compaction_level_ = best_level;
  v-&amp;gt;compaction_score_ = best_score;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;file_to_compact_ 则是由 allowed_seeks 来控制。从下面代码的注释可知 25 次 seek 的开销和一次 compaction 的开销差不多。allowed_seeks 可以理解为文件剩余查找次数，每次查找失败allowed_seeks 就会减 1。当 allowed_seeks 小于等于 0，意味着应该启动 compaction 来减少查找未命中带来的 seek 的开销了：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;bool Version::UpdateStats(const GetStats&amp;amp; stats) {
  FileMetaData* f = stats.seek_file;
  if (f != NULL) {
    f-&amp;gt;allowed_seeks--;
    if (f-&amp;gt;allowed_seeks &amp;lt;= 0 &amp;amp;&amp;amp; file_to_compact_ == NULL) {
      file_to_compact_ = f;
      file_to_compact_level_ = stats.seek_file_level;
      return true;
    }
  }
  return false;
}

// Apply all of the edits in *edit to the current state.
void Builder::Apply(VersionEdit* edit) {
  // Update compaction pointers
  for (size_t i = 0; i &amp;lt; edit-&amp;gt;compact_pointers_.size(); i++) {
    const int level = edit-&amp;gt;compact_pointers_[i].first;
    vset_-&amp;gt;compact_pointer_[level] =
        edit-&amp;gt;compact_pointers_[i].second.Encode().ToString();
  }

  // Delete files
  const VersionEdit::DeletedFileSet&amp;amp; del = edit-&amp;gt;deleted_files_;
  for (VersionEdit::DeletedFileSet::const_iterator iter = del.begin();
        iter != del.end();
        ++iter) {
    const int level = iter-&amp;gt;first;
    const uint64_t number = iter-&amp;gt;second;
    levels_[level].deleted_files.insert(number);
  }

  // Add new files
  for (size_t i = 0; i &amp;lt; edit-&amp;gt;new_files_.size(); i++) {
    const int level = edit-&amp;gt;new_files_[i].first;
    FileMetaData* f = new FileMetaData(edit-&amp;gt;new_files_[i].second);
    f-&amp;gt;refs = 1;

    // We arrange to automatically compact this file after
    // a certain number of seeks.  Let&amp;#39;s assume:
    //   (1) One seek costs 10ms
    //   (2) Writing or reading 1MB costs 10ms (100MB/s)
    //   (3) A compaction of 1MB does 25MB of IO:
    //         1MB read from this level
    //         10-12MB read from next level (boundaries may be misaligned)
    //         10-12MB written to next level
    // This implies that 25 seeks cost the same as the compaction
    // of 1MB of data.  I.e., one seek costs approximately the
    // same as the compaction of 40KB of data.  We are a little
    // conservative and allow approximately one seek for every 16KB
    // of data before triggering a compaction.
    f-&amp;gt;allowed_seeks = (f-&amp;gt;file_size / 16384);
    if (f-&amp;gt;allowed_seeks &amp;lt; 100) f-&amp;gt;allowed_seeks = 100;

    levels_[level].deleted_files.erase(f-&amp;gt;number);
    levels_[level].added_files-&amp;gt;insert(f);
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;看看 Compaction 做了哪些工作：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;void DBImpl::BackgroundCompaction() {
  mutex_.AssertHeld();

  if (imm_ != NULL) {
    CompactMemTable();
    return;
  }
  // 这里去掉了 manual compaction 的代码 不关心
  Compaction* c = versions_-&amp;gt;PickCompaction();

  Status status;
  if (c == NULL) {
    // Nothing to do
  } else if (c-&amp;gt;IsTrivialMove()) {
    // Move file to next level
    // IsTrivialMove 返回 True 则直接将文件移入 level + 1 层即可
    assert(c-&amp;gt;num_input_files(0) == 1);
    FileMetaData* f = c-&amp;gt;input(0, 0);
    c-&amp;gt;edit()-&amp;gt;DeleteFile(c-&amp;gt;level(), f-&amp;gt;number);
    c-&amp;gt;edit()-&amp;gt;AddFile(c-&amp;gt;level() + 1, f-&amp;gt;number, f-&amp;gt;file_size,
                       f-&amp;gt;smallest, f-&amp;gt;largest);
    status = versions_-&amp;gt;LogAndApply(c-&amp;gt;edit(), &amp;amp;mutex_);
    if (!status.ok()) {
      RecordBackgroundError(status);
    }
  } else {
    CompactionState* compact = new CompactionState(c);
    status = DoCompactionWork(compact);
    if (!status.ok()) {
      RecordBackgroundError(status);
    }
    CleanupCompaction(compact);
    c-&amp;gt;ReleaseInputs();
    DeleteObsoleteFiles();
  }
  delete c;

  if (status.ok()) {
    // Done
  } else if (shutting_down_.Acquire_Load()) {
    // Ignore compaction errors found during shutting down
  } else {
    Log(options_.info_log,
        &amp;quot;Compaction error: %s&amp;quot;, status.ToString().c_str());
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Compaction* VersionSet::PickCompaction() {
  Compaction* c;
  int level;

  // We prefer compactions triggered by too much data in a level over
  // the compactions triggered by seeks.
  // 判断是 size_compaction 还是 seek_compaction
  const bool size_compaction = (current_-&amp;gt;compaction_score_ &amp;gt;= 1);
  const bool seek_compaction = (current_-&amp;gt;file_to_compact_ != NULL);
  if (size_compaction) {
    level = current_-&amp;gt;compaction_level_;
    assert(level &amp;gt;= 0);
    assert(level+1 &amp;lt; config::kNumLevels);
    c = new Compaction(level);

    // Pick the first file that comes after compact_pointer_[level]
    // compact_pointer_[level] 记录上次 compact 时最大的 key
    for (size_t i = 0; i &amp;lt; current_-&amp;gt;files_[level].size(); i++) {
      FileMetaData* f = current_-&amp;gt;files_[level][i];
      if (compact_pointer_[level].empty() ||
          icmp_.Compare(f-&amp;gt;largest.Encode(), compact_pointer_[level]) &amp;gt; 0) {
        c-&amp;gt;inputs_[0].push_back(f);
        break;
      }
    }
    if (c-&amp;gt;inputs_[0].empty()) {
      // Wrap-around to the beginning of the key space
      c-&amp;gt;inputs_[0].push_back(current_-&amp;gt;files_[level][0]);
    }
  } else if (seek_compaction) {
    level = current_-&amp;gt;file_to_compact_level_;
    c = new Compaction(level);
    c-&amp;gt;inputs_[0].push_back(current_-&amp;gt;file_to_compact_);
  } else {
    return NULL;
  }

  c-&amp;gt;input_version_ = current_;
  c-&amp;gt;input_version_-&amp;gt;Ref();

  // Files in level 0 may overlap each other, so pick up all overlapping ones
  if (level == 0) {
    InternalKey smallest, largest;
    GetRange(c-&amp;gt;inputs_[0], &amp;amp;smallest, &amp;amp;largest);
    // Note that the next call will discard the file we placed in
    // c-&amp;gt;inputs_[0] earlier and replace it with an overlapping set
    // which will include the picked file.
    current_-&amp;gt;GetOverlappingInputs(0, &amp;amp;smallest, &amp;amp;largest, &amp;amp;c-&amp;gt;inputs_[0]);
    assert(!c-&amp;gt;inputs_[0].empty());
  }

  // 填充 level + 1 的文件，更新 compact_pointer_ 
  SetupOtherInputs(c);

  return c;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;IsTrivialMove 判断能否直接将文件移入 level + 1 层：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;bool Compaction::IsTrivialMove() const {
  // Avoid a move if there is lots of overlapping grandparent data.
  // Otherwise, the move could create a parent file that will require
  // a very expensive merge later on.
  return (num_input_files(0) == 1 &amp;amp;&amp;amp;
          num_input_files(1) == 0 &amp;amp;&amp;amp;
          TotalFileSize(grandparents_) &amp;lt;= kMaxGrandParentOverlapBytes);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;具体的合并操作在 DoCompactionWork 方法：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status DBImpl::DoCompactionWork(CompactionState* compact) {
  if (snapshots_.empty()) {
    compact-&amp;gt;smallest_snapshot = versions_-&amp;gt;LastSequence();
  } else {
    compact-&amp;gt;smallest_snapshot = snapshots_.oldest()-&amp;gt;number_;
  }

  // Release mutex while we&amp;#39;re actually doing the compaction work
  mutex_.Unlock();

  Iterator* input = versions_-&amp;gt;MakeInputIterator(compact-&amp;gt;compaction);
  input-&amp;gt;SeekToFirst();
  Status status;
  ParsedInternalKey ikey;
  std::string current_user_key;
  bool has_current_user_key = false;
  SequenceNumber last_sequence_for_key = kMaxSequenceNumber;
  for (; input-&amp;gt;Valid() &amp;amp;&amp;amp; !shutting_down_.Acquire_Load(); ) {
    // Prioritize immutable compaction work
    if (has_imm_.NoBarrier_Load() != NULL) {
      mutex_.Lock();
      if (imm_ != NULL) {
        CompactMemTable();  // 总是优先处理 CompactMemTable 避免阻塞 MemTable 的写入
        bg_cv_.SignalAll();  // Wakeup MakeRoomForWrite() if necessary
      }
      mutex_.Unlock();
    }

    Slice key = input-&amp;gt;key();
    if (compact-&amp;gt;compaction-&amp;gt;ShouldStopBefore(key) &amp;amp;&amp;amp;
        compact-&amp;gt;builder != NULL) {
      status = FinishCompactionOutputFile(compact, input);
      if (!status.ok()) {
        break;
      }
    }

    // Handle key/value, add to state, etc.
    bool drop = false;
    if (!ParseInternalKey(key, &amp;amp;ikey)) {
      // Do not hide error keys
      current_user_key.clear();
      has_current_user_key = false;
      last_sequence_for_key = kMaxSequenceNumber;
    } else {
      if (!has_current_user_key ||
          user_comparator()-&amp;gt;Compare(ikey.user_key,
                                     Slice(current_user_key)) != 0) {
        // First occurrence of this user key
        current_user_key.assign(ikey.user_key.data(), ikey.user_key.size());
        has_current_user_key = true;
        last_sequence_for_key = kMaxSequenceNumber;
      }

      if (last_sequence_for_key &amp;lt;= compact-&amp;gt;smallest_snapshot) {
        // Hidden by an newer entry for same user key
        drop = true;    // (A)
      } else if (ikey.type == kTypeDeletion &amp;amp;&amp;amp;
                 ikey.sequence &amp;lt;= compact-&amp;gt;smallest_snapshot &amp;amp;&amp;amp;
                 compact-&amp;gt;compaction-&amp;gt;IsBaseLevelForKey(ikey.user_key)) {
        // For this user key:
        // (1) there is no data in higher levels
        // (2) data in lower levels will have larger sequence numbers
        // (3) data in layers that are being compacted here and have
        //     smaller sequence numbers will be dropped in the next
        //     few iterations of this loop (by rule (A) above).
        // Therefore this deletion marker is obsolete and can be dropped.
        // 如果高层还有记录，则 kTypeDeletion 标记不能丢掉。
        // smallest_snapshot 主要是为了快照功能服务
        // 但 ikey.sequence &amp;lt;= compact-&amp;gt;smallest_snapshot 这个判断没看懂
        drop = true;
      }

      last_sequence_for_key = ikey.sequence;
    }

    if (!drop) {
      // Open output file if necessary
      if (compact-&amp;gt;builder == NULL) {
        status = OpenCompactionOutputFile(compact);
        if (!status.ok()) {
          break;
        }
      }
      if (compact-&amp;gt;builder-&amp;gt;NumEntries() == 0) {
        compact-&amp;gt;current_output()-&amp;gt;smallest.DecodeFrom(key);
      }
      compact-&amp;gt;current_output()-&amp;gt;largest.DecodeFrom(key);
      compact-&amp;gt;builder-&amp;gt;Add(key, input-&amp;gt;value());

      // Close output file if it is big enough
      if (compact-&amp;gt;builder-&amp;gt;FileSize() &amp;gt;=
          compact-&amp;gt;compaction-&amp;gt;MaxOutputFileSize()) {
        status = FinishCompactionOutputFile(compact, input);  // 输出新的 SST 文件
        if (!status.ok()) {
          break;
        }
      }
    }

    input-&amp;gt;Next();
  }

  // 中间省略一坨代码

  mutex_.Lock();
  stats_[compact-&amp;gt;compaction-&amp;gt;level() + 1].Add(stats);

  if (status.ok()) {
    status = InstallCompactionResults(compact);
  }

  return status;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;最后调用 InstallCompactionResults，记录版本变化：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status DBImpl::InstallCompactionResults(CompactionState* compact) {
  mutex_.AssertHeld();
  Log(options_.info_log,  &amp;quot;Compacted %d@%d + %d@%d files =&amp;gt; %lld bytes&amp;quot;,
      compact-&amp;gt;compaction-&amp;gt;num_input_files(0),
      compact-&amp;gt;compaction-&amp;gt;level(),
      compact-&amp;gt;compaction-&amp;gt;num_input_files(1),
      compact-&amp;gt;compaction-&amp;gt;level() + 1,
      static_cast&amp;lt;long long&amp;gt;(compact-&amp;gt;total_bytes));

  // Add compaction outputs
  compact-&amp;gt;compaction-&amp;gt;AddInputDeletions(compact-&amp;gt;compaction-&amp;gt;edit());
  const int level = compact-&amp;gt;compaction-&amp;gt;level();
  for (size_t i = 0; i &amp;lt; compact-&amp;gt;outputs.size(); i++) {
    const CompactionState::Output&amp;amp; out = compact-&amp;gt;outputs[i];
    compact-&amp;gt;compaction-&amp;gt;edit()-&amp;gt;AddFile(
        level + 1,
        out.number, out.file_size, out.smallest, out.largest);
  }
  return versions_-&amp;gt;LogAndApply(compact-&amp;gt;compaction-&amp;gt;edit(), &amp;amp;mutex_);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Fri, 23 Jun 2017 15:53:23 +0800</pubDate>
        <link>http://masutangu.com/2017/06/leveldb_1/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/06/leveldb_1/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>链接和装载</title>
        <description>&lt;p&gt;本文是读《程序员的自我修养: 链接、装载与库》所整理的读书笔记。&lt;/p&gt;

&lt;h1&gt;概论&lt;/h1&gt;

&lt;p&gt;从源文件到可执行文件，可以分解为四个过程：&lt;strong&gt;预处理&lt;/strong&gt;，&lt;strong&gt;编译&lt;/strong&gt;，&lt;strong&gt;汇编&lt;/strong&gt;，&lt;strong&gt;链接&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;预处理主要完成以下工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;展开所有宏定义，删除 #define&lt;/li&gt;
&lt;li&gt;处理所有条件预编译指令&lt;/li&gt;
&lt;li&gt;处理 #include 预编译指令。将被包含的文件插入到该预编译指令的位置&lt;/li&gt;
&lt;li&gt;删除所有注释&lt;/li&gt;
&lt;li&gt;添加行号和文件名标识，以便编译时编辑器产生调试用的行号信息以及编译产生错误或警告时的行号信息&lt;/li&gt;
&lt;li&gt;保留所有 #pragma 编译器指令&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;编译的过程即把预处理完的文件进行一系列的词法分析、语法分析、语义分析以及优化后产生相应的汇编代码文件。&lt;/p&gt;

&lt;p&gt;汇编器将汇编代码转变为机器可以执行的指令，即目标文件，再由链接器将多个目标文件输出成最后的可执行文件。链接器负责解决&lt;strong&gt;模块间符号引用&lt;/strong&gt;的问题，链接的过程包括了&lt;strong&gt;地址和空间分配&lt;/strong&gt;、&lt;strong&gt;符号决议&lt;/strong&gt;和&lt;strong&gt;重定位&lt;/strong&gt;。&lt;/p&gt;

&lt;h1&gt;目标文件&lt;/h1&gt;

&lt;p&gt;目标文件和可执行文件的格式很相似，在 Linux 下统称为 ELF 文件。ELF 文件格式的核心思想是按不同属性分段（section）存储。&lt;/p&gt;

&lt;p&gt;编译后的目标文件格式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;程序源代码编译后的机器指令通常放在代码段（.text），已初始化的全局变量和静态局部变量放在数据段（.data），.bss 段用于为未初始化的全局变量和静态局部变量预留空间，因此该段在文件中不占据空间。.rodata 段存放的是只读数据，一般是只读变量和字符串常量。&lt;/p&gt;

&lt;p&gt;分段的好处在于：&lt;strong&gt;方便权限控制&lt;/strong&gt;、&lt;strong&gt;提高 CPU 缓存命中率&lt;/strong&gt;和&lt;strong&gt;节省内存&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;下面看个实际的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/*
simplesection.c
linux: gcc -c simplesection.c -o simplesection.o
*/

int printf(const char* format, ...);

int global_init_var = 84;
int global_uninit_var;

void func1(int i) 
{
    printf(&amp;quot;%d\n&amp;quot;, i);
}

int main(void) 
{
    static int static_var = 85;
    static int static_var2;

    int a = 1;
    int b;

    func1(static_var + static_var2 + a + b);
    return a;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;使用 &lt;code&gt;objdump -h&lt;/code&gt; 查看段表的信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意，&lt;code&gt;objdump -h&lt;/code&gt; 只会显示关键的段，可以用 &lt;code&gt;readelf -S&lt;/code&gt; 查看完整的段表信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-5.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意这里的 .rel.text 段是重定位表，.symtab 段是符号表。下面会重点说明。&lt;/p&gt;

&lt;p&gt;可以使用 &lt;code&gt;objdump -s -d&lt;/code&gt; 查看各个段的内容：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到 .data 段前后四个字节分别是是 54000000 和 55000000，即十进制 84 和 85。正好对应 global_init_var 和 static_var 这两个变量。.rodata 段存放了 25640a00，即 %d\n 的 ASCII 字节序。&lt;/p&gt;

&lt;p&gt;接下来用 &lt;code&gt;readelf -h&lt;/code&gt; 看看 ELF 文件的头部：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-4.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;入口地址（entry point address）标识了 ELF 程序的入口虚拟地址，操作系统在加载完该程序后从这个入口地址开始执行进程的指令。可重定位文件一般没有入口地址，即值为 0。&lt;/p&gt;

&lt;h3&gt;符号表&lt;/h3&gt;

&lt;p&gt;用 &lt;code&gt;readelf -s&lt;/code&gt; 看看 ELF 文件的符号表：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-6.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Type 列含义如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NOTYPE：未知类型&lt;/li&gt;
&lt;li&gt;OBJECT：数据对象&lt;/li&gt;
&lt;li&gt;FUNC：函数或可执行代码&lt;/li&gt;
&lt;li&gt;SECTION：段&lt;/li&gt;
&lt;li&gt;FILE：文件名&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bind 列含义如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LOCAL：局部符号，对目标文件的外部不可见&lt;/li&gt;
&lt;li&gt;GLOBAL：全局符号&lt;/li&gt;
&lt;li&gt;WEAK：弱引用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果符号定义在本目标文件中，那 Ndx 列表示符号所在段在段表中的下标，如果不是定义在本目标文件中或是特殊符号，含义如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ABS：表明该符号包含了一个绝对值，例如文件名符号&lt;/li&gt;
&lt;li&gt;COMMON：表明该符号是一个 COMMON 块类型的符号，一般未初始化的全局变量就是这种类型&lt;/li&gt;
&lt;li&gt;UNDEF：表明该符号未定义，在本目标文件被引用但定义在其他目标文件中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Value 列含义如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果是符号的定义并且不是 COMMON 块，则表示符号在段中的偏移&lt;/li&gt;
&lt;li&gt;如果是 COMMON 块，则表示对齐属性&lt;/li&gt;
&lt;li&gt;可执行文件中，表示符号的虚拟地址，该虚拟地址对动态链接器来说非常有用&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;静态链接&lt;/h1&gt;

&lt;p&gt;链接器一般采用两步链接的方法来分配空间：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;扫描所有输入目标文件，收集各个段的长度、属性和未位置，并将输入目标文件符号表中的所有符号定义和符号引用汇总到全局符号表。&lt;/li&gt;
&lt;li&gt;读取输入文件中段的数据和重定位信息，进行符号解析与重定位。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;来看一个链接的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;/* a.c */

extern int shared;

int main() 
{
    int a = 100;
    swap(&amp;amp;a, &amp;amp;shared);
}

/* b.c */
int shared = 1;

void swap(int *a, int *b) 
{
    *a ^= *b ^= *a ^= *b;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;可以看到 a.c 中引用了 b.c 的两个符号，先用 objdump 看看 a.o 中代码段的反编译结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-11.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当 a.c 被编译成目标文件时，编译器并不知道 share 和 swap 的地址，因此编译器暂时把 地址 0 看成 shared 的地址：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;13: be 00 00 00 00          mov    $0x0,%esi
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;相似的，调用 swap 的时候使用了临时假地址：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;20: e8 00 00 00 00          callq  25 &amp;lt;main+0x25&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;使用 ld 将 a.o 和 b.o 链接起来：&lt;code&gt;ld a.o b.o -e main -o ab&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;再用 objdump 查看链接前后地址分配的情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-8.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-9.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-10.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VMA 表示虚拟内存地址，LMA 表示加载地址，正常情况下这两个值是一样的。&lt;/p&gt;

&lt;p&gt;可以发现链接前目标文件所有段的 VMA 都是 0，因为虚拟空间还没分配。链接后可执行文件 ab 的各个段都分配了相应的虚拟地址。&lt;/p&gt;

&lt;p&gt;当链接完成，由于各个段地址已经确定，各个符号在段内的相对地址也是固定的，这样各个符号的绝对地址也已经确定了。可以通过 objdump 观察到 ab 文件中符号地址已经修正了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-12.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;实际上，链接器是通过 ELF 文件中的重定位表，来找到需要重定位的符号的。&lt;code&gt;objdump -r&lt;/code&gt; 可以查看重定位表的信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-13.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;OFFSET 表示该重定位符号在段中的偏移。&lt;/p&gt;

&lt;h1&gt;装载&lt;/h1&gt;

&lt;p&gt;Linux 下创建一个进程，加载可执行文件并执行，大致步骤如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建一个独立的虚拟地址空间&lt;/li&gt;
&lt;li&gt;读取可执行文件头，建立虚拟空间与可执行文件的映射关系。&lt;strong&gt;Linux 内核的 VMA 结构就是用与建立虚拟空间和可执行文件的映射关系&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将 CPU 指令寄存器设置为可执行文件的入口地址，启动运行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;操作系统并不关心可执行文件中各个段的实际内容，只关心段的权限。为了减少内存浪费（映射时以页长作为单位），对于相同权限的段，合并到一起当做一个段进行映射。因此 ELF 可执行文件引入了 segment 的概念。一个 segment 包含一个或多个属性相似的 section。描述 segment 的结构叫程序头（program header），可以使用 &lt;code&gt;readelf -l&lt;/code&gt; 查看 segment 信息。&lt;/p&gt;

&lt;p&gt;VMA 除了用以映射可执行文件的各个 segment 以外，还被用来管理进程的地址空间。进程执行需要的栈和堆，也是以 VMA 形式存在的。可以通过 &lt;code&gt;cat /proc/pid/maps&lt;/code&gt; 查看进程的虚拟空间分布。&lt;/p&gt;

&lt;h1&gt;动态链接&lt;/h1&gt;

&lt;p&gt;为了节省空间，简化程序的更新和发布，引入了动态链接的概念。动态链接的基本思想在于&lt;strong&gt;将链接的过程推迟到运行时&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;由于共享对象的加载地址在编译时是不确定的，因此需要在装载时重定位。但由于装载时重定位会修改指令，没有办法做到同一份指令被多个进程共享，因此引入了&lt;strong&gt;地址无关代码&lt;/strong&gt;（PIC）的概念。其基本思想是把指令中那些需要修改的部分抽离出来放到数据部分，这样的话指令部分可以保持不变，被多个进程共享，而数据部分每个进程都有一个副本。&lt;/p&gt;

&lt;p&gt;当使用 PIC 编译时，模块内的数据引用和函数访问是通过相对寻址的方式。模块间的数据引用和函数访问则通过数据段的全局偏移表（GOT）来实现。&lt;/p&gt;

&lt;p&gt;使用 gcc 编译时，指定 &lt;code&gt;-shared&lt;/code&gt; 使用装载时重定位的方法，如果指定了 &lt;code&gt;fPIC&lt;/code&gt; 则产生地址无关的共享对象。&lt;/p&gt;

&lt;p&gt;为了提高动态链接的效率，引入了 PLT 来实现延迟绑定。&lt;/p&gt;

&lt;p&gt;动态链接需要注意&lt;strong&gt;全局符号介入&lt;/strong&gt;的问题，当一个符号需要被加入全局符号表时，如果相同的符号名已经存在，则后加入的符号将被忽略。来看看下面的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/* a1.c */

#include &amp;lt;stdio.h&amp;gt;

void a()
{
    printf(&amp;quot;a1.c\n&amp;quot;);
}

/* a2.c */
#include &amp;lt;stdio.h&amp;gt;

void a()
{
    printf(&amp;quot;a2.c\n&amp;quot;);
}

/* b1.c */
void a();

void b1()
{
    a();
}

/* b2.c */
void a();

void b2() 
{
    a();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;假设 b1.so 依赖于 a1.so，b2.so 依赖于 a2.so。将 b1.so 与 a1.so 进行链接，b2.so 与 a2.so 进行链接：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;gcc -fPIC -shared a1.c -o a1.so
gcc -fPIC -shared a2.c -o a2.so
gcc -fPIC -shared b1.c a1.so -o b1.so
gcc -fPIC -shared b2.c a2.so -o b2.so
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;当有程序同时使用 b1.c 的函数 b1 和 b2.c 中的函数 b2 时：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/* main.c */

#include &amp;lt;stdio.h&amp;gt;

void b1();
void b2();

int main()
{
    b1();
    b2();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;编译并运行：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-16.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;观察到输出是两个 a1.c，意味着 a2.c 的 a() 函数被忽略了。&lt;/p&gt;

&lt;p&gt;如果是采用静态编译，则链接时会报重定义的错误：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-17.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再来看看另一个有趣的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/* foo.c */
#include &amp;lt;stdio.h&amp;gt;

struct {
    int a;
    int b;
} b = { 3, 3 };

int main();

void foo()
{
    b.a = 4;
    b.b = 4;
    printf(&amp;quot;foo: b.a=%d, b.b=%d\n&amp;quot;, b.a, b.b);
}

/* t1.c */
#include &amp;lt;stdio.h&amp;gt;

int b = 1;
int c = 1;

int main()
{
    int count = 5;
    while (count-- &amp;gt; 0) {
        t2();
        foo();
        printf(&amp;quot;t1: b=%d, c=%d\n&amp;quot;, b, c);
        sleep(1);
    }
    return 0;
}

/* t2.c */
#include &amp;lt;stdio.h&amp;gt;

int b;
int c;

int t2()
{
    printf(&amp;quot;t2: b=%d, c=%d\n&amp;quot;, b, c);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;编译：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;gcc -shared -fPIC foo.c -o foo.so 
gcc  t1.c t2.c foo.so -o test -Xlinker -rpath ./
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;输出结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-18.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其实在动态链接时，foo.c 里定义的 struct b 符号被忽略了（因为 t1.c 里已经定义了符号 b）。因此在后续调用 foo() 时，&lt;code&gt;b.a = 4&lt;/code&gt; 中 b.a 的地址其实是 t1.c 文件中变量 b 的地址，&lt;code&gt;b.b = 4&lt;/code&gt; 中 b.b 的地址其实是 t1.c 文件中变量 c 的地址（因为 t1.c 中变量 b 和 c 的地址刚好相邻）。&lt;/p&gt;

&lt;p&gt;由于可能存在全局符号介入的问题，模块内函数的调用不能用相对地址调用，编译器会将其当做模块外部符号来处理，使用 .got.plt 进行重定位。因此为了提高模块内函数调用的效率，&lt;strong&gt;建议使用 static 关键字将被调用的函数设置为编译单元私有函数&lt;/strong&gt;。此时编译器会采用相对地址的编译方式，因为能确保该函数不会被其他模块所覆盖。&lt;/p&gt;

&lt;h1&gt;内存&lt;/h1&gt;

&lt;p&gt;下图为 Linux 进程内存空间的典型布局：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-14.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中 dynamic libraries 用于映射装载的动态链接库。&lt;/p&gt;

&lt;h2&gt;栈&lt;/h2&gt;

&lt;p&gt;栈在程序运行中起了举足轻重的地位。栈保存了一个函数调用所需要的维护信息，通常称为堆栈帧（Stack Frame）。通常有以下内容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;函数的返回地址和参数&lt;/li&gt;
&lt;li&gt;临时变量，包括函数的非静态局部变量以及编译器自动生成的其他临时变量&lt;/li&gt;
&lt;li&gt;保存的上下文，包括函数调用前后需要保存的寄存器&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;i386 中，esp 寄存器始终指向栈顶，ebp 寄存器指向了堆栈帧的一个固定位置，因此 ebp 又称为帧指针（Frame Pointer），如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-15.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;i386 的函数调用过程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;把参数压入栈中&lt;/li&gt;
&lt;li&gt;把当前指令的下一条指令的地址压入栈中&lt;/li&gt;
&lt;li&gt;跳转到函数体执行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;i386 的函数体开头大致如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;push ebp: 把旧的 ebp 压入栈中 &lt;/li&gt;
&lt;li&gt;mov ebp, esp: 将 esp 的值赋给 ebp，此时 ebp 和 esp 都指向栈顶，栈顶保存的就是 old ebp&lt;/li&gt;
&lt;li&gt;sub esp, XXX: 可选，在栈上分配 XXX 字节的临时空间&lt;/li&gt;
&lt;li&gt;push XXX: 可选，如有必要，保存名为 XXX 的寄存器 &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;函数返回的流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;pop XXX: 可选，如有必要，恢复保存过的寄存器的值&lt;/li&gt;
&lt;li&gt;mov esp, ebp: 恢复 ESP，回收局部变量的空间&lt;/li&gt;
&lt;li&gt;pop ebp: 从栈顶恢复旧的 ebp 的值&lt;/li&gt;
&lt;li&gt;ret: 从栈顶取得返回地址，并跳转到该位置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;eax 寄存器通常是函数返回值的通道。函数将返回值存储在 eax 中，返回后调用方读取 eax 得到函数的返回值。由于 eax 只有 4 个字节，如果返回的是 5~8 字节对象的情况，惯例是采用 eax 和 edx 联合返回的方式。超过 8 字节的，则通过临时变量的方式来实现：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用者在栈上开辟了一片空间，并且将这块空间的一部分作为传递返回值的临时对象 temp&lt;/li&gt;
&lt;li&gt;将 temp 对象的地址作为隐藏参数传递给被调用的函数&lt;/li&gt;
&lt;li&gt;被调用的函数将返回值拷贝给 temp 对象，并将 temp 对象的地址用 eax 传出&lt;/li&gt;
&lt;li&gt;返回后，调用者只需要拷贝 eax 指向的 temp 对象的内容就能得到返回值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这也是为什么不能直接对函数返回值进行取址的原因，因为函数返回后临时变量 temp 就被释放掉了。&lt;/p&gt;

&lt;h2&gt;堆&lt;/h2&gt;

&lt;p&gt;Linux 提供了两种堆空间分配的方式：brk() 和 mmap()。&lt;/p&gt;

&lt;p&gt;brk() 的作用是设置进程数据段的结束地址，它可以扩大或缩小数据段。mmap() 的作用是向操作系统申请一段虚拟地址空间，可以是映射到某个文件也可以是匿名空间。&lt;/p&gt;

&lt;p&gt;glibc 的 malloc 函数，对小于 128 KB 的请求来说，会在现有的堆空间里按照堆分配算法分配一块空间并返回。对于大于 128 KB 的请求来说，它会使用 mmap() 函数分配一块匿名空间。&lt;/p&gt;
</description>
        <pubDate>Sat, 25 Feb 2017 10:55:19 +0800</pubDate>
        <link>http://masutangu.com/2017/02/linker-loader-library-note/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/02/linker-loader-library-note/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>Linux 性能监控</title>
        <description>&lt;p&gt;本文是对 &lt;a href=&quot;http://www.vpsee.com/2009/11/linux-system-performance-monitoring-introduction/&quot;&gt;《Linux 性能监测》&lt;/a&gt; 系列文章的读书笔记，并在此基础上丰富。&lt;/p&gt;

&lt;h2&gt;CPU 相关&lt;/h2&gt;

&lt;h3&gt;vmstat&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0 164412 143200  35916 243216    0    0    12    11   46   22  1  1 98  0  0
 0  0 164412 142960  35916 243260    0    0     0     0  583  854  2  1 97  0  0
 0  0 164412 142960  35916 243260    0    0     0     0  940 1184  2  1 97  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;参数说明：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;r:    可运行队列的线程数，这些线程都是可运行状态，只不过 CPU 暂时不可用&lt;/li&gt;
&lt;li&gt;b:    被 blocked 的进程数，正在等待 IO 请求&lt;/li&gt;
&lt;li&gt;in:   被处理过的中断数&lt;/li&gt;
&lt;li&gt;cs:   系统上正在做上下文切换的数目&lt;/li&gt;
&lt;li&gt;us:   用户占用 CPU 的百分比&lt;/li&gt;
&lt;li&gt;sy:   内核和中断占用 CPU 的百分比&lt;/li&gt;
&lt;li&gt;wa:   所有可运行的线程被 blocked 以后都在等待 IO，这时候 CPU 空闲的百分比&lt;/li&gt;
&lt;li&gt;id:   CPU 完全空闲的百分比&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;合理的参数范围：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CPU 利用率：如果 CPU 达到 100％ 利用率，那么 us 和 sy 占比应该达到这样一个平衡：65％－70％ User Time，30％－35％ System Time，0％－5％ Idle Time&lt;/li&gt;
&lt;li&gt;上下文切换：上下文切换应该和 CPU 利用率联系起来看，如果能保持上面的 CPU 利用率平衡，大量的上下文切换是可以接受的&lt;/li&gt;
&lt;li&gt;可运行队列：每个处理器的可运行队列不应该超过3个线程，比如：双处理器系统的可运行队列里不应该超过6个线程&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;案例 1：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 4  0    140 2915476 341288 3951700  0    0     0     0 1057  523 19 81  0  0  0
 4  0    140 2915724 341296 3951700  0    0     0     0 1048  546 19 81  0  0  0
 4  0    140 2915848 341296 3951700  0    0     0     0 1044  514 18 82  0  0  0
 4  0    140 2915848 341296 3951700  0    0     0    24 1044  564 20 80  0  0  0
 4  0    140 2915848 341296 3951700  0    0     0     0 1060  546 18 82  0  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上面的输出可以看出：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;system time（sy）一直保持在 80％ 以上，而且上下文切换较低（cs），说明某个进程可能一直霸占着 CPU&lt;/li&gt;
&lt;li&gt;run queue（r）刚好在4个&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;案例 2：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
14  0    140 2904316 341912 3952308  0    0     0   460 1106 9593 36 64  1  0  0
17  0    140 2903492 341912 3951780  0    0     0     0 1037 9614 35 65  1  0  0
20  0    140 2902016 341912 3952000  0    0     0     0 1046 9739 35 64  1  0  0
17  0    140 2903904 341912 3951888  0    0     0    76 1044 9879 37 63  0  0  0
16  0    140 2904580 341912 3952108  0    0     0     0 1055 9808 34 65  1  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上面的输出可以看出：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;context switch（cs）比 interrupts（in）要高得多，说明内核不得不来回切换进程&lt;/li&gt;
&lt;li&gt;进一步观察发现 system time（sy）很高而 user time（us）很低，而且加上高频度的上下文切换（cs），说明正在运行的应用程序调用了大量的系统调用&lt;/li&gt;
&lt;li&gt;run queue（r）在14个线程以上，按照这个测试机器的硬件配置（四核），应该保持在12个以内。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;案例 3：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 5  0     92 185724 735036 2736384   0    0     2    11    0    1  2  0 98  0  0
 7  0     92 184980 735044 2736376   0    0     0   124 6682 7806 39  3 58  0  0
 6  0     92 184856 735044 2737064   0    0     0  1888 6721 7601 38  5 49  8  0
 2  0     92 184732 735044 2737064   0    0     0     0 6549 7525 46  4 50  0  0
 3  0     92 183988 735044 2737904   0    0     0     0 6375 7081 45  3 52  0  0
 1  0     92 184360 735048 2738156   0    0     0     0 6764 7601 44  4 51  0  0 
 8  1     92 183368 735048 2738508   0    0     0  1384 6774 8005 42  4 54  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;cpu 利用率上不去，vmstat 输出如上，分析可能的瓶颈：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;si、so 都是 0，free 也有，说明内存足够，排除内存。&lt;/li&gt;
&lt;li&gt;bi、bo 都不大，所以 io 似乎不严重，排除硬盘&lt;/li&gt;
&lt;li&gt;cs、in 都较大，说明 CPU 频于应付上下文切换和中断，而且从 r 的数字来看正在等 CPU 的进程较多，所以猜测服务器上运行的进程较多，CPU 疲于切换进程以及应付中断，猜测瓶颈是 CPU。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;mpstat&lt;/h3&gt;

&lt;p&gt;mpstat 和 vmstat 类似，不同的是 mpstat 可以输出多个处理器的数据。&lt;/p&gt;

&lt;h3&gt;ps&lt;/h3&gt;

&lt;p&gt;ps 用于查看某个程序、进程占用的 CPU 资源。&lt;/p&gt;

&lt;h3&gt;实践：定位 CPU 100% 的问题&lt;/h3&gt;

&lt;p&gt;某个进程 CPU 100% 了，如何定位？&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果是多线程，使用 &lt;code&gt;ps -eL |grep 进程id&lt;/code&gt;，找出占用 CPU 最长时间的线程 id&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;strace -p 线程id -tt&lt;/code&gt; 观察调用的系统调用&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;perf top&lt;/code&gt; 看看哪个函数占用率最高&lt;/li&gt;
&lt;li&gt;或使用 &lt;code&gt;watch pstack 线程 id&lt;/code&gt; 看看调用堆栈&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;之前工作中遇到过 CPU 使用率很高，通过 &lt;code&gt;perf top&lt;/code&gt; 和 &lt;code&gt;pstack&lt;/code&gt; 观察到写磁盘操作很多，推测是日志打印过多导致 CPU 使用率暴涨，调低了日志等级后顺利解决。&lt;/p&gt;

&lt;h2&gt;内存相关&lt;/h2&gt;

&lt;p&gt;kswapd daemon 用来检查 pages_high 和 pages_low，如果可用内存少于 pages_low，kswapd 就开始扫描并试图释放 32个页面，并且重复扫描释放的过程直到可用内存大于 pages_high 为止。&lt;/p&gt;

&lt;p&gt;扫描的时候检查3件事：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果页面没有修改，把页放到可用内存列表里&lt;/li&gt;
&lt;li&gt;如果页面被文件系统修改，把页面内容写到磁盘上&lt;/li&gt;
&lt;li&gt;如果页面被修改了，但不是被文件系统修改的，把页面写到交换空间&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;pdflush daemon 用来同步文件相关的内存页面，把内存页面及时同步到硬盘上。比如打开一个文件，文件被导入到内存里，对文件做了修改后并保存后，内核并不马上保存文件到硬盘，由 pdflush 决定什么时候把相应页面写入硬盘，这由一个内核参数 vm.dirty_background_ratio 来控制，比如下面的参数显示脏页面（dirty pages）达到所有内存页面10％的时候开始写入硬盘。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# /sbin/sysctl -n vm.dirty_background_ratio
10
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;vmstat&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0 164412 143200  35916 243216    0    0    12    11   46   22  1  1 98  0  0
 0  0 164412 142960  35916 243260    0    0     0     0  583  854  2  1 97  0  0
 0  0 164412 142960  35916 243260    0    0     0     0  940 1184  2  1 97  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;swpd: 已使用的 SWAP 空间大小，KB 为单位&lt;/li&gt;
&lt;li&gt;free: 可用的物理内存大小，KB 为单位&lt;/li&gt;
&lt;li&gt;buff: 物理内存用来缓存读写操作的 buffer 大小，KB 为单位&lt;/li&gt;
&lt;li&gt;cache: 物理内存用来缓存进程地址空间的 cache 大小，KB 为单位&lt;/li&gt;
&lt;li&gt;si: 数据从 SWAP 读取到 RAM（swap in）的大小，KB 为单位&lt;/li&gt;
&lt;li&gt;so: 数据从 RAM 写到 SWAP（swap out）的大小，KB 为单位&lt;/li&gt;
&lt;li&gt;bi: 从块设备读取（block in）的大小，block 为单位&lt;/li&gt;
&lt;li&gt;bo: 写入块设备（block out）的大小，block 为单位&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache    si    so    bi    bo   in   cs us sy id  wa st
 0  3 252696   2432    268   7148  3604  2368  3608  2372  288  288  0  0 21  78  1
 0  2 253484   2216    228   7104  5368  2976  5372  3036  930  519  0  0  0 100  0
 0  1 259252   2616    128   6148 19784 18712 19784 18712 3821 1853  0  1  3  95  1
 1  2 260008   2188    144   6824 11824  2584 12664  2584 1347 1174 14  0  0  86  0
 2  1 262140   2964    128   5852 24912 17304 24952 17304 4737 2341 86 10  0   0  4
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上面是一个频繁读写交换区的例子，可以观察到：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;buff 稳步减少说明系统知道内存不够了，kwapd 正在从 buff 那里借用部分内存&lt;/li&gt;
&lt;li&gt;kswapd 持续把脏页面写到 swap 交换区（so），并且从 swapd 逐渐增加看出确实如此。根据上面讲的 kswapd 扫描时检查的三件事，如果页面被修改了，但不是被文件系统修改的，把页面写到 swap，所以这里 swapd 持续增加&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;free&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ free
             total       used       free     shared    buffers     cached
Mem:       1014432     884460     129972      10168      43468     248580
-/+ buffers/cache:     592412     422020
Swap:      1046524     164376     882148
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;total: 总内存大小&lt;/li&gt;
&lt;li&gt;used: 已经使用的内存大小，包含 cached、buffers 和 shared 部分&lt;/li&gt;
&lt;li&gt;free: 空闲的内存大小&lt;/li&gt;
&lt;li&gt;shared: 进程间共享内存&lt;/li&gt;
&lt;li&gt;buffers: buffer cache&lt;/li&gt;
&lt;li&gt;cached: page cache&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-/+ buffers/cache 看作两部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;-buffers/cache：正在使用的内存大小，其值等于used1 减去 buffers1 再减去 cached1&lt;/li&gt;
&lt;li&gt;+buffers/cache：可用的内存大小，其值等于 free1 加上 buffers1 再加上 cached&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当空闲物理内存不多时，不一定表示系统运行状态很差，因为内存的 cached 及 buffers 部分可以随时被重用。swap 如果被频繁调用，bi 和 bo 长时间不为 0，才是内存资源是否紧张的依据。通过 free 看资源时，实际主要关注 -/+ buffers/cache 的值就可以知道内存到底够不够了。&lt;/p&gt;

&lt;h3&gt;valgrind&lt;/h3&gt;

&lt;p&gt;valgrind 是定位内存泄漏的好工具，使用 &lt;code&gt;valgrind --lead-check=full --log-file=valgrind.log ./a.out&lt;/code&gt; 即可在进程结束运行后输出内存泄露报告。&lt;/p&gt;

&lt;h3&gt;maps, smaps and status&lt;/h3&gt;

&lt;p&gt;参考这篇文章：&lt;a href=&quot;https://jameshunt.us/writings/smaps.html&quot;&gt;maps, smaps and Memory Stats!&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;pmap&lt;/h3&gt;

&lt;p&gt;待补充&lt;/p&gt;

&lt;h2&gt;IO 相关&lt;/h2&gt;

&lt;h3&gt;Buffers &amp;amp; Cached&lt;/h3&gt;

&lt;p&gt;Linux 利用虚拟内存极大的扩展了程序地址空间，使得原来物理内存不能容下的程序也可以通过内存和硬盘之间的不断交换（把暂时不用的内存页交换到硬盘，把需要的内存页从硬盘读到内存）来赢得更多的内存，看起来就像物理内存被扩大了一样。如果数据不在内存里就引起一个缺页中断（Page Fault），然后从硬盘读取缺页，并把缺页缓存到物理内存里。缺页中断可分为主缺页中断（Major Page Fault）和次缺页中断（Minor Page Fault），要&lt;strong&gt;从磁盘读取数据而产生的中断是主缺页中断&lt;/strong&gt;；数据已经被读入内存并被缓存起来，&lt;strong&gt;从内存缓存区中而不是直接从硬盘中读取数据而产生的中断是次缺页中断&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;从内存缓存区（页高速缓存）读取页比从硬盘读取页要快得多，所以 Linux 内核希望能尽可能产生次缺页中断（从页高速缓存读），并且尽可能避免主缺页中断（从硬盘读），这样随着次缺页中断的增多，缓存区也逐步增大，直到系统只有少量可用物理内存的时候 Linux 才开始释放一些不用的页。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ cat /proc/meminfo
MemTotal:        1014432 kB
MemFree:          137884 kB
Buffers:           43732 kB
Cached:           248744 kB
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这台服务器总共有 10GB 物理内存（MemTotal），1GB 左右可用内存（MemFree），43 MB 左右用来做磁盘缓存（Buffers），248 MB 左右用来做文件缓存区（Cached）。&lt;/p&gt;

&lt;p&gt;Linux 中内存页面有三种类型：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Read pages: 只读页（或代码页），通过主缺页中断从硬盘读取的页面，包括不能修改的静态文件、可执行文件、库文件等。当内核需要它们的时候把它们读到内存中，当内存不足的时候，内核就释放它们到空闲列表，当程序再次需要它们的时候需要通过缺页中断再次读到内存。&lt;/li&gt;
&lt;li&gt;Dirty pages: 脏页，指在内存中被修改过的数据页，比如文本文件等。这些文件由 pdflush 负责同步到硬盘，内存不足的时候由 kswapd 和 pdflush 把数据写回硬盘并释放内存。&lt;/li&gt;
&lt;li&gt;Anonymous pages: 匿名页，属于某个进程但是又和任何文件无关联，不能被同步到硬盘上，内存不足的时候由 kswapd 负责将它们写到交换分区并释放内存。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;顺序 IO 和 随机 IO&lt;/h3&gt;

&lt;p&gt;IO 可分为顺序 IO 和 随机 IO 两种。顺序 IO 重视每次 IO 的吞吐能力（KB per IO），而随机 IO 重视的是每秒能 IOPS 的次数，而不是每次 IO 的吞吐能力（KB per IO）。&lt;/p&gt;

&lt;h3&gt;Swap&lt;/h3&gt;

&lt;p&gt;当系统没有足够物理内存来应付所有请求的时候就会用到 swap 设备，swap 设备可以是一个文件，也可以是一个磁盘分区。使用 swap 的代价非常大，如果系统没有物理内存可用，就会频繁 swapping。如果 swap 设备和程序正要访问的数据在同一个文件系统上，那会碰到严重的 IO 问题，最终导致整个系统迟缓，甚至崩溃。swap 设备和内存之间的 swapping 状况是判断 Linux 系统性能的重要参考，我们已经有很多工具可以用来监测 swap 和 swapping 情况，比如：top、cat /proc/meminfo、vmstat。&lt;/p&gt;

&lt;h2&gt;Network 相关&lt;/h2&gt;

&lt;h3&gt;iptraf&lt;/h3&gt;

&lt;p&gt;两台主机之间有网线（或无线）、路由器、交换机等设备，测试两台主机之间的网络性能的一个办法就是在这两个系统之间互发数据并统计结果，看看吞吐量、延迟、速率如何。iptraf 就是一个很好的查看本机网络吞吐量的好工具。&lt;/p&gt;

&lt;h3&gt;tcpdump&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;sudo tcpdump -i eth0 port 80  -w output.dump    // 指定端口
sudo tcpdump -i eth0 src port 80                // 指定源端口
sudo tcpdump -i eth0 dst port 80                // 指定目的端口
sudo tcpdump -i eth0 src host 192.168.1.1       // 指定源地址
sudo tcpdump -i eth0 dst host 192.168.1.1       // 指定目的地址
sudo tcpdump -i eth0 tcp                        // 协议过滤
sudo tcpdump -i eth0 udp                        // 协议过滤
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;netstat&lt;/h3&gt;

&lt;p&gt;使用 netstat 实时监控 udp 网络收发包情况：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ watch netstat -su

IcmpMsg:
    InType0: 19
    InType3: 55
    InType8: 918828
    InType11: 5
    OutType0: 918828
    OutType3: 55
    OutType8: 20
Udp:
    101881 packets received
    51 packets to unknown port received.
    0 packet receive errors  // 关注该项 如果持续增长，说明在丢包。网卡收到了，但是应用层来不及处理
    164740 packets sent
UdpLite:
IpExt:
    InNoRoutes: 8
    OutMcastPkts: 2
    InBcastPkts: 1938486
    InOctets: 26851362935
    OutOctets: 18903227033
    OutMcastOctets: 80
    InBcastOctets: 300768203
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;常用工具汇总&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;工具&lt;/th&gt;
&lt;th&gt;简单介绍&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;top&lt;/td&gt;
&lt;td&gt;查看进程活动状态以及一些系统状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;vmstat&lt;/td&gt;
&lt;td&gt;查看系统状态、硬件和系统信息等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;iostat&lt;/td&gt;
&lt;td&gt;查看CPU 负载，硬盘状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sar&lt;/td&gt;
&lt;td&gt;综合工具，查看系统状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mpstat&lt;/td&gt;
&lt;td&gt;查看多处理器状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;netstat&lt;/td&gt;
&lt;td&gt;查看网络状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;iptraf&lt;/td&gt;
&lt;td&gt;实时网络状况监测&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tcpdump&lt;/td&gt;
&lt;td&gt;抓取网络数据包，详细分析&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tcptrace&lt;/td&gt;
&lt;td&gt;数据包分析工具&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;netperf&lt;/td&gt;
&lt;td&gt;网络带宽工具&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dstat&lt;/td&gt;
&lt;td&gt;综合工具，综合了 vmstat, iostat, ifstat, netstat 等多个信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;相关资料&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.thomas-krenn.com/en/wiki/Linux_Performance_Measurements_using_vmstat&quot;&gt;《Linux Performance Measurements using vmstat》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://linuxwiki.github.io/NetTools/tcpdump.html&quot;&gt;《tcpdump使用技巧》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/&quot;&gt;《Perf -- Linux下的系统性能调优工具》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.51testing.com/html/56/490256-3711169.html&quot;&gt;《通过/proc查看Linux内核态调用栈来定位问题》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://linuxtools-rst.readthedocs.io/zh_CN/latest/advance/03_optimization.html&quot;&gt;《Linux性能优化》&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Feb 2017 22:57:39 +0800</pubDate>
        <link>http://masutangu.com/2017/02/linux-performance-monitor/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/02/linux-performance-monitor/</guid>
        
        
        <category>工作</category>
        
      </item>
    
      <item>
        <title>我的 2016</title>
        <description>&lt;p&gt;时间飞逝，又到了写年终总结的时候了。翻回看去年的总结和展望，回想起去年的雄心壮志，今年则是坎坷、困惑与焦虑的一年。&lt;/p&gt;

&lt;h1&gt;回顾过去&lt;/h1&gt;

&lt;p&gt;在这整整一年中，我所思考的和困扰的，可以由三个词来概括：&lt;strong&gt;成绩&lt;/strong&gt;、&lt;strong&gt;成长&lt;/strong&gt;和&lt;strong&gt;价值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;工作已经两年半，对自己目前取得的成绩，对自己技术成长的预期，对自己为团队创造的价值，实话实说，都不满意。&lt;/p&gt;

&lt;p&gt;从今年年初开始，我就有点焦虑，觉得自己没有太多的成长，一直在原地踏步，已经没有刚入职时那种回顾过去会觉得自己突飞猛进的感觉（工作后做的每个比较大的需求，我都会整理保存下来 ppt，回看时就会清楚自己相比起过去进步了多少）。困于瓶颈期时，我尝试更加主动的去做事情。在那段时间，我开始关注些不仅仅是技术上的知识，例如关注了&lt;a href=&quot;https://wanqu.co/&quot;&gt;《湾区日报》&lt;/a&gt;，做了些读书笔记&lt;a href=&quot;http://masutangu.com/2015/12/dewdrop-note-1/&quot;&gt;《水滴石穿》&lt;/a&gt;。那段时间有些收获，但当我尝试把我阅读中收获的这些想法，运用到工作中时，却发现有层层阻碍。其中细节就不展开了，这让我非常沮丧。一方面，我理解在大公司工作，最重要是“稳”。有新的方案，新的想法，首要考虑的不是这个新的方案、新的想法的收益，而是运维成本。另一方面，这也让我觉得在大公司工作非常乏味，每个人的贡献都是固定的，尤其是工程师，你的定位就是执行者。公司也已经有很多很成熟的组件，即使不太适应于业务场景，也能勉强用用，你的工作就是做做接入，其它不需要操心。&lt;/p&gt;

&lt;p&gt;这种状况让我觉得非常的不适应。在学生时代，每一阶段、每个学期你都会学习到新的知识。而在工作中，更多的时候你是在重复做些体力活，例如，复制粘贴的完成一些需求。又例如，一遍遍的用已经成熟的方案去解决一些问题。而我其实不太喜欢这样的工作方式。我蛮希望自己是一个比较有创造力的工程师，我倾向于用不同的方案去完成类似的需求，通过真正的实践来对比不同的方案的优劣性。但在大公司来说，&lt;strong&gt;进度&lt;/strong&gt;和&lt;strong&gt;稳定性&lt;/strong&gt;是首要目标。只有在发展迅猛的前沿/明星项目中，你才有可能遇到各种新的问题，才有得到锻炼的机会。&lt;/p&gt;

&lt;p&gt;互联网不是按照工龄来排资论辈，同样工作三五年，差距可能非常大。有一句话说得好，&lt;strong&gt;“Good judgment comes from experience, experience comes from bad judgment.”&lt;/strong&gt;（正确的判断来自于丰富的经验,而丰富的经验来自错误的判断）。如果工作中没有太多挑战，不能促使你学习进步以应对工作的要求，一味追求保守无法得到犯错踩坑进步的机会，那你就应该停下来思考自己的未来了。我非常不希望把工作当做是一个任务，我希望工作是融于生活的，能带给我挑战和战胜难题的动力，能带给我解决问题后的成就感。如果说做为工程师，工作于己如同体力劳动般每日重复，那和流水线工人又有什么区别呢？&lt;/p&gt;

&lt;p&gt;再一个让我不适应的，是大公司的考核机制。并不像在学生时代，你的排名和你考出来的成绩相关，和你上课积不积极听讲，有没经常举手回答问题，一点关系都没有。所以你的成绩很差，抱歉，是你不够努力，你知道是自己的原因，所以你会努力去学习让自己进步。工作则不是如此简单纯粹。由于工作中有挑战的难点并不多，每个人做的事情都差不多，那只好看谁做事比较积极主动（并非吐槽，我也非常理解）。而我不太喜欢“伪加班”，也希望工作完成后能有更多自己的时间去学习充电。因此，工作后自己取得的绩效非常平庸。我意识到再这样下去，职业生涯也许就这样了。做为一个已经不算新人的员工来说，我渴望做出成绩，希望能为团队贡献更多的价值。我觉得自己还有很多的能量，我能做的不仅仅是完成我手上的工作。我也意识需要到达一定的职位，才能去推动些什么，去改变些什么。但以我这平庸的考核，我对自己未来的发展不抱有太多的信心，所以我开始寻求改变。&lt;/p&gt;

&lt;p&gt;既然不想再在大公司做了，我开始寻找一些有意思的创业公司。在 v2ex 上逛的时候，&lt;a href=&quot;https://www.xiaohongshu.com/&quot;&gt;小红书&lt;/a&gt; 吸引了我的注意。CTO 来自前谷歌中国工程院副院长，团队很多海归名校的背景，非常有吸引力。在经过电面，飞到上海去面试后，我拿到了offer。然而犹豫再三，我还是放弃了。放弃的原因主要是因为我资历尚浅，5月份拿到 offer，那时我才工作了一年多，当时小红书的开发团队已经有几十人，已经算是个大团队了。但不得不说，面试官给我的感觉非常的好，如果是在更早期，团队还是小规模的时候，我一定愿意加入这样的团队。&lt;/p&gt;

&lt;p&gt;之后就在公司内部寻找些机会，7月份到了现在的游戏工作室。小团队，后台只有几个人，听起来很有成就感。转岗之前我也有点小担心，担心难以融入，担心过来后也是打打杂，幸好过来后发现多虑了。工作室给我的感觉，很明显，大家共同的目标就是把游戏做好。当然从做社交，到做游戏，一开始还是有些不适应。做社交，本质上是各类存储的设计。游戏则不太一样，复杂的都是在业务逻辑。&lt;/p&gt;

&lt;p&gt;下半年的工作，新的环境，新的方向。学习了新的后台框架，对比之前用的框架，自己造了个轮子，写了篇文章&lt;a href=&quot;http://masutangu.com/2016/08/simple-async-framework/&quot;&gt;《简单异步应用框架的实现》&lt;/a&gt;，对后台异步框架的设计有一些了解，不再局限于只会用框架了。浅读了 libuv 和 libco 的源码，同样写了两篇文章&lt;a href=&quot;http://masutangu.com/2016/10/libuv-source-code/&quot;&gt;《Libuv 源码阅读》&lt;/a&gt; 和 &lt;a href=&quot;http://masutangu.com/2016/10/learn-libco/&quot;&gt;《浅读 Libco》&lt;/a&gt;，对异步和协程两种模式都有了进一步的认识。之后，在日常查问题的时候，我意识到自己定位问题的能力有所缺失，主要是对 linux 的各种监控系统状态的命令还不熟悉，操作系统和网络的知识也忘掉差不多了，所以决定重新翻读下 《UNIX 环境高级编程》、《现代操作系统》，并结合 《Linux 内核设计与实现》，了解些操作系统的理论和实现，这个系列的文章&lt;a href=&quot;http://masutangu.com/2016/11/linux-kernel-serial-1/&quot;&gt;《Linux 内核系列－进程》&lt;/a&gt; 还没写完。&lt;/p&gt;

&lt;p&gt;经过这阵子的摸索，我明确了之后的突破点，找到了进步的方向。虽然说，这一年，我有很多困惑、迷茫和焦虑，心情经常非常差，情绪起伏也很大。我明白这些都是成长的必经之路，这么看来，这些起起伏伏，也是蛮值得的。&lt;/p&gt;

&lt;h1&gt;展望未来&lt;/h1&gt;

&lt;p&gt;新的一年，工作上认真努力，不必多说。这里来聊聊新的一年，个人方面，我想做些什么。&lt;/p&gt;

&lt;p&gt;今年我意识到，对于大多数项目来说，技术并不是最重要的，只要不出问题就好（虽然我热爱技术，但我也不得不承认这点）。那技术人员应该如何发挥更大的价值呢？&lt;/p&gt;

&lt;p&gt;我给自己定的目标是：&lt;strong&gt;提高核心竞争力&lt;/strong&gt;和&lt;strong&gt;变得更全面&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;提升技术能力，这是首要目标。我希望新的一年可以把基础打扎实了，作为后台开发，操作系统和网络知识要打牢。另外了解业界流行的中间件（消息队列、数据库等）的实现，比较深入的选择一个方向（游戏引擎、数据分析、图形学、编程语言等）去研究。&lt;/p&gt;

&lt;p&gt;另外在公司工作，技能点很容易变得非常窄。我希望自己可以变得更加全面，不希望把自己局限于后台开发，也不仅局限于技术。新的一年，我希望自己能够做一个上线的 side project 并用心运营。目前看来我应该会选择做一款独立游戏，技术上独立完成前台－接入层－后台的实现，也借此学习下游戏策划的一些思想，让自己更加了解游戏这个行业。&lt;/p&gt;

&lt;h1&gt;总结心得&lt;/h1&gt;

&lt;p&gt;今天读了陈皓的&lt;a href=&quot;http://coolshell.cn/articles/17583.html&quot;&gt;《技术人员的发展之路》&lt;/a&gt;，写的很好，推荐大家都读一读。这一年，有两句话，我经常对自己说的，一是：&lt;strong&gt;不忘初心&lt;/strong&gt;，二是：&lt;strong&gt;Pursue excellence, and success will follow&lt;/strong&gt; (追求卓越，成功就会如期而至)。&lt;/p&gt;

&lt;p&gt;不忘初心，是提醒自己，选择了计算机的道路，是因为我喜欢编程，喜欢创造。不要因为眼前的失意去妥协自己。希望自己工作三年，五年，十年，都能保持学生的心态。&lt;strong&gt;stay hungry, stay foolish&lt;/strong&gt;。 &lt;/p&gt;

&lt;p&gt;追求卓越，是因为我相信，让自己成为一个优秀的工程师，比拿到好的绩效更加重要。自己要为自己的职业生涯负责，更勇敢的去追求梦想。&lt;/p&gt;

&lt;p&gt;大公司工作，可以带给你光环，但自己要想清楚，去掉光环后，自己还剩下些什么。也许我们都是平凡人，但平凡人也希望做出稍微那么不平凡的成绩。2017 年，希望自己不留遗憾！&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Dec 2016 22:19:43 +0800</pubDate>
        <link>http://masutangu.com/2016/12/review/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/12/review/</guid>
        
        
        <category>随笔</category>
        
      </item>
    
      <item>
        <title>Linux 内核系列－文件系统和 IO</title>
        <description>&lt;p&gt;本系列文章为阅读《现代操作系统》和《Linux 内核设计与实现》所整理的读书笔记，源代码取自 Linux-kernel 2.6.34 版本并有做简化。&lt;/p&gt;

&lt;h1&gt;概念&lt;/h1&gt;

&lt;p&gt;如果能把文件看成是一种地址空间，那么就离理解文件不远了。（文件类似虚拟地址空间，相应的磁盘地址对应内存物理地址，通过 inode 来管理映射关系，类似页表的作用）。&lt;/p&gt;

&lt;h2&gt;文件系统的实现&lt;/h2&gt;

&lt;p&gt;文件系统存放在磁盘上。多数磁盘划分为一个或多个区，每个分区有一个独立的文件系统。磁盘的 0 号扇区称为主引导记录（MBR），用来引导计算机。在 MBR 结尾是分区表，给出每个分区的起始和结束地址。&lt;/p&gt;

&lt;p&gt;文件系统通常包含了超级块（包含文件系统的关键参数）、空闲空间管理、i节点、根目录以及文件存储区。&lt;/p&gt;

&lt;h3&gt;文件的实现&lt;/h3&gt;

&lt;p&gt;文件存储的实现关键问题是记录各个文件分别用到哪些磁盘块。&lt;/p&gt;

&lt;h4&gt;连续分配&lt;/h4&gt;

&lt;p&gt;最简单的分配方案是把每个文件作为一连串连续数据块存储在磁盘上。&lt;/p&gt;

&lt;h4&gt;链表分配&lt;/h4&gt;

&lt;p&gt;链表分配不会有磁盘碎片的问题，顺序读取非常方便，但随即存取却相当缓慢。而且由于指针占了一些字节，磁盘块存储数据的字节数不再是 2 的整数幂。&lt;/p&gt;

&lt;h4&gt;在内存中采用的链表分配&lt;/h4&gt;

&lt;p&gt;将每个磁盘块的指针放在内存的一张表中，可以解决上面的两个不足。随机存取虽然依然需要遍历，但不再需要任何磁盘引用。缺点在于整张表必须放在内存，对大磁盘来说（表太大）不太合适。&lt;/p&gt;

&lt;h4&gt;i 节点&lt;/h4&gt;

&lt;p&gt;最后一个解决方案是给每个文件赋予一个 i 节点，包含文件属性和文件块的磁盘地址。只有文件打开时，i 节点才会加载到内存。&lt;/p&gt;

&lt;h3&gt;目录的实现&lt;/h3&gt;

&lt;p&gt;对于 i 节点系统，目录项只包括文件名和相应的 i 节点号。查找文件名时，可以在每个目录使用散列表来加快查找速度。另外一种方法是将查找结果放入高速缓存。&lt;/p&gt;

&lt;h3&gt;虚拟文件系统&lt;/h3&gt;

&lt;p&gt;UNIX 使用虚拟文件系统的概念，关键思想在于抽象出所有文件系统的共有部分，把这部分代码放在单独的一层，该层调用底层的实际文件系统来管理数据。&lt;/p&gt;

&lt;h1&gt;Linux 中的实现&lt;/h1&gt;

&lt;h2&gt;虚拟文件系统&lt;/h2&gt;

&lt;p&gt;虚拟文件系统（VPS）作为内核子系统，为用户空间程序提供了文件系统相关的接口。通过虚拟文件系统，程序可以利用标准的 UNIX 文件系统调用对不同介质的不同文件系统进行读写操作。&lt;/p&gt;

&lt;h3&gt;通用文件系统接口&lt;/h3&gt;

&lt;p&gt;VFS 使用户可以直接使用 open()、read() 和 write() 这样的系统调用而无需考虑具体文件系统和实际物理介质。&lt;/p&gt;

&lt;h3&gt;文件系统抽象层&lt;/h3&gt;

&lt;p&gt;VFS 抽象层定义了所有文件系统都支持的基本的、概念上的接口和数据结构，因此能衔接各种各样的文件系统。&lt;/p&gt;

&lt;p&gt;在内核中，除了文件系统本身外，并不需要了解文件系统的内部细节。例如用户空间程序执行如下的操作：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;write(f, &amp;amp;buf, len);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;该代码将 &amp;amp;buf 指针指向的、长度为 len 字节的数据写入文件描述符 f 对应的文件的当前位置。该用户调用首先被一个通用系统调用 &lt;code&gt;sys_write()&lt;/code&gt; 处理，&lt;code&gt;sys_write()&lt;/code&gt; 函数要找到 f 所在的文件系统对应的写操作，然后执行该操作。&lt;/p&gt;

&lt;h3&gt;Unix 文件系统&lt;/h3&gt;

&lt;p&gt;Unix 使用了四种和文件系统相关的传统抽象概念：文件、目录项、索引节点和安装点（mount point）。从本质上讲，文件系统是特殊的数据分层存储结构，它包含文件、目录和相关的控制信息。文件系统的通用操作包含创建、删除和安装等等。在 Unix 中，文件系统被安装在一个特定的安装点上，该安装点在全局层次结构中被称为命名空间，所有的已安装文件系统都作为根文件系统树的枝叶出现在系统中。&lt;/p&gt;

&lt;p&gt;Unix 中，目录属于普通文件，它列出包含在其中的所有文件。因此可以对目录执行和文件相同的操作。 &lt;/p&gt;

&lt;p&gt;Unix 将文件的相关信息和文件本身着两个概念加以区分，例如访问控制权限、大小、拥有者、创建时间等信息。文件相关信息有时被称为索引节点（inode）。&lt;/p&gt;

&lt;p&gt;文件系统的控制信息存储在超级块中，超级块是一种包含文件系统信息的数据结构。我们将文件信息和文件系统的信息统称为文件系统数据元。&lt;/p&gt;

&lt;p&gt;Unix 文件系统在他们物理磁盘布局中也是按照上述的概念实现的。文件信息按照索引节点形式存储在单独的块中，控制信息集中存储在磁盘的超级块中。&lt;/p&gt;

&lt;h3&gt;VFS 对象及其数据结构&lt;/h3&gt;

&lt;p&gt;VFS 采用的是面向对象的设计思路，使用一族数据结构来代表通用文件对象。VFS 中有四个主要的对象类型：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;超级块对象，代表一个已安装文件系统&lt;/li&gt;
&lt;li&gt;索引节点对象，代表一个文件&lt;/li&gt;
&lt;li&gt;目录项对象，代表一个目录项，是路径的一个组成部分&lt;/li&gt;
&lt;li&gt;文件对象，代表进程打开的文件&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;超级块对象&lt;/h3&gt;

&lt;p&gt;各种文件系统都必须实现超级块，该对象用于存储特定文件系统信息，通常对应存放于磁盘特定扇区中的文件系统超级块或文件系统控制块。对于并非基于磁盘的文件系统，它们会在现场创建超级块并保存到内存中。&lt;/p&gt;

&lt;p&gt;超级块对象由 super_block 结构体表示，定义在文件 &lt;linux/fs.h&gt; 中。&lt;/p&gt;

&lt;h3&gt;索引节点对象&lt;/h3&gt;

&lt;p&gt;索引节点对象包含了内核在操作文件或目录时需要的全部信息，由 inode 结构体表示，定义在文件 &lt;linux/fs.h&gt; 中。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct inode {
    struct hlist_node   i_hash;
    struct list_head    i_list;     // 索引节点链表
    struct list_head    i_sb_list;  // 超级块链表
    struct list_head    i_dentry;   // 目录项链表
    unsigned long       i_ino;      // 节点号
    atomic_t            i_count;
    unsigned int        i_nlink;
    uid_t           i_uid;
    gid_t           i_gid;
    dev_t           i_rdev;         // 实际设备标识符
    unsigned int    i_blkbits;      // 以位为单位的块大小
    u64             i_version;
    loff_t          i_size;         // 以字节为单位的文件大小
#ifdef __NEED_I_SIZE_ORDERED
    seqcount_t      i_size_seqcount;
#endif
    struct timespec     i_atime;  // 最后访问时间
    struct timespec     i_mtime;  // 最后修改时间
    struct timespec     i_ctime;  // 最后改变时间
    blkcnt_t        i_blocks;     // 文件块数
    unsigned short  i_bytes;      // 使用的字节数
    umode_t         i_mode;       // 访问权限
    spinlock_t      i_lock; /* i_blocks, i_bytes, maybe i_size */
    struct mutex        i_mutex;
    struct rw_semaphore i_alloc_sem;
    const struct inode_operations   *i_op;  // 索引节点操作表
    const struct file_operations    *i_fop; /* former -&amp;gt;i_op-&amp;gt;default_file_ops */
    struct super_block  *i_sb;
    struct file_lock    *i_flock;
    struct address_space    *i_mapping;
    struct address_space    i_data;

    struct list_head    i_devices;
    union {
        struct pipe_inode_info  *i_pipe;
        struct block_device *i_bdev;
        struct cdev     *i_cdev;
    };
    unsigned long       i_state;
    unsigned long       dirtied_when;   // 第一次弄脏数据的时间
    unsigned int        i_flags;        // 文件系统标识
    atomic_t        i_writecount;       // 写者计数
    void            *i_private; /* fs or device private pointer */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;目录项对象&lt;/h3&gt;

&lt;p&gt;VFS 经常需要执行目录相关的操作，例如路径名查找等。路径名查找需要解析路径中的每一个组成部分。为了方便查找操作，VFS 引入目录项的概念。每个 dentry 代表路径中的一个特定部分。在路径中，包括普通文件在内，每一个部分都是目录项对象。&lt;/p&gt;

&lt;p&gt;目录项由对象 dentry 结构体表示，定义在文件 &lt;linux/dcache.h&gt; 中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct dentry {
    atomic_t d_count;       // 使用记账
    unsigned int d_flags;   /* protected by d_lock */
    spinlock_t d_lock;      /* per dentry lock */
    int d_mounted;
    struct inode *d_inode;      /* Where the name belongs to - NULL is * negative */
    /*
     * The next three fields are touched by __d_lookup.  Place them here
     * so they all fit in a cache line.
     */
    struct hlist_node d_hash;   // dcache中的所有dentry对象都通过d_hash指针域链到相应的dentry哈希链表中。
    struct dentry *d_parent;    /* parent directory */
    struct qstr d_name;

    struct list_head d_lru;     /* LRU list */
    /*
     * d_child and d_rcu can share memory
     */
    union {
        struct list_head d_child;   /* child of parent list */
        struct rcu_head d_rcu;
    } d_u;
    struct list_head d_subdirs; /* our children */
    struct list_head d_alias;   /* inode alias list */
    unsigned long d_time;       /* used by d_revalidate */
    const struct dentry_operations *d_op;
    struct super_block *d_sb;   /* The root of the dentry tree */
    void *d_fsdata;         /* fs-specific data */

    unsigned char d_iname[DNAME_INLINE_LEN_MIN];    /* small names */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;不同于前面的两个对象，目录项对象没有对应的磁盘数据结构，VFS 根据字符串形式的路径名现场创建它。&lt;/p&gt;

&lt;h4&gt;目录项状态&lt;/h4&gt;

&lt;p&gt;目录项对象有三种有效状态：被使用、未被使用和负状态。&lt;/p&gt;

&lt;p&gt;一个被使用的目录项对应一个有效的索引节点（d_inode 指向相应的索引节点）并表明该对象存在一个或多个使用者（d_count 为正值）。&lt;/p&gt;

&lt;p&gt;一个未被使用的目录项对应一个有效的索引节点（d_inode 指向一个索引节点）但 VFS 当前并未使用它（d_count 为 0)。该目录项对象仍然指向一个有效对象，而且被保留在缓存中以便需要时再使用。&lt;/p&gt;

&lt;p&gt;一个负状态的目录项没有对应的有效索引节点（d_inode 为 NULL），因为索引节点已被删除或路径不再正确。&lt;/p&gt;

&lt;h4&gt;目录项缓存&lt;/h4&gt;

&lt;p&gt;内核将目录项对象缓存在目录项缓存（dcache）中。目录项缓存包含三个主要部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;“被使用的”目录项链表：该链表通过索引节点对象中的 i_dentry 项连接相关的索引节点。一个给定的索引节点可能有多个链接，就可能有多个目录项对象，因此用链表来连接。&lt;/li&gt;
&lt;li&gt;“最近被使用的”双向链表：该链表含有未被使用的和负状态的目录项对象。该链表以时间顺序插入，所以链头的节点是最新数据。当内核必须通过删除节点项回收内存时，会从链尾删除节点项。&lt;/li&gt;
&lt;li&gt;散列表和相应的散列函数用来快速将给定路径解析为相关目录项对象。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;文件对象&lt;/h3&gt;

&lt;p&gt;文件对象表示进程已打开的文件，由结构体 file 表示，定义在文件 &lt;linux/fs.h&gt; 中。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct file {
    /*
     * fu_list becomes invalid after file_free is called and queued via
     * fu_rcuhead for RCU freeing
     */
    union {
        struct list_head    fu_list;    // 文件对象链表
        struct rcu_head     fu_rcuhead; // 释放后 rcu 链表
    } f_u;
    struct path     f_path;   // 包含目录项
#define f_dentry    f_path.dentry
#define f_vfsmnt    f_path.mnt
    const struct file_operations    *f_op;  // 文件操作表
    spinlock_t      f_lock;   /* f_ep_links, f_flags, no IRQ */
    atomic_long_t   f_count;  // 文件对象使用计数
    unsigned int    f_flags;  //打开文件指定的标志位
    fmode_t         f_mode;   // 文件访问模式
    loff_t          f_pos;    // 文件当前的位移量
    struct fown_struct  f_owner;
    u64         f_version;
    struct address_space    *f_mapping;  // 页缓存映射
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;文件对象通过 f_dentry 指针指向相关的目录项对象，目录项会指向相关的索引节点，索引节点会记录文件是否为脏。&lt;/p&gt;

&lt;h3&gt;文件系统相关的数据结构&lt;/h3&gt;

&lt;p&gt;struct file_system_type 用来描述每种文件系统的功能和行为：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct file_system_type {
    const char *name;               /* 文件系统的名字 */
    int fs_flags;                   /* 文件系统类型标志 */

    /* 从磁盘读取超级块 */
    int (*get_sb) (struct file_system_type *, int,
               const char *, void *, struct vfsmount *);

    /* 终止访问超级块 */
    void (*kill_sb) (struct super_block *);

    struct module *owner;           /* 文件系统模块 */
    struct file_system_type * next; /* 链表中下一个 */
    struct list_head fs_supers;     /* 超级块对象链表 */

};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;当文件系统被实际安装时，将有一个 vfsmount 结构体在安装点被创建。该结构体用来代表文件系统的实例：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct vfsmount {
    struct list_head mnt_hash;
    struct vfsmount *mnt_parent;    /* fs we are mounted on */
    struct dentry *mnt_mountpoint;  /* dentry of mountpoint */
    struct dentry *mnt_root;    /* root of the mounted tree */
    struct super_block *mnt_sb; /* pointer to superblock */
    struct list_head mnt_mounts;    /* list of children, anchored here */
    struct list_head mnt_child; /* and going through their mnt_child */
    int mnt_flags;
    /* 4 bytes hole on 64bits arches */
    const char *mnt_devname;    /* Name of device e.g. /dev/dsk/hda1 */
    struct list_head mnt_list;
    struct mnt_namespace *mnt_ns;   /* containing namespace */
    int mnt_id;         /* mount identifier */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;进程相关的数据结构&lt;/h3&gt;

&lt;p&gt;有三个数据结构将 VFS 层和系统进程紧密联系在一起，分别是：files_struct、fs_struct 和 namespace 结构体。&lt;/p&gt;

&lt;p&gt;files_structt 结构体定义在文件 &lt;linux/file.h&gt; 中。该结构体由进程描述符中的 files 域指向。所有与每个进程（per-process）相关的信息如果打开的文件和文件描述符都在其中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct fdtable {
    unsigned int max_fds;
    struct file ** fd;      /* current fd array */
    fd_set *close_on_exec;
    fd_set *open_fds;
    struct rcu_head rcu;
    struct fdtable *next;
};

struct files_struct {
  /*
   * read mostly part
   */
    atomic_t count;
    struct fdtable *fdt;
    struct fdtable fdtab;
    int next_fd;
    struct embedded_fd_set close_on_exec_init;
    struct embedded_fd_set open_fds_init;
    struct file * fd_array[NR_OPEN_DEFAULT];
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;fd 数组指针指向已打开的文件对象链表，默认情况下指向 fd_array 数组。因为 NR_OPEN_DEFAULT 等于 32，如果一个进程打开的文件对象超过 32 个，内核将分配一个新数组并将 fd 指针指向它。&lt;/p&gt;

&lt;p&gt;下图是 APUE 中进程打开文件的图例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linux-kernel-serial-5/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中 process table entry 表项对应 files_struct 对象，file table 表项对应 file 对象，v-node table 表项可以看成两部分，一部分是文件操作函数的指针，由 file 对象的 f_op 字段指向，另一部分 inode 信息，由 file 对象的 f_dentry 字段指向的目录项对象的 d_inode 关联到相关的 inode 节点：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linux-kernel-serial-5/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;注：上图取自&lt;a href=&quot;https://www.zhihu.com/question/39148572&quot;&gt;知乎&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;和进程相关的第二个结构体是 fs_struct。该结构由进程描述符 fs 域指向。它包含文件系统和进程相关的信息，定义在 &lt;linux/fs_struct.h&gt; 中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct path {
    struct vfsmount *mnt;
    struct dentry *dentry;
};

struct fs_struct {
    int users;                  /* 结构的使用计数 */
    rwlock_t lock;   
    int umask;                  /* 默认的文件访问权限 */
    int in_exec;             
    struct path root, pwd;     /* 根目录和当前目录的目录项对象和安装点对象 */  
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;最后一个结构体是 mnt_namespace，定义在 &lt;linux/mnt_namespace.h&gt; 中，由进程描述符中的 namespace 指向。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct mnt_namespace {
    atomic_t        count;          /* 结构的使用计数 */
    struct vfsmount *   root;       /* 根目录的安装点对象 */
    struct list_head    list;       /* 安装点链表 */
    wait_queue_head_t poll; 
    int event;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;对大多数进程来说，它们的描述符会指向唯一的 files_struct 和 fs_struct 结构体。对于使用克隆标志 CLONE_FILES 或 CLONE_FS 创建的进程，会共享这两个结构体。所以多个进程描述符可能会指向同一个 files_struct 或 fs_struct 结构体。因此每个结构体维护一个 count 域（或 users 域）作为引用计数。&lt;/p&gt;

&lt;p&gt;namespace 结构体则不同，默认情况下，所有进程共享同样的命名空间。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://bean-li.github.io/vfs-inode-dentry/&quot;&gt;http://bean-li.github.io/vfs-inode-dentry/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://unicornx.github.io/2016/03/20/20160320-lk-vfs/&quot;&gt;http://unicornx.github.io/2016/03/20/20160320-lk-vfs/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;APUE 对应进程打开文件的图例&lt;/p&gt;

&lt;h2&gt;块 I/O 层&lt;/h2&gt;

&lt;p&gt;系统能随机访问固定大小数据片（chunk）的设备被称作块设备。另一种基本的设备类型是字符设备，字符设备按照字符流的方式被有序访问，例如串口和键盘。&lt;/p&gt;

&lt;h3&gt;解剖一个块设备&lt;/h3&gt;

&lt;p&gt;块设备中最小的可寻址单元是扇区（sector）。扇区大小一般是 2 的整数倍，最常见的大小是 512 个字节。扇区的大小是设备的物理属性，扇区是所有块设备的基本单元，块设备无法对它还小的单元进行寻址的操作。&lt;/p&gt;

&lt;p&gt;最小逻辑可寻址单元是块（block）。块是文件系统的抽象，只能基于块来访问文件系统。虽然物理磁盘寻址是按照扇区级进行的，但内核执行的所有磁盘操作都是按照块进行的。对块大小的要求是：必须是扇区大小的 2 的整数倍，并且要小于页面大小。所以块大小通常为 512 字节、1K 或 4K。&lt;/p&gt;

&lt;h3&gt;缓冲区和缓冲区头&lt;/h3&gt;

&lt;p&gt;当块被调入内存时，它要存储在一个缓冲区中。缓冲区相当于磁盘块在内存中的表示。由于内核在处理数据时需要一些相关的控制信息（比如块属于哪一个块设备，对于哪个缓冲区等），所以每个缓冲区都有一个对应的描述符，由 buffer_head 结构体表示，称为缓冲区头，在 &lt;linux/buffer_head.h&gt; 中定义。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct buffer_head {
    unsigned long b_state;      /* buffer state bitmap (see above) */
    struct buffer_head *b_this_page;/* circular list of page&amp;#39;s buffers */
    struct page *b_page;        /* the page this bh is mapped to */

    sector_t b_blocknr;     /* start block number */
    size_t b_size;          /* size of mapping */
    char *b_data;           /* pointer to data within the page */

    struct block_device *b_bdev;
    bh_end_io_t *b_end_io;      /* I/O completion */
    void *b_private;        /* reserved for b_end_io */
    struct list_head b_assoc_buffers; /* associated with another mapping */
    struct address_space *b_assoc_map;  /* mapping this buffer is
                           associated with */
    atomic_t b_count;       /* users using this buffer_head */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;与缓冲区对应的磁盘物理块由 b_blocknr 域索引，该值是 b_bdev 域指明的块设备中的逻辑块号。&lt;/p&gt;

&lt;p&gt;与缓冲区对应的内存物理页由 b_page 域表示，另外 b_data 域直接指向相应的块（它位于 b_page 域所指明的页面的某个位置上）。块的大小由 b_size 域表示，所以块在内存中的起始位置在 b_data 处，结束位置在 (b_data + b_size) 处。&lt;/p&gt;

&lt;h3&gt;bio 结构体&lt;/h3&gt;

&lt;p&gt;内核中块 I/O 操作的基本容器由 bio 结构体表示，定义在文件 &lt;linux/bio.h&gt; 中。&lt;/p&gt;

&lt;p&gt;每个块 I/O 请求都通过一个 bio 结构体表示。每个请求包含了一个或多个块，这些块存储在 bio_vec 结构体数组中。这些结构体描述了每个片段在物理页中的实际位置，并且像 vector 一样被组织在一起。I/O 操作的第一个片段由 b_io_vec 结构体所指向，共有 bi_vcnt 个片段。当块 I/O 层开始执行请求、需要使用各个片段时，bi_idx 域会不断更新，从而指向当前片段。&lt;/p&gt;

&lt;p&gt;buffer_head 和 bio 结构体之间存在明显差别。bio 结构体代表的是 I/O 操作，它可以包含内存中的一个或多页；而另一方面，buffer_head 结构体代表的是一个缓冲区，它描述的仅仅是磁盘中的一个块。因为缓冲区头关联的是单独页中的单独磁盘块，所以它可能会引起不必要的分割，将请求按块为单位划分。bio 则不需要连续存储区，也不需要分割 I/O 操作。&lt;/p&gt;

&lt;h3&gt;请求队列&lt;/h3&gt;

&lt;p&gt;块设备将它们挂起的块 I/O 请求保存在请求队列中，该队列由 reques_queue 结构体表示，定义在 &lt;linux/blkdev.h&gt; 中，包含一个双向请求链表以及相关控制信息。请求队列表中的每一项都是一个单独的请求，由 request 结构体表示。一个请求可能要操作多个连续的磁盘块，所以每个请求可以由多个 bio 结构体组成。&lt;/p&gt;

&lt;h3&gt;I/O 调度程序&lt;/h3&gt;

&lt;p&gt;磁盘寻址是整个计算机中最慢的操作之一，缩短寻址时间是提高系统性能的关键。为了优化寻址操作，内核会在提交任务前先执行合并与排序的预操作。在内核中负责提交 I/O 请求的子系统称为 I/O 调度程序。&lt;/p&gt;

&lt;h4&gt;I/O 调度程序的工作&lt;/h4&gt;

&lt;p&gt;I/O 调度程序的工作是管理块设备的请求队列。I/O 调度程序通过&lt;strong&gt;合并&lt;/strong&gt;和&lt;strong&gt;排序&lt;/strong&gt;来减少磁盘寻址时间。&lt;/p&gt;

&lt;h4&gt;Linus 电梯&lt;/h4&gt;

&lt;p&gt;第一个 I/O 调度程序被称为 Linus 电梯。当有新的请求加入队列时，会先检查每一个挂起的请求是否可以和新请求合并。Linus 电梯 I/O 调度程序可以执行向前和向后合并。如果合并失败，那就需要寻找可能的插入点。如果找到就插入，如果没合适的位置，那么新请求就被加入到队列尾部。另外如果队列中有驻留时间过长的请求，那么新请求也将被加入到队列尾部，即使插入后还要排序。这是为了避免由于访问相近磁盘位置的请求太多，从而造成访问磁盘其他位置的请求难以得到执行机会。&lt;/p&gt;

&lt;h4&gt;最终期限 I/O 调度程序&lt;/h4&gt;

&lt;p&gt;最终期限 I/O 调度程序中，每个请求都有一个超时时间。默认情况下，读请求的超时时间是 500 毫秒，写请求的超时时间是 5 秒。最终期限 I/O 调度请求类似于 Linus 电梯，也以磁盘物理位置次序维护请求队列，这个队列称为排序队列。但同时也会根据请求类型将它们插入到额外队列中。读请求按次序被插入特定的读 FIFO 队列中，写请求被插入到特定的写 FIFO 队列中。一般情况下，调度程序从排序队列头部取出请求，再推入到派发队列中。如果在写／读 FIFO 队列头的请求超时，那么调度程序便从 FIFO 队列中提取请求。&lt;/p&gt;

&lt;h2&gt;页高速缓存和页回写&lt;/h2&gt;

&lt;p&gt;页高速缓存是 Linux 内核实现的一种主要磁盘缓存。它主要用来减少对磁盘的 I/O 操作。具体来讲，是通过把磁盘中的数据缓存到物理内存，把对磁盘的访问变成对物理内存的访问。&lt;/p&gt;

&lt;p&gt;页高速缓存是由 RAM 中的物理页组成，每一页都对应磁盘多个块。每当内核开始执行一个页 I/O 操作时，首先会检查需要的数据是否在高速缓存中，如果在，则直接使用高速缓存中的数据。&lt;/p&gt;

&lt;p&gt;也可以通过块 I/O 缓冲区把独立的磁盘块与页高速缓存联系在一起。通过缓存磁盘块以及缓冲块 I/O 操作，页高速缓存同样可以减少块 I/O 操作期间的磁盘访问量。这种缓存通常称为“缓冲区高速缓存”，也是页高速缓存中的一部分。&lt;/p&gt;

&lt;h3&gt;页高速缓存&lt;/h3&gt;

&lt;p&gt;页高速缓存包含了最近被访问过的文件的全部页面，在执行 I/O 操作前，内核会检查数据是否已经在页高速缓存中了，如果在，则不再需要从磁盘读取数据。&lt;/p&gt;

&lt;h4&gt;address_space 对象&lt;/h4&gt;

&lt;p&gt;一个物理页可能由多个不连续的物理磁盘块组成，所以在页高速缓存中检测特定数据是否已经被缓存是件非常困难的工作。&lt;/p&gt;

&lt;p&gt;Liunx 页高速缓存使用 address_space 结构体描述页高速缓存中的页面。该结构定义在 &lt;linux/fs.h&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct address_space {
    struct inode            *host;      /* owner: inode, block_device */
    struct radix_tree_root  page_tree;  /* radix tree of all pages */
    spinlock_t              tree_lock;  /* and lock protecting it */
    unsigned int            i_mmap_writable;/* count VM_SHARED mappings */
    struct prio_tree_root   i_mmap;     /* tree of private and shared mappings */
    struct list_head        i_mmap_nonlinear;/*list VM_NONLINEAR mappings */
    spinlock_t              i_mmap_lock;    /* protect tree, count, list */
    unsigned int            truncate_count; /* Cover race condition with truncate */
    unsigned long           nrpages;    /* number of total pages */
    pgoff_t                 writeback_index;/* writeback starts here */
    const struct address_space_operations *a_ops;   /* methods */
    unsigned long           flags;      /* error bits/gfp mask */
    struct backing_dev_info *backing_dev_info; /* device readahead, etc */
    spinlock_t              private_lock;   /* for use by the address_space */
    struct list_head        private_list;   /* ditto */
    struct address_space    *assoc_mapping; /* ditto */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;i_mmap 字段是个优先搜索树，它的搜索范围包含了在 address_space 中所有共享和私有的映射页面。address_space 结构往往会和某些内核对象关联。通常会与一个索引节点（inode）关联，这时 host 域就指向该索引节点，该索引节点的 i_mapping 域指向到 address_space 对象，方便查找自身文件数据是否已经缓存。&lt;/p&gt;

&lt;p&gt;a_ops 域指向地址空间对象中的操作函数表。&lt;/p&gt;

&lt;p&gt;struct page 中有两个字段：mapping 和 index。其中 mapping 指向该页所有者的 address_space，index 字段表示所有者地址空间中以页大小为单位的偏移量。用这两个字段就能在页高速缓存中查找。&lt;/p&gt;

&lt;p&gt;页高速缓存通过两个参数：address_space 对象和一个偏移量进行搜索。每个 address_space 对象都有唯一一个基树，保存在 page_tree 结构体中。基树是一个二叉树，只要指定了文件偏移量，就可以在基树中迅速检索到希望的数据。&lt;/p&gt;

&lt;p&gt;inode、address space 和 page 三者的关系如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linux-kernel-serial-5/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h1&gt;Linux 中的 I/O 机制&lt;/h1&gt;

&lt;h2&gt;Buffered I/O&lt;/h2&gt;

&lt;p&gt;Buffered I/O 指的是在内核和用户程序之间设置了一层缓冲区，用来提高IO读写的效率：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读取：硬盘---&amp;gt;内核缓冲区---&amp;gt;用户缓冲区---&amp;gt;用户程序&lt;/li&gt;
&lt;li&gt;写回：用户程序---&amp;gt;用户缓冲区---&amp;gt;内核缓冲区---&amp;gt;硬盘&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Unbuffered I/O&lt;/h2&gt;

&lt;p&gt;Unbuffered I/O 没有用户缓冲区，&lt;strong&gt;注意内核缓冲区仍然存在&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读取：硬盘---&amp;gt;内核缓冲区---&amp;gt;用户程序&lt;/li&gt;
&lt;li&gt;写回：用户程序---&amp;gt;内核缓冲区---&amp;gt;硬盘&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Direct IO&lt;/h2&gt;

&lt;p&gt;Direct I/O 是真正的什么缓冲区都没有，直接与硬盘交互：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读取：硬盘---&amp;gt;用户程序&lt;/li&gt;
&lt;li&gt;写回：用户程序---&amp;gt;硬盘&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用带有内核缓冲区的 I/O（Buffer I/O 和 Unbuffer I/O），DMA 方式可以将数据直接从磁盘读到页缓存中，或者将数据从页缓存直接写回到磁盘上，而不能直接在应用程序地址空间和磁盘之间进行数据传输。数据在传输过程中需要在应用程序地址空间和页缓存之间进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。&lt;/p&gt;

&lt;p&gt;Direct I/O 最主要的优点就是通过减少操作系统内核缓冲区和应用程序地址空间的数据拷贝次数，降低了对文件读取和写入时所带来的 CPU 的使用以及内存带宽的占用。&lt;/p&gt;
</description>
        <pubDate>Fri, 16 Dec 2016 21:37:16 +0800</pubDate>
        <link>http://masutangu.com/2016/12/linux-kernel-serial-5/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/12/linux-kernel-serial-5/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>Linux 内核系列－内存管理</title>
        <description>&lt;p&gt;本系列文章为阅读《现代操作系统》和《Linux 内核设计与实现》所整理的读书笔记，源代码取自 Linux-kernel 2.6.34 版本并有做简化。&lt;/p&gt;

&lt;h1&gt;概念&lt;/h1&gt;

&lt;p&gt;操作系统存储管理方案的演进：&lt;/p&gt;

&lt;h2&gt;无存储抽象&lt;/h2&gt;

&lt;p&gt;早期计算机并没有存储抽象，程序直接访问物理内存地址。使用这种模型，想要同时运行多个程序非常困难。&lt;/p&gt;

&lt;h2&gt;存储抽象：地址空间&lt;/h2&gt;

&lt;h3&gt;地址空间的概念&lt;/h3&gt;

&lt;p&gt;要保证多个应用程序同时处于内存并且互不影响，则需要解决两个问题：&lt;strong&gt;保护&lt;/strong&gt;和&lt;strong&gt;重定位&lt;/strong&gt;。内存块加上保护键并通过装载时重定位程序虽然可以做到，但是是个缓慢和复杂的解决方案。一个更好的方法是创造一个新的内存抽象：地址空间。地址空间是一个进程可用于寻址内存的一套地址集合。进程的地址空间独立于其他进程的地址空间。&lt;/p&gt;

&lt;h3&gt;交换技术&lt;/h3&gt;

&lt;p&gt;有两种处理内存超载的通用方法，最简单的策略是交接（swapping）技术，即把一个进程完整调入内存，运行一段时间后，存回磁盘。另一种策略是虚拟内存。&lt;/p&gt;

&lt;h3&gt;空闲内存管理&lt;/h3&gt;

&lt;p&gt;在动态分配内存时，操作系统通常有两种方式跟踪内存使用情况：&lt;strong&gt;位图&lt;/strong&gt;和&lt;strong&gt;空闲链表&lt;/strong&gt;。&lt;/p&gt;

&lt;h2&gt;虚拟内存&lt;/h2&gt;

&lt;p&gt;虚拟内存的基本思想是：每个程序拥有自己的地址空间，这个空间被分割为许多块，每一块被称为页面（page）。这些页被映射到物理内存，但不是所有页都在内存才能运行程序。&lt;/p&gt;

&lt;h3&gt;分页&lt;/h3&gt;

&lt;p&gt;大部分虚拟内存系统都使用了&lt;strong&gt;分页&lt;/strong&gt;技术。程序产生的地址称为虚拟地址，访问时不是直接由内存总线处理，而是通过内存管理单元（MMU)，MMU 把虚拟地址映射到物理内存。&lt;/p&gt;

&lt;p&gt;虚拟地址空间按照固定大小划分页面，物理内存对应的单元称为页框（page frame）。页面和页框的大小通常是一样的。RAM 和磁盘之间的交换总是以整个页面为单元进行的。&lt;/p&gt;

&lt;p&gt;当进程访问了一个未映射的页面，MMU 注意到该页面没有被映射，于是使 CPU 陷入到操作系统（缺页中断），操作系统找到一个很少使用的页框，将其内容写入磁盘，并把需要访问的页面的内容读到该页框中，修改映射关系后，重新启动引起陷进的指令。&lt;/p&gt;

&lt;h3&gt;页表&lt;/h3&gt;

&lt;p&gt;页表的简单实现：虚拟地址被分成&lt;strong&gt;虚拟页号&lt;/strong&gt;（高位部分）和&lt;strong&gt;偏移量&lt;/strong&gt;（低位部分）。虚拟页号可用作页表的索引，以找到相应的页表项。由页表项可以找到页框号。页框号加上偏移量就是实际的内存物理地址。&lt;/p&gt;

&lt;p&gt;页表项的结构同城包含页框号、“在／不在”位、“保护”位（读写执行权限）、“修改”位、“访问”位和“高速缓存禁止”位。&lt;/p&gt;

&lt;p&gt;若页面不在内存时，该页面对应的磁盘地址不是页表的一部分。这部分信息保存在操作系统内部的软件表格中，硬件不需要。&lt;/p&gt;

&lt;h3&gt;加速分页过程&lt;/h3&gt;

&lt;p&gt;大多数程序总是对少量页面进行多次访问，因此优化方案是为计算机配置一个小型硬件设备 TLB，将虚拟地址直接映射成物理地址，而不必访问页表。&lt;/p&gt;

&lt;h3&gt;针对大内存的页表&lt;/h3&gt;

&lt;p&gt;64位机器上，多级页表不是个好主意。解决方案之一是使用倒排页表。在这种设计中，每一个页框有一个表项，而不是每个页面有一个表项。倒排页表的不足在于从虚拟地址到物理地址的转换变得很困难。可以通过 TLB 和散列表来提升效率。&lt;/p&gt;

&lt;h2&gt;分页系统中的设计问题&lt;/h2&gt;

&lt;h3&gt;分离的指令空间和数据空间&lt;/h3&gt;

&lt;p&gt;大多数计算机只有一个地址空间，即存放程序也存放数据。如果地址空间太小的话，PDP-11的解决方案是为指令和数据设置分离的地址空间，分别称为 I 空间和 D 空间。此时链接器必须将数据重定位到虚拟地址 0，而不是指令段后。&lt;/p&gt;

&lt;h3&gt;共享库&lt;/h3&gt;

&lt;p&gt;传统的链接，会将被调用的外部库的函数加载到二进制文件，当程序载入内存开始执行时，它所需的所有函数都已经准备就绪。&lt;/p&gt;

&lt;p&gt;为了节省磁盘和内存空间，引入了共享库。当程序和共享库链接时，链接器没有加载被调用的函数，而是加载了一小段能够在运行时绑定所调用函数的存根例程（stbu routine）。共享库或和程序一起加载，或在第一次被调用时加载。当其他程序已经加载过，就没有必要再次加载了。共享库不是一次性读入内存，而是以页面为单位装载的。&lt;/p&gt;

&lt;h3&gt;内存映射文件&lt;/h3&gt;

&lt;p&gt;共享库其实是一种更通用的机制：内存映射文件的一个特例。其思想是：进程可以通过系统调用，将一个文件映射到其虚拟地址空间的一部分。在映射共享的页面时不会实际读入页面的内容，而是访问页面时才会被读入，磁盘文件当作后备存储，当进程退出或显式解除文件映射时，所有改动才会写回文件。&lt;/p&gt;

&lt;p&gt;如果两个或以上的进程同时映射了一个文件，它们就可以通过共享内存来通信。&lt;/p&gt;

&lt;h1&gt;Linux 中的实现&lt;/h1&gt;

&lt;h2&gt;内存管理&lt;/h2&gt;

&lt;h3&gt;页&lt;/h3&gt;

&lt;p&gt;内核把物理页作为内存管理的基本单位。尽管处理器最小可寻址单位通常为字，但内存管理单元（MMU)通常以页为单位进行处理。体系结构不同，支持的页大小也不同。大多数 32 位体系结构支持 4 KB 的页，而 64 位体系结构一般支持 8 KB 的页。&lt;/p&gt;

&lt;p&gt;内核用 &lt;code&gt;struct page&lt;/code&gt; 结构表示系统中的每个物理页，该结构位于 &lt;linux/mm_types.h&gt; 中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct page {
    unsigned long flags;    /* Atomic flags, some possibly updated asynchronously */
    atomic_t _count;        /* Usage count, see below. */

    atomic_t _mapcount;     /* Count of ptes mapped in mms,
                             * to show when page is mapped
                             * &amp;amp; limit reverse map searches.
                             */
    };
    union {
        struct {
        unsigned long private;  /* Mapping-private opaque data:
                                 * usually used for buffer_heads
                                 * if PagePrivate set; used for
                                 * swp_entry_t if PageSwapCache;
                                 * indicates order in the buddy
                                 * system if PG_buddy is set.
                                 */
        struct address_space *mapping;  /* If low bit clear, points to
                                         * inode address_space, or NULL.
                                         * If page mapped as anonymous
                                         * memory, low bit is set, and
                                         * it points to anon_vma object:
                                         * see PAGE_MAPPING_ANON below.
                                         */
        };
    union {
        pgoff_t index;      /* Our offset within mapping. */
        void *freelist;     /* SLUB: freelist req. slab lock */
    };
    struct list_head lru;   /* Pageout list, eg. active_list
                             * protected by zone-&amp;gt;lru_lock !
                             */
    void *virtual;          /* Kernel virtual address (NULL if not kmapped, ie. highmem) */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;flage 域用来存放页的状态。这些状态包括页是不是脏的，是不是被锁定在内存中等等。_count 域存放页的引用计数，变成 0 说明当前内核没有引用这一页。页可以由页缓存使用（此时 mapping 域指向和这个页关联的 address_space 对象)，或者作为私有数据（由 private 指向），或者作为进程页表中的映射。&lt;/p&gt;

&lt;p&gt;virtual 域是页的虚拟地址，通常情况下，就是页在虚拟内存中的地址。高端内存并不会永久映射到内核地址空间上，这种情况下，virtual 域的值为 NULL。&lt;/p&gt;

&lt;p&gt;page 结构与物理页相关，并非与虚拟页相关。&lt;/p&gt;

&lt;h3&gt;区&lt;/h3&gt;

&lt;p&gt;由于硬件的限制，内核把页划分为不同的区（zone）。内核使用区对具有相似特性的页进行分组。Linux 必须处理以下两种因硬件存在的缺陷而引起的内存寻址问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一些硬件只能用特定的内存地址来执行 DMA（直接内存访问）&lt;/li&gt;
&lt;li&gt;一些体系结构其内存的物理寻址范围比虚拟寻址范围大得多，这样就有些内存不能永久地映射到内核空间上&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为存在这些制约条件，Linux 使用三种区：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ZONE_DMA： 这个区包含的页能用来执行 DMA 操作&lt;/li&gt;
&lt;li&gt;ZONE_NORMAL： 这个区包含的都是能正常映射的页&lt;/li&gt;
&lt;li&gt;ZONE_HIGHMEM： 这个区包含“高端内存”，其中的页并不能永久地映射到内核地址空间。这些区定义于 &lt;linux/mmzone.h&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Linux 把系统的页划分为区，形成不同的内存池。每个区都用 &lt;code&gt;struct zone&lt;/code&gt; 表示，定义在 &lt;linux/mmzone.h&gt; 中。&lt;/p&gt;

&lt;h3&gt;获得页&lt;/h3&gt;

&lt;p&gt;内核提供一种请求内存的底层机制，并提供了对它进行访问的几个接口。所有这些接口都以页为单位分配内存，定义于 &lt;linux/gfp.h&gt;。最核心的函数是：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struc page * alloc_pages(unsigned int gfp_mask, unsigned int order)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;该函数分配 2&lt;sup&gt;order&lt;/sup&gt; 个连续的物理页，并返回一个指针，该指针指向第一个页的 page 结构体；如果出错就返回 NULL。&lt;/p&gt;

&lt;p&gt;下面的函数：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;void *page_address(struct page *page)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;把给定的物理页转换成逻辑地址。如果你不需要使用 struct page，可以直接调用&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;unsigned long__get_free_pages(unsigned int gfp_mask, unsigned int order)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;该函数与 &lt;code&gt;alloc_page()&lt;/code&gt; 作用相同，不过它直接返回请求的第一个页的逻辑地址，因为页是连续的，其他页也会紧随其后。&lt;/p&gt;

&lt;h2&gt;kmalloc()&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;kmalloc()&lt;/code&gt; 函数与用户空间的 &lt;code&gt;malloc()&lt;/code&gt; 一族非常类似，只不过它多了一个 flags 参数。&lt;code&gt;kmalloc()&lt;/code&gt; 函数是一个简单的接口，用它可以获得以字节为单位的一块内核内存。&lt;code&gt;kmalloc()&lt;/code&gt; 在 &lt;linux/slab.h&gt; 中声明：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;void *kmalloc(size_t size, int flags)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这个函数返回一个指向内存块的指针，其内存块至少要有 size 大小。所分配的内存区在物理上是连续的。在出错时返回 NULL。&lt;/p&gt;

&lt;h3&gt;vmalloc()&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;vmalloc()&lt;/code&gt; 函数的工作方式类似于 &lt;code&gt;kmalloc()&lt;/code&gt;，只不过前者分配的内存虚拟地址是连续的，而物理地址无需连续。这也是用户空间分配函数的工作方式：由 &lt;code&gt;malloc()&lt;/code&gt; 返回的页在进程的虚拟地址空间内是连续的，但并不保证它们在物理 RAM 中也连续。&lt;code&gt;kmalloc()&lt;/code&gt; 函数确保页在物理地址上是连续的。&lt;/p&gt;

&lt;p&gt;大多数情况下，只有硬件设备需要得到物理地址连续的内存，硬件设备存在于内存管理单元之外，它根本不理解什么是虚拟内存。因此硬件设备用到的任何内存区都必须是物理上连续的块，而不仅仅是虚拟地址连续的块。而仅供软件使用的内存块（例如进程相关的缓冲区）就可以使用只有虚拟地址连续的内存块。&lt;/p&gt;

&lt;p&gt;尽管在某些情况下才需要物理上连续的内存块，但很多内核代码都用 &lt;code&gt;kmalloc()&lt;/code&gt; 来获得内存，而不是 &lt;code&gt;vmalloc()&lt;/code&gt;。这主要是出于性能的考虑。&lt;code&gt;vmalloc()&lt;/code&gt; 为了把物理上不连续的页转换为虚拟空间上连续的页，必须专门建立页表项，通过 &lt;code&gt;vmalloc()&lt;/code&gt; 获得的页必须一个个进行映射，这会导致比直接内存映射大得多的 TLB 抖动。因此 &lt;code&gt;vmalloc()&lt;/code&gt; 仅在不得已的时候才使用，一般是在为了获得大块内存，例如当模块被动态插入到内核中时，就把模块装载到由 &lt;code&gt;vmalloc()&lt;/code&gt; 分配的内存上。&lt;/p&gt;

&lt;h3&gt;slab 层&lt;/h3&gt;

&lt;p&gt;Linux 内核提供了 slab 层（即 slab 分配器），slab 分配器扮演了通用数据结构缓存层的角色。&lt;/p&gt;

&lt;h4&gt;slab 层的设计&lt;/h4&gt;

&lt;p&gt;slab 层把不同的对象划分为所谓的&lt;strong&gt;高速缓存组&lt;/strong&gt;，其中每个高速缓存都存放不同类型的对象，每种对象类型对应一个高速缓存。例如一个高速缓存用于存放进程描述符，另一个高速缓存存放索引节点对象（struct inode）。&lt;code&gt;kmalloc()&lt;/code&gt; 接口建立在 slab 层之上，使用了一组通用高速缓存。&lt;/p&gt;

&lt;p&gt;这些高速缓存又被划分为 slab。slab 由一个或多个物理上连续的页组成。每个高速缓存由多个 slab 组成。每个 slab 都包含一些对象成员，即被缓存的数据结构。每个 slab 处于三种状态之一：满、部分满或空。当内核需要一个新对象时，先从部分满的 slab 中进行分配，如果没有部分满的 slab，就从空的 slab 进行分配。如果没有空的 slab，就要创建一个 slab。&lt;/p&gt;

&lt;h2&gt;进程地址空间&lt;/h2&gt;

&lt;p&gt;内核除了管理自身的内存外，还必须管理进程的地址空间。Linux 操作系统采用虚拟内存技术，对每个进程来说，它们好像都可以访问整个系统的所有物理内存，即使单独一个进程，它拥有的地址空间也可远大于系统物理内存。&lt;/p&gt;

&lt;p&gt;每个进程都有一个 32 或 64 位的平坦地址空间，空间的具体大小取决于体系结构。每个进程有唯一的平坦地址空间，而且进程地址空间之间彼此互不相干。两个不同的进程可以在它们各自地址空间中国年相同的地址内存存放不同的数据，进程之间也可以选择共享地址空间（线程）。&lt;/p&gt;

&lt;p&gt;进程地址空间中，可被访问的合法地址区间称为内存区域（memory area）。进程只能访问有效范围内的内存地址。每个内存区域也具有进程必须遵循的特定访问属性，如只读、只写、可执行等属性。如果进程访问了不在有效范围中的地址，或以不正确的方式访问有效地址，那么内核就会终止该进程，并返回“段错误”。&lt;/p&gt;

&lt;p&gt;内存区域可以包含各种内存对象：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;可执行文件代码的内存映射，称为代码段（text section）&lt;/li&gt;
&lt;li&gt;可执行文件的已初始化全局变量的内存映射，称为数据段（data section）&lt;/li&gt;
&lt;li&gt;包含未初始化全局变量，即 bss 段的零页的内存映射&lt;/li&gt;
&lt;li&gt;用于进程用户空间栈的零页的内存映射&lt;/li&gt;
&lt;li&gt;每个共享库的代码段、数据段和 bss 也会载入进程的地址空间&lt;/li&gt;
&lt;li&gt;任何内存映射文件&lt;/li&gt;
&lt;li&gt;任何共享内存段&lt;/li&gt;
&lt;li&gt;任何匿名的内存映射，比如由 malloc() 分配的内存&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;内存描述符&lt;/h3&gt;

&lt;p&gt;内核使用内存描述符结构体表示进程的地址空间，该结构包含了和进程地址空间有关的全部心血。内存描述法由 mm_struct 结构体表示，定义在文件 &lt;linux/sched.h&gt; 中。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct mm_struct {
    struct vm_area_struct * mmap;       /* list of VMAs */
    struct rb_root mm_rb;
    struct vm_area_struct * mmap_cache; /* last find_vma result */

    unsigned long free_area_cache;      /* first hole of size cached_hole_size or larger */
    pgd_t * pgd;
    atomic_t mm_users;          /* How many users with user space? */
    atomic_t mm_count;          /* How many references to &amp;quot;struct mm_struct&amp;quot; (users count as 1) */
    int map_count;              /* number of VMAs */
    struct rw_semaphore mmap_sem;
    spinlock_t page_table_lock;     /* Protects page tables and some counters */

    struct list_head mmlist;        /* List of maybe swapped mm&amp;#39;s.  These are globally strung
                                     * together off init_mm.mmlist, and are protected
                                     * by mmlist_lock
                                     */
    unsigned long hiwater_rss;  /* High-watermark of RSS usage */
    unsigned long hiwater_vm;   /* High-water virtual memory usage */

    unsigned long total_vm, locked_vm, shared_vm, exec_vm;
    unsigned long stack_vm, reserved_vm, def_flags, nr_ptes;
    unsigned long start_code, end_code, start_data, end_data;
    unsigned long start_brk, brk, start_stack;
    unsigned long arg_start, arg_end, env_start, env_end;   

    cpumask_t cpu_vm_mask;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;mm_users 域纪录正在使用该地址的进程数目。mm_count 域是 mm_struct 结构体的主引用数。只有当 mm_users 为 0，mm_count 值才会变成 0，表示已经没有任何指向该 mm_struct 结构体的引用，这时该结构体就会被销毁。&lt;/p&gt;

&lt;p&gt;mmap 和 mm_rb 这两个不同数据结构体描述的对象是相同的：该地址空间中的全部内存区域。前者以链表形式存放而后者以红黑树的形式存放。mmap 结构体作为链表，方便简单、高效地遍历所有元素；而 mm_rb 结构体作为红黑树，方便搜索指定元素。&lt;/p&gt;

&lt;p&gt;所有 mm_struct 结构体都通过自身的 mmlist 域链接在一个双向链表中。该链表的首元素是 init_mm 内存描述符，他代表 init 进程的地址空间。&lt;/p&gt;

&lt;h3&gt;分配内存描述符&lt;/h3&gt;

&lt;p&gt;在进程的进程描述符中，mm 域存放着该进程使用的内存描述符。&lt;code&gt;fork()&lt;/code&gt; 函数利用 &lt;code&gt;copy_mm()&lt;/code&gt; 函数复制父进程的内存描述符，也就是 current-&amp;gt;mm 域给其子进程。而子进程的 mm_struct 结构体是通过文件 kernel/fork.c 中的 &lt;code&gt;allcote_mm()&lt;/code&gt; 宏从 mm_cachep slab 缓存中分配得到的。通常每个进程都有唯一的 mm_struct 结构体，即唯一的进程地址空间。&lt;/p&gt;

&lt;p&gt;如果父子进程共享地址空间，可以调用 &lt;code&gt;clone()&lt;/code&gt; 时，设置 CLONE_VM 标志。我们把这样的进程称为线程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;if (clone_flags &amp;amp; CLONE_VM) {
    atomic_inc(&amp;amp;current-&amp;gt;mm-&amp;gt;mm_users);
    tsk-&amp;gt;mm = current-&amp;gt;mm;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;销毁内存描述符&lt;/h3&gt;

&lt;p&gt;进程退出时，内核会调用 &lt;code&gt;exit_mm()&lt;/code&gt; 函数，该函数会调用 &lt;code&gt;mmput()&lt;/code&gt; 函数来减少内存描述符中的 mm_users 用户计数，如果为 0 则调用 &lt;code&gt;mmdrop()&lt;/code&gt; 函数，减少 mm_count 使用计数。如果使用计数也等于 0 了，则调用 &lt;code&gt;free_mm()&lt;/code&gt; 宏通过 &lt;code&gt;kmem_cache_free()&lt;/code&gt; 函数将 mm_struct 结构体归还到 mm_cachep slab 缓存中。&lt;/p&gt;

&lt;h3&gt;mm_struct 与内核线程&lt;/h3&gt;

&lt;p&gt;内核线程没有进程地址空间，也没有相关的内存描述符。所以内核线程对应的进程描述符中的 mm 域为空。&lt;/p&gt;

&lt;p&gt;当进程被调度时，该进程的 mm 域指向的地址空间被装载到内存，进程描述符中的 active_mm 域会被更新，指向新的地址空间。当内核线程被调度时，内核发现他的 mm 域为 NULL，就会保留前一个进程的地址空间，随后更新内核线程对应进程描述符中的 active_mm 域，使其指向前一个进程的内存描述符。因此在需要时，内核线程可以使用前一个进程的页表。因为内核线程不访问用户空间的内存，仅仅使用地址空间中和内核内存相关的信息。&lt;/p&gt;

&lt;h2&gt;内存区域&lt;/h2&gt;

&lt;p&gt;内存区域由 vm_area_struct 结构体描述，定义在文件 &lt;linux/mm.h&gt; 中，内存区域在内核中也经常被称做虚拟内存区域或 VMA。&lt;/p&gt;

&lt;p&gt;vm_area_struct 结构体描述了指定地址空间内连续区间上的一个独立内存范围。内核将每个内存区域作为一个单独的内存对象管理，每个内存区域都拥有一致的属性，比如访问权限等。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct vm_area_struct {
    struct mm_struct * vm_mm;   /* The address space we belong to. */
    unsigned long vm_start;     /* Our start address within vm_mm. */
    unsigned long vm_end;       /* The first byte after our end address within vm_mm. */

    /* linked list of VM areas per task, sorted by address */
    struct vm_area_struct *vm_next;

    pgprot_t vm_page_prot;      /* Access permissions of this VMA. */
    unsigned long vm_flags;     /* Flags, see mm.h. */

    struct rb_node vm_rb;

    /*
     * For areas with an address space and backing store,
     * linkage into the address_space-&amp;gt;i_mmap prio tree, or
     * linkage to the list of like vmas hanging off its node, or
     * linkage of vma in the address_space-&amp;gt;i_mmap_nonlinear list.
     */
    union {
        struct {  
            struct list_head list;
            void *parent;   /* aligns with prio_tree_node parent */
            struct vm_area_struct *head;
        } vm_set;

        struct raw_prio_tree_node prio_tree_node;
    } shared;

    /*
     * A file&amp;#39;s MAP_PRIVATE vma can be in both i_mmap tree and anon_vma
     * list, after a COW of one of the file pages.  A MAP_SHARED vma
     * can only be in the i_mmap tree.  An anonymous MAP_PRIVATE, stack
     * or brk vma (with NULL file) can only be in an anon_vma list.
     */
    struct list_head anon_vma_chain; /* Serialized by mmap_sem &amp;amp; page_table_lock */
    struct anon_vma *anon_vma;       /* Serialized by page_table_lock */

    /* Function pointers to deal with this struct. */
    const struct vm_operations_struct *vm_ops;

    /* Information about our backing store: */
    unsigned long vm_pgoff;     /* Offset (within vm_file) in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */
    struct file * vm_file;      /* File we map to (can be NULL). */
    void * vm_private_data;     /* was vm_pte (shared mem) */
    unsigned long vm_truncate_count;/* truncate_count or restart_addr */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;vm_mm 域指向和 VMA 相关的 mm_struct 结构体，注意每个 VMA 对其相关的 mm_struct 结构体来说都是唯一的。即使两个独立的进程将同一个文件映射到各自的地址空间，它们分别都有一个 vm_area_struct 结构体来标志自己的内存区域。但如果两个线程共享一个地址空间，那么它们也同时共享其中的所有 vm_area_struct 结构体。&lt;/p&gt;

&lt;h3&gt;VMA 标志&lt;/h3&gt;

&lt;p&gt;VMA 标志是一种位标志，包含在 vm_flags 域内，标志了内存区域所包含的页面的行为和信息：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;标志&lt;/th&gt;
&lt;th&gt;对 VMA 及其页面的影响&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;VM_READ&lt;/td&gt;
&lt;td&gt;页面可读取&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VM_WRITE&lt;/td&gt;
&lt;td&gt;页面可写&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VM_EXEC&lt;/td&gt;
&lt;td&gt;页面可执行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VM_SHARED&lt;/td&gt;
&lt;td&gt;页面可共享&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;当访问 VMA 时，需要查看其访问权限。比如进程的对象代码映射区域可能会标志为 VM_READ 和 VM_EXEC，而不会标志为 VM_WRITE。另一方面，可执行对象数据段的映射区域被标志为 VM_READ 和 VM_WRITE，而 VM_EXEC 标志对它毫无意义。只读文件数据段的映射区域仅可被标志为 VM_READ。VM_SHARED 指明了内存区域包含的映射是否可以在多进程间共享，如果该标志被设置，则称其为共享映射。如果未被设置，则只有一个进程可以使用该映射的内容，称其为私有映射。&lt;/p&gt;

&lt;p&gt;VM_IO 标志内存区域中的包含对设备 I/O 空间的映射。该标志通常在设备驱动程序执行 &lt;code&gt;mmap()&lt;/code&gt; 函数进行 I/O 空间映射时才被设置。同时该标志也表示该内存区域不能被包含在任何进程的 coredump 中。&lt;/p&gt;

&lt;h3&gt;实际使用中的内存区域&lt;/h3&gt;

&lt;p&gt;可以使用 /proc 文件系统和 pmap 工具查看给定进程的内存空间和其中所含的内存区域。&lt;/p&gt;

&lt;h2&gt;页表&lt;/h2&gt;

&lt;p&gt;当应用程序访问一个虚拟地址时，必须将虚拟地址转化为物理地址，然后处理器才能解析地址访问请求。&lt;/p&gt;

&lt;p&gt;Linux 中使用三级页表完成地址转换。利用多级页表能够节约地址转换需占用的存放空间。&lt;/p&gt;

&lt;p&gt;顶级页表是页全局目录(PGD)，PGD 包含了一个 pgd_t 类型数组，PGD 中的表项指向二级页目录中的表项：PMD。&lt;/p&gt;

&lt;p&gt;二级页表是中间页目录（PMD)，PMD 是一个 pmd_t 类型数组，其中表项指向 PTE 中的表项。&lt;/p&gt;

&lt;p&gt;最后一级的页表简称页表，其中包含 pte_t 类型的页表项，该页表项指向物理页面。&lt;/p&gt;

&lt;p&gt;每个进程都有自己的页表，内存描述符的 pgd 域指向的就是进程的页全局目录。操作和检索页表时必须使用 page_table_lock 锁。&lt;/p&gt;

&lt;p&gt;由于每次对虚拟内存中的页面访问都必须先解析，所以页表操作的性能非常关键。为了加快搜索，多数体系结构都实现了一个翻译后缓冲器（TLB)。TLB 是一个将虚拟地址映射到物理地址的硬件缓存。&lt;/p&gt;

&lt;h1&gt;相关资料&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/&quot;&gt;《How the Kernel Manages Your Memory》&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 11 Dec 2016 10:21:16 +0800</pubDate>
        <link>http://masutangu.com/2016/12/linux-kernel-serial-4/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/12/linux-kernel-serial-4/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
  </channel>
</rss>
