<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Masutangu</title>
    <description>也許我這一生　始終在追逐那顆九號球</description>
    <link>http://masutangu.com/</link>
    <atom:link href="http://masutangu.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 23 Nov 2017 09:37:42 +0800</pubDate>
    <lastBuildDate>Thu, 23 Nov 2017 09:37:42 +0800</lastBuildDate>
    <generator>Jekyll v3.1.1</generator>
    
      <item>
        <title>MIT 6.824 学习笔记（一）</title>
        <description>&lt;p&gt;本系列文章是对 &lt;a href=&quot;https://pdos.csail.mit.edu/6.824/schedule.html&quot;&gt;MIT 6.824&lt;/a&gt; 课程的学习笔记。&lt;/p&gt;

&lt;h1&gt;Introduction&lt;/h1&gt;

&lt;p&gt;本课程涵盖以下主题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RPC、线程、并发控制&lt;/li&gt;
&lt;li&gt;性能 &lt;/li&gt;
&lt;li&gt;容灾：&lt;strong&gt;Availability&lt;/strong&gt;, &lt;strong&gt;Durability&lt;/strong&gt;. replicated servers 是不错的选择。&lt;/li&gt;
&lt;li&gt;一致性：replica如何保持一致？ &lt;strong&gt;Consistency&lt;/strong&gt; 和 &lt;strong&gt;Performance&lt;/strong&gt; 不可兼得&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;MapReduce&lt;/h1&gt;

&lt;p&gt;Map funciton 接收 input pair 处理生成一系列的 intermediate key/value pairs。MapReduce 库将相同 intermediate key 的 intermediate values 打包起来传给 Reduce function。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-1/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Reduce function 接收 intermediate key 和与其关联的一系列 intermediate values。Reduce function 将这些 intermediate values 合并成更小的 values set。The intermediate values are supplied to the user’s reduce function via an iterator。&lt;/p&gt;

&lt;p&gt;Map Reduce function 的输入输出参数通常如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;map (k1,v1) → list(k2,v2)&lt;/li&gt;
&lt;li&gt;reduce (k2,list(v2)) → list(v2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;容错：worker 挂掉，重跑任务。master挂掉？直接暂停，由用户决定是否重跑。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;MR re-runs just the failed Map()s and Reduce()s. MR requires them to be pure functions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;they don&amp;#39;t keep state across calls,&lt;/li&gt;
&lt;li&gt;they don&amp;#39;t read or write files other than expected MR inputs/outputs,&lt;/li&gt;
&lt;li&gt;there&amp;#39;s no hidden communication among tasks.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So re-execution yields the same output.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;重跑如何保持一致：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Rely on atomic commits of map and reduce task outputs 细节？&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;不确定性？&lt;/p&gt;

&lt;p&gt;实现一个精简map reduce&lt;/p&gt;

&lt;h1&gt;RPC&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;Better RPC behavior: &amp;quot;at most once&amp;quot;&lt;/p&gt;

&lt;p&gt;idea: server RPC code detects duplicate requests, returns previous reply instead of re-running handler&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;如何检测重复的请求？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Client 在每个请求都带上唯一的 Request ID，重试时使用相同的 Request ID：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;server:
    if seen[xid]:
      r = old[xid]
    else
      r = handler()
      old[xid] = r
      seen[xid] = true
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Request ID 如何保证唯一？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;请求 id 包含客户端 ip，以区分不同客户端&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Server 端何时可以删掉保存的请求 id？&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;unique client IDs, per-client RPC sequence numbers, client includes &amp;quot;seen all replies &amp;lt;= X&amp;quot; with every RPC, much like TCP sequence #s and acks （客户端带上 ack_req_id，服务端可以把 &amp;lt;= ack_req_id 的请求 id 都删掉）&lt;/li&gt;
&lt;li&gt;only allow client one outstanding RPC at a time arrival of seq + 1 allows server to discard all &amp;lt;= seq&lt;/li&gt;
&lt;li&gt;client agrees to keep retrying for &amp;lt; 5 minutes, server discards after 5+ minutes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Server 应该把 Dupliate Request 信息写入磁盘，也应该同步到 replica。万一 server crash 或者重启，才不会丢失。&lt;/p&gt;

&lt;h1&gt;GFS&lt;/h1&gt;

&lt;p&gt;GFS 重新审视了传统文件系统的设计，并总结了以下几点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;组件挂掉是常态事件，因此文件系统必须集成监控、错误侦测、容灾以及自动恢复的机制&lt;/li&gt;
&lt;li&gt;几 GB 的大文件很普遍。&lt;/li&gt;
&lt;li&gt;随机写的场景非常少。一旦写入完成，文件通常只会被顺序读取&lt;/li&gt;
&lt;li&gt;co-designing the applications and the file system API benefits the overall system by increasing our flexibility（不理解，是说简化 API 的设计么？）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GFS 集群由单一 master 和多个 chunkserver 构成，可同时被多个 client 访问。文件被划为固定大小的 chunks。每个 chunk 在创建时由 master 分配一个不可修改且全局唯一的 chunk handle 标记。chunkservers 以 linux 文件形式保存 chunks，读写 chunks 时client 指定 chunk handle 和 byte range。每个 chunk 被复制多份以实现 reliability。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-1/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Master 维护整个文件系统的 metadata，包括命名空间，访问控制，文件到 chunks 的映射和 chunks 所在的位置。Master 还管理系统范围内的活动，例如 chunk 租用管理， orphaned chunk 的回收，以及 chunks 在 chunkservers 之间的迁移。Master 使用心跳信息周期地和每个 chunkserver 通讯，发送指令并收集 chunkserver 的状态信息。&lt;/p&gt;

&lt;p&gt;Client 和 master 的通信只涉及元数据，所有的数据操作都直接和 chunkservers 通信。&lt;/p&gt;

&lt;p&gt;Master 主要保存下面三种元数据：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;文件和 chunk 的命名空间&lt;/li&gt;
&lt;li&gt;文件到 chunk 的映射关系&lt;/li&gt;
&lt;li&gt;chunk 复本的位置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;前两种通过 logging mutations 持久化。chunk 复本的位置则是启动时 master 向每个 chunkserver 询问的。&lt;/p&gt;

&lt;p&gt;容灾：通过 &lt;strong&gt;snapshot&lt;/strong&gt; 和 &lt;strong&gt;logging mutations&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;一致性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A file region is &lt;strong&gt;consistent&lt;/strong&gt; if all clients will always see the same data, regardless of which replicas they read from. &lt;/li&gt;
&lt;li&gt;A region is &lt;strong&gt;defined&lt;/strong&gt; after a file data mutation if it is consistent and clients will see what the mutation writes in
its entirety.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;GFS 通过以下措施确保被修改的文件 region 是已定义的，并且包含最后一次修改操作写入的数据：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;chunk 的所有副本的修改操作顺序保持一致&lt;/li&gt;
&lt;li&gt;使用 chunk 的版本号来检测副本是否有效&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;为了应对记录追加的 at-least-once 特性，readers 可以使用下面的方法来处理 padding 和重复的 record。Writers （应用层 writer）在每条写入的记录中都包含了额外的信息例如 Checksum，用来验证它的有效性。Reader 使用 Checksum 识别和丢弃额外的 padding 和记录片段。应用程序还可以用记录的唯一标识符来过滤重复 record。 &lt;/p&gt;

&lt;p&gt;GFS 使用租约（lease）来保证多个副本间变更顺序的一致性。Master 节点给其中一个 replica 分配 chunk 租约，该 replica 变成 primary。Mutations 的顺序由 primary 决定。&lt;/p&gt;

&lt;p&gt;Master 维护了每个 chunk 的版本号，用以分辨出过时的 replicas。 每次 master 下发新的 lease 都会提升 chunk 的版本号。当 chunkserver 上报自身 chunk 集合和相关的版本号时，master 就可以检测出失效的 replica。 &lt;/p&gt;

&lt;h1&gt;Fault-Tolerant Virtual Machines&lt;/h1&gt;

&lt;p&gt;实现容错系统最常见的一种方法是主备方法，备机必须与主机保持接近一致。实现主备一致的一个普遍的做法是将主机状态的变化都同步给备机，包括 CPU、内存、I/O，但这种方式需要大量的带宽。另一种方式是将服务器建模成 deterministic state machine，如果输入相同，那最终的状态也会相同。通过同步输入序列的方式，对带宽的要求远低于同步状态的方式。&lt;/p&gt;

&lt;p&gt;Primary VM 的输入将通过 logging channel 同步给 backup VM。backup 的输出会被 hypervisor 丢弃，只有 primary VM 的输出会返回给客户端。&lt;/p&gt;

&lt;p&gt;Log all hardware events into a log: clock interrupts, network interrupts, i/o interrupts, etc.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;For non-deterministic instructions, record additional info&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;e.g., log the value of the time stamp register&lt;/p&gt;

&lt;p&gt;on replay: return the value from the log instead of the actual register&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Replay: delivery inputs in the same order at the same instructions&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;if during recording delivered clock interrupt at nth instruction executed
during replay also delivers the clock interrupt at the nth instruction&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Output Requirement&lt;/strong&gt;: if the backup VM ever takes over after a failure of the primary, the backup VM will continu executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;要满足 Output Requirement，所有的输出都必须延迟直到 backup VM 收到和该输出相关联的信息以便其可以回放。确保 Output Requirement 的一个简单的做法是给每个 output 操作创建一个特殊的log entry，当 backup VM 接收并 ack 该 log entry 时 primary VM 才会输出结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mit-6824-note-1/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;FT 使用 UDP 发送心跳包来检测 server 是否存活。另外 FT 还会通过监控从 primary 发往 backup 的流量的方式来检测。&lt;/p&gt;

&lt;p&gt;为了避免 split-brain 的问题，在切换主的时候，需要在 shared storage 上执行原子的 test-and-set 操作，执行成功的才能升为 primary。&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Nov 2017 15:40:29 +0800</pubDate>
        <link>http://masutangu.com/2017/11/mit-6824-note-1/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/11/mit-6824-note-1/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>游戏开发之状态机</title>
        <description>&lt;p&gt;这阵子工作的内容有用到状态机，感觉挺有意思。正好好久没写博客了，今天也来写一篇总结下。&lt;/p&gt;

&lt;h1&gt;前言&lt;/h1&gt;

&lt;p&gt;用状态机来实现业务模型，有以下几点好处：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;不需要写一大坨 if-else 或 switch case。代码逻辑结构清晰，也更便于调试&lt;/li&gt;
&lt;li&gt;代码阅读起来更加友好，方便其他读者理解整个业务逻辑&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;状态机可以划分为下面三个模块：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;状态集&lt;/strong&gt;：总共包括哪些状态&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;事件（条件）&lt;/strong&gt;：事件会触发状态机的状态发生变化&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;动作&lt;/strong&gt;：事件发生后执行的动作，可以变迁到新状态，也可以维持当前状态&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;实现&lt;/h1&gt;

&lt;h2&gt;一个简单的状态机的实现&lt;/h2&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 1. simple state machine
// 事件 interface
type Event interface {
  EventId() int64
}

type State int

// 事件处理函数 返回触发事件后的下一个状态 
type Handler func(prevState State, event Event) State

type StateMachine struct {
  currState    State
  handlers map[int64]Handler
}

// 添加事件处理方法 
func (s *StateMachine) AddHandler(eventId int64, handler Handler) {
  s.handlers[eventId] = handler
}

// 事件处理
func (s *StateMachine) Call(event Event)  {
  fmt.Println(&amp;quot;original state: &amp;quot;, s.currState)
  if handler, ok := s.handlers[event.EventId()]; ok {
    s.currState = handler(s.currState, event)  // 调用对应的 handler 更新状态机的状态
  }
  fmt.Println(&amp;quot;new state: &amp;quot;, s.currState)
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;Handler&lt;/code&gt; 为事件处理函数，输入参数为当前状态和事件，返回处理后的新状态。状态机根据事件找到对应的&lt;code&gt;Handler&lt;/code&gt;，&lt;code&gt;Handler&lt;/code&gt; 根据当前状态和触发的事件，返回下一个新状态，由状态机更新。&lt;/p&gt;

&lt;p&gt;下面看看一个开关的例子，初始状态为关，按下按钮状态由关变为开，再次按下由开变为关。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 1. simple state machine
const (
  EVENT_PRESS = iota
)

var (
  Off = State(0)  // 定义关闭状态
  On  = State(1)  // 定义开启状态 
)

// 定义 press 事件
type PressEvent struct {
}

func (event *PressEvent) EventId() int64 {
  return EVENT_PRESS
}

// 定义事件 Handler
func PressButton(prevState State, event Event) State {
  if prevState == Off {
    return On
  } else {
    return Off
  }
}

func main() {
  stateMachine := StateMachine{
    currState:    Off,  // 初始状态为关闭
    handlers: make(map[int64]Handler),
  }

  stateMachine.AddHandler(EVENT_PRESS, PressButton)
  stateMachine.Call(&amp;amp;PressEvent{}) // 按下后变成开
  stateMachine.Call(&amp;amp;PressEvent{}) // 再次按下变为关闭
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;程序输出：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;original state:  0
new state:  1
original state:  1
new state:  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这个实现很简单，但不足之处在于状态变迁逻辑都放在&lt;code&gt;Handler&lt;/code&gt;去实现了。对于读代码的人来说，需要读每个Handler的代码，才能整理出整个状态变迁图。&lt;/p&gt;

&lt;h2&gt;一个稍微复杂点的状态机&lt;/h2&gt;

&lt;p&gt;我们希望可以把状态变迁以更直观的方式表现出来，让读者一看就知道状态是如何流转的。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 2. a little more complicate state machine

type Event interface {
  EventId() int64
}

type State int

// 事件处理函数 返回 true 表示可以变迁到下一个状态 返回 false 表示维持当前状态
type Handler func(prevState State, event Event) bool

type StateMachine struct {
  currState    State
  handlers map[int64]Handler
  transitions map[State]map[int64]State
}

// 添加事件处理方法 
func (s *StateMachine) AddHandler(eventId int64, handler Handler) {
  s.handlers[eventId] = handler
}

// 添加状态变迁
func (s *StateMachine) AddTransition(originState State, eventId int64, destState State) {
  if trans, ok := s.transitions[originState]; !ok {
    s.transitions[originState] = map[int64]State{eventId: destState}
  } else {
    trans[eventId] = destState
  }
}

// 事件处理
func (s *StateMachine) Call(event Event) {
  fmt.Println(&amp;quot;original state: &amp;quot;, s.currState)  
  if handler, ok := s.handlers[event.EventId()]; ok { // 首先找到事件的handler
    if handler(s.currState, event) { // 如果事件Handler返回true 则执行状态变迁
      if trans, ok := s.transitions[s.currState]; ok {
        if newState, ok := trans[event.EventId()]; ok { 
          s.currState = newState  // 执行状态变迁
        }
      }
    }
  }
  fmt.Println(&amp;quot;new state: &amp;quot;, s.currState) 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这个状态机用&lt;code&gt;transitions&lt;/code&gt; 结构来记录状态流转的关系。初始化时调用方调用&lt;code&gt;AddTransition&lt;/code&gt;方法来添加状态变迁。请看下面的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 2. a little more complicate state machine

const (
  EVENT_PRESS = iota
)

var (
  Off = State(0)  // 关闭
  On  = State(1)  // 开启 
  COUNT = 0
)


type PressEvent struct {
}

func (event *PressEvent) EventId() int64 {
  return EVENT_PRESS
}

// 定义事件 Handler
func PressButton(prevState State, event Event) bool {
  COUNT += 1
  if COUNT % 2 == 0 { // 按两下才切换到新状态
    return true
  }
  return false // 只按一次维持当前状态
}

func main() {
  stateMachine := StateMachine{
    currState:    Off,  // 初始状态为关闭
    handlers: make(map[int64]Handler),
    transitions: make(map[State]map[int64]State),
  }

  stateMachine.AddHandler(EVENT_PRESS, PressButton)
  stateMachine.AddTransition(Off, EVENT_PRESS, On)
  stateMachine.AddTransition(On, EVENT_PRESS, Off)
  stateMachine.Call(&amp;amp;PressEvent{}) // 按一次状态不变
  stateMachine.Call(&amp;amp;PressEvent{}) // 按两次变成 off 状态
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;通过&lt;code&gt;stateMachine.AddTransition(Off, EVENT_PRESS, On)&lt;/code&gt;就可以清晰的知道 Press 事件可能会让状态 Off 切换到 状态 On，尽管 Press 事件发生后还是有可能维持当前状态不变（当 Handler 返回 false 时）。&lt;/p&gt;

&lt;p&gt;程序输出：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;original state:  0
new state:  0
original state:  0
new state:  1
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;更模块化的状态机&lt;/h2&gt;

&lt;p&gt;最后我们来实现一个更模块化的状态机，把事件和条件这两个逻辑彻底分开。当你在事件触发时，还需要做逻辑判断才能确定是否发生状态变迁时，建议将事件处理和条件判断剥离开来。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;// example 3. more modular state machine

type Event interface {
  EventId() int64
}

type State int

// 事件处理 Handler
type Handler interface {
  Process(prevState State, event Event)  // 只处理事件
  Check() bool                           // 处理完判断下是否应该做状态切换
}

type StateMachine struct {
  currState    State
  handlers          map[int64]Handler
  transitions   map[State]map[int64]State
}

// 添加事件处理方法 
func (s *StateMachine) AddHandler(eventId int64, handler Handler) {
  s.handlers[eventId] = handler
}

// 添加状态变迁
func (s *StateMachine) AddTransition(originState State, eventId int64, destState State) {
  if trans, ok := s.transitions[originState]; !ok {
    s.transitions[originState] = map[int64]State{eventId: destState}
  } else {
    trans[eventId] = destState
  }
}

// 事件处理
func (s *StateMachine) Call(event Event) {
  fmt.Println(&amp;quot;original state: &amp;quot;, s.currState)  
  if handler, ok := s.handlers[event.EventId()]; ok { // 首先找到事件的handler
    handler.Process(s.currState, event) 
    if handler.Check() {
      if trans, ok := s.transitions[s.currState]; ok {
        if newState, ok := trans[event.EventId()]; ok { 
          s.currState = newState  // 执行状态变迁
        }
      }
    }
  }
  fmt.Println(&amp;quot;new state: &amp;quot;, s.currState) 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;定义&lt;code&gt;Handler&lt;/code&gt;结构体，有两个接口：&lt;code&gt;Process&lt;/code&gt;只负责事件引发的逻辑处理， &lt;code&gt;Check&lt;/code&gt;判断逻辑处理后是否应该做状态变迁。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// example 3. more modular state machine

const (
  EVENT_PRESS = iota
)

var (
  Off = State(0)  // 关闭
  On  = State(1)  // 开启 
  COUNT = 0
)

type PressEvent struct {
}

func (event *PressEvent) EventId() int64 {
  return EVENT_PRESS
}

type PressEventHandler struct {}

// Process 只处理事件带来的内部变量的变化
func (h *PressEventHandler) Process(prevState State, event Event) {
  COUNT += 1
}


// Check 判断是否应该做状态切换
func (h *PressEventHandler) Check() bool {
  if COUNT % 2 == 0 { // 按两下才有作用
    return true
  }
  return false
}

func main() {
  stateMachine := StateMachine{
    currState:    Off,  // 初始状态为关闭
    handlers: make(map[int64]Handler),
    transitions: make(map[State]map[int64]State),
  }

  stateMachine.AddHandler(EVENT_PRESS, &amp;amp;PressEventHandler{})
  stateMachine.AddTransition(Off, EVENT_PRESS, On)
  stateMachine.AddTransition(On, EVENT_PRESS, Off)
  stateMachine.Call(&amp;amp;PressEvent{}) // 按一次状态不变
  stateMachine.Call(&amp;amp;PressEvent{}) // 按两次变成 off 状态
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;程序输出：
&lt;code&gt;
original state:  0
new state:  0
original state:  0
new state:  1
&lt;/code&gt;&lt;/p&gt;

&lt;h2&gt;一些补充&lt;/h2&gt;

&lt;p&gt;可以把 &lt;code&gt;State&lt;/code&gt; 定义成 interface，提供 &lt;code&gt;Enter&lt;/code&gt; 和 &lt;code&gt;Leave&lt;/code&gt; 接口：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;type State interface {
  Enter() 
  Leave()
}

// 事件处理
func (s *StateMachine) Call(event Event) {
  fmt.Println(&amp;quot;original state: &amp;quot;, s.currState)  
  if handler, ok := s.handlers[event.EventId()]; ok { // 首先找到事件的handler
    handler.Process(s.currState, event) 

    if handler.Check() {
      if trans, ok := s.transitions[s.currState]; ok {
        if newState, ok := trans[event.EventId()]; ok { 
          s.currState.Leave()     // 离开当前状态 调用 Leave 
          s.currState = newState  // 执行状态变迁
          s.currState.Enter()     // 进入新状态 调用 Enter
        }
      }
    } 
  }
  fmt.Println(&amp;quot;new state: &amp;quot;, s.currState) 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;与 goroutine 的结合&lt;/h2&gt;

&lt;p&gt;涉及到多个 goroutine 时，总会面临数据竞争的问题。通过 channel 来传递事件，由状态机处理，可以让代码变得清晰，避免加锁。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-golang&quot; data-lang=&quot;golang&quot;&gt;
type Room struct {
  eventCh chan Event // 通过channel 传递事件给状态机
  st *StateMachine
}

func (room *Room) Process() {
  for e := range room.eventCh {
    room.st.Call(e)
  }
}

func (room *Room) DispatchEvent(event Event) {
  room.eventCh &amp;lt;- event
}

func main() {
  stateMachine := StateMachine{
    currState:    Off,  // 初始状态为关闭
    handlers: make(map[int64]Handler),
    transitions: make(map[State]map[int64]State),
  }

  stateMachine.AddHandler(EVENT_PRESS, &amp;amp;PressEventHandler{})
  stateMachine.AddTransition(Off, EVENT_PRESS, On)
  stateMachine.AddTransition(On, EVENT_PRESS, Off)

  room := Room{st: &amp;amp;stateMachine, eventCh: make(chan Event)}

  go room.DispatchEvent(&amp;amp;PressEvent{})
  go room.DispatchEvent(&amp;amp;PressEvent{})
  go room.DispatchEvent(&amp;amp;PressEvent{})

  room.Process()  // just sample code
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;即使是多个 goroutine 并发抛出事件，状态机只从&lt;code&gt;eventCh&lt;/code&gt;中串行的取出事件并处理，处理过程中不需要对数据加锁。 &lt;/p&gt;
</description>
        <pubDate>Wed, 01 Nov 2017 08:33:41 +0800</pubDate>
        <link>http://masutangu.com/2017/11/state-machine/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/11/state-machine/</guid>
        
        
        <category>工作</category>
        
      </item>
    
      <item>
        <title>LevelDB 源码阅读（一）</title>
        <description>&lt;p&gt;这篇文章主要记录 LevelDB 的重要模块、类以及方法。把读写操作和 Compaction 操作的代码串了一遍，并添加了小部分注释。&lt;/p&gt;

&lt;h1&gt;模块&lt;/h1&gt;

&lt;h3&gt;Log 文件&lt;/h3&gt;

&lt;p&gt;客户端的写请求会先 append 到 Log 文件，成功后再写入到 Memtable。如果宕机可以通过 Log 文件来恢复 Memtable。&lt;/p&gt;

&lt;h3&gt;Memtable 和 Immutable Memtable&lt;/h3&gt;

&lt;p&gt;内存数据结构，基于跳表。客户端的读写请求都会由 Memtable 处理。 当 Memtable 占用的内存达到一定阈值，重新生成新的 Memtable 处理客户端请求。原来的 Memtable 转成 Immutable Memtable，等待归并到 SST 文件中。&lt;/p&gt;

&lt;h3&gt;SST 文件&lt;/h3&gt;

&lt;p&gt;落地到磁盘的存储文件。SST 分为不同的 level，具体参考&lt;a href=&quot;https://github.com/google/leveldb/blob/master/doc/impl.md&quot;&gt;文档&lt;/a&gt;。&lt;/p&gt;

&lt;h3&gt;Manifest 文件&lt;/h3&gt;

&lt;p&gt;Manifest 记录不同 level 的 SST 文件，包括每个 SST 文件的 key range、大小等 metadata。&lt;/p&gt;

&lt;h3&gt;Current 文件&lt;/h3&gt;

&lt;p&gt;Current 记录了最新的 Manifest 文件。&lt;/p&gt;

&lt;h1&gt;类成员变量&lt;/h1&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;class DBImpl : public DB {
  private:
    TableCache* table_cache_;
    MemTable* mem_;
    MemTable* imm_;
    WritableFile* logfile_;
    log::Writer* log_;
    std::deque&amp;lt;Writer*&amp;gt; writers_;
    VersionSet* versions_;

    // Set of table files to protect from deletion because they are
    // part of ongoing compactions.
    std::set&amp;lt;uint64_t&amp;gt; pending_outputs_;
};

class MemTable {
  private:
    typedef SkipList&amp;lt;const char*, KeyComparator&amp;gt; Table;
    Arena arena_;  // 内存池
    Table table_;  // 跳表
};

struct FileMetaData {
  int refs;
  int allowed_seek;   // seeks allowed until compaction
  uint64_t number;    // ?? 
  uint64_t file_size;
  InternalKey smallest;
  InternalKey largest;
};

class VersionEdit {
  private:
    typedef std::set&amp;lt; std::pair&amp;lt;int, uint64_t&amp;gt; &amp;gt; DeletedFileSet;

    std::vector&amp;lt; std::pair&amp;lt;int, InternalKey&amp;gt; &amp;gt; compact_pointers_;
    DeletedFileSet deleted_files_;
    std::vector&amp;lt; std::pair&amp;lt;int, FileMetaData&amp;gt; &amp;gt; new_files_;
};

class Version {
  public:
    Status Get(const ReadOptions&amp;amp;, const LookupKey&amp;amp; key, std::string* val, 
               GetStats* stats);
  private:
    VersionSet* vset_;
    Version* next_;
    Version* prev_;

    // list of files per level
    std::vector&amp;lt;FileMetaData*&amp;gt; files_[config::kNumLevels];
};

class TableCache {
  public:
    Status Get(const ReadOptions&amp;amp; options, uint64_t file_number, 
               uint64_t file_size, const Slice&amp;amp; k, void *arg, 
               void (*handle_result)(void*, const Slice&amp;amp;, const Slice&amp;amp;));

  private:
    Cache* cache_;
};

class VersionSet {
  private:
    TableCache* const table_cache_;
    WritableFile* descriptor_file_;
    log::Writer* descriptor_log_;
    Version dummy_versions_;  // Head of circurlar doubly-linked list of versions  
    Version* current_;        // == dummy_versions_.prev_
};

class WriteBatch {
  public:
    class Handler {
    public:
        virtual ~Handler();
        virtual void Put(const Slice&amp;amp; key, const Slice&amp;amp; value) = 0;
        virtual void Delete(const Slice&amp;amp; key) = 0;
    };
  private:
    friend class WriteBatchInternal;
    std::string req_;
}

struct DBImpl::Writer {
  Status status;
  WriteBatch* batch;
  bool sync;
  bool done;
  port::CondVar cv;

  expplicit Writer(port::Mutex* mu) : cv(mu) { }
};

class Compaction {
  private:
    Version* input_version_;
    VersionEdit edit_;

    // Each compaction reads inputs from &amp;quot;level_&amp;quot; and &amp;quot;level_+1&amp;quot;
    std::vector&amp;lt;FileMetaData*&amp;gt; inputs_[2];      // The two sets of inputs

    // State used to check for number of of overlapping grandparent files
    // (parent == level_ + 1, grandparent == level_ + 2)
    std::vector&amp;lt;FileMetaData*&amp;gt; grandparents_;
    size_t grandparent_index_;  // Index in grandparent_starts_
    bool seen_key_;             // Some output key has been seen
    int64_t overlapped_bytes_;  // Bytes of overlap between current output
                                // and grandparent files

    // level_ptrs_ holds indices into input_version_-&amp;gt;levels_: our state
    // is that we are positioned at one of the file ranges for each
    // higher level than the ones involved in this compaction (i.e. for
    // all L &amp;gt;= level_ + 2).
    size_t level_ptrs_[config::kNumLevels];
};

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h1&gt;主要操作&lt;/h1&gt;

&lt;h3&gt;读操作&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status DBImpl::Get(const ReadOptions&amp;amp; options,
                   const Slice&amp;amp; key,
                   std::string* value) {

  MutexLock l(&amp;amp;mutex_);
  MemTable* mem = mem_;
  MemTable* imm = imm_;
  Version* current = versions_-&amp;gt;current();

  bool have_stat_update = false;
  Version::GetStats stats;

  // Unlock while reading from files and memtables
  {
    mutex_.Unlock();
    // First look in the memtable, then in the immutable memtable (if any).
    LookupKey lkey(key, snapshot);
    if (mem-&amp;gt;Get(lkey, value, &amp;amp;s)) {  // 1）先在 MemTable 中查找
      // Done
    } else if (imm != NULL &amp;amp;&amp;amp; imm-&amp;gt;Get(lkey, value, &amp;amp;s)) {  // 2）再在 Imutable MemTable 中查找
      // Done
    } else {
      s = current-&amp;gt;Get(options, lkey, value, &amp;amp;stats);  // 3) 最后在当前 Version 中查找
      have_stat_update = true;
    }
    mutex_.Lock();
  }

  // UpdateStats 减去 allowed_seeks，如果小于等于 0，则设置 file_to_compact_，准备 compaction
  if (have_stat_update &amp;amp;&amp;amp; current-&amp;gt;UpdateStats(stats)) {
    MaybeScheduleCompaction();
  }

  return s;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;// Version 类的 Get 方法
Status Version::Get(const ReadOptions&amp;amp; options,
                    const LookupKey&amp;amp; k,
                    std::string* value,
                    GetStats* stats) {
  Slice ikey = k.internal_key();
  Slice user_key = k.user_key();
  const Comparator* ucmp = vset_-&amp;gt;icmp_.user_comparator();
  Status s;

  stats-&amp;gt;seek_file = NULL;
  stats-&amp;gt;seek_file_level = -1;
  FileMetaData* last_file_read = NULL;
  int last_file_read_level = -1;

  // We can search level-by-level since entries never hop across
  // levels.  Therefore we are guaranteed that if we find data
  // in an smaller level, later levels are irrelevant.
  std::vector&amp;lt;FileMetaData*&amp;gt; tmp;
  FileMetaData* tmp2;
  for (int level = 0; level &amp;lt; config::kNumLevels; level++) {
    size_t num_files = files_[level].size();
    if (num_files == 0) continue;

    // 这里省略一大段代码 files 指向候选文件列表，num_files 为列表的长度。具体实现看源码

    for (uint32_t i = 0; i &amp;lt; num_files; ++i) {
      if (last_file_read != NULL &amp;amp;&amp;amp; stats-&amp;gt;seek_file == NULL) {
        // We have had more than one seek for this read.  Charge the 1st file.
        // last_file_read 保存的其实就是第一个查找未命中的文件，函数返回后会调用 UpdateStats 来减去 allowed_seeks
        stats-&amp;gt;seek_file = last_file_read;
        stats-&amp;gt;seek_file_level = last_file_read_level;
      }

      FileMetaData* f = files[i];
      last_file_read = f;
      last_file_read_level = level;

      Saver saver;
      saver.state = kNotFound;
      saver.ucmp = ucmp;
      saver.user_key = user_key;
      saver.value = value;
      // 从 TableCache 中读取文件内容
      s = vset_-&amp;gt;table_cache_-&amp;gt;Get(options, f-&amp;gt;number, f-&amp;gt;file_size,
                                   ikey, &amp;amp;saver, SaveValue);
      if (!s.ok()) {
        return s;
      }
      switch (saver.state) {
        case kNotFound:
          break;      // Keep searching in other files
        case kFound:
          return s;
        case kDeleted:
          s = Status::NotFound(Slice());  // Use empty error message for speed
          return s;
        case kCorrupt:
          s = Status::Corruption(&amp;quot;corrupted key for &amp;quot;, user_key);
          return s;
      }
    }
  }

  return Status::NotFound(Slice());  // Use an empty error message for speed
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status TableCache::Get(const ReadOptions&amp;amp; options, uint64_t file_number, 
                      uint64_t file_size, const Slice&amp;amp; k, void *arg,
                      void (*saver)(void* const Slice&amp;amp;, const Slice&amp;amp;)) {
  Cache::Handle* handle = NULL;
  Status s = FindTable(file_number, file_size, &amp;amp;handle);
  if (s.ok()) {
    Table* t = reinterpret_cast&amp;lt;TableAndFile*&amp;gt;(cache_-&amp;gt;Value(handle))-&amp;gt;table;
    s = t-&amp;gt;InternalGet(options, k, arg, saver);
    cache_-&amp;gt;Release(handle);
  }
  return s;                        
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;查找顺序如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/leveldb/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;写操作&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status DB::Put(const WriteOptions&amp;amp; opt, const Slice&amp;amp; key, const Slice&amp;amp; value) {
  WriteBatch batch;
  batch.Put(key, value);
  return Write(opt, &amp;amp;batch);
}

Status DBImpl::Write(const WriteOptions&amp;amp; options, WriteBatch* my_batch) {
  Writer w(&amp;amp;mutex_);
  w.batch = my_batch;
  w.sync = options.sync;
  w.done = false;

  MutexLock l(&amp;amp;mutex_);
  writers_.push_back(&amp;amp;w);
  // 生产者消费者模型
  while (!w.done &amp;amp;&amp;amp; &amp;amp;w != writers_.front()) {
    w.cv.Wait();
  }
  // 写操作有可能被合并处理，因此有可能取到的时候写入已经完成。完成的话直接返回
  if (w.done) {
    return w.status;
  }

  // May temporarily unlock and wait.
  // MakeRoomForWrite 判断是非需要归并 memtable
  Status status = MakeRoomForWrite(my_batch == NULL);
  uint64_t last_sequence = versions_-&amp;gt;LastSequence();
  Writer* last_writer = &amp;amp;w;
  if (status.ok() &amp;amp;&amp;amp; my_batch != NULL) {  // NULL batch is for compactions
    WriteBatch* updates = BuildBatchGroup(&amp;amp;last_writer); // 合并写操作
    WriteBatchInternal::SetSequence(updates, last_sequence + 1);
    last_sequence += WriteBatchInternal::Count(updates);

    // Add to log and apply to memtable.  We can release the lock
    // during this phase since &amp;amp;w is currently responsible for logging
    // and protects against concurrent loggers and concurrent writes
    // into mem_.
    {
      mutex_.Unlock();
      status = log_-&amp;gt;AddRecord(WriteBatchInternal::Contents(updates));
      bool sync_error = false;
      if (status.ok() &amp;amp;&amp;amp; options.sync) {
        status = logfile_-&amp;gt;Sync();
        if (!status.ok()) {
          sync_error = true;
        }
      }
      if (status.ok()) {
        status = WriteBatchInternal::InsertInto(updates, mem_);
      }
      mutex_.Lock();
      if (sync_error) {
        // The state of the log file is indeterminate: the log record we
        // just added may or may not show up when the DB is re-opened.
        // So we force the DB into a mode where all future writes fail.
        RecordBackgroundError(status);
      }
    }
    if (updates == tmp_batch_) tmp_batch_-&amp;gt;Clear();

    versions_-&amp;gt;SetLastSequence(last_sequence);
  }

  while (true) {
    Writer* ready = writers_.front();
    writers_.pop_front();
    if (ready != &amp;amp;w) {
      ready-&amp;gt;status = status;
      ready-&amp;gt;done = true;
      ready-&amp;gt;cv.Signal();
    }
    if (ready == last_writer) break;
  }

  // Notify new head of write queue
  if (!writers_.empty()) {
    writers_.front()-&amp;gt;cv.Signal();
  }

  return status;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;// REQUIRES: Writer list must be non-empty
// REQUIRES: First writer must have a non-NULL batch
// 尝试合并写操作
WriteBatch* DBImpl::BuildBatchGroup(Writer** last_writer) {
  assert(!writers_.empty());
  Writer* first = writers_.front();
  WriteBatch* result = first-&amp;gt;batch;
  assert(result != NULL);

  size_t size = WriteBatchInternal::ByteSize(first-&amp;gt;batch);

  // Allow the group to grow up to a maximum size, but if the
  // original write is small, limit the growth so we do not slow
  // down the small write too much.
  size_t max_size = 1 &amp;lt;&amp;lt; 20;
  if (size &amp;lt;= (128&amp;lt;&amp;lt;10)) {
    max_size = size + (128&amp;lt;&amp;lt;10);
  }

  *last_writer = first;
  std::deque&amp;lt;Writer*&amp;gt;::iterator iter = writers_.begin();
  ++iter;  // Advance past &amp;quot;first&amp;quot;
  for (; iter != writers_.end(); ++iter) {
    Writer* w = *iter;
    if (w-&amp;gt;sync &amp;amp;&amp;amp; !first-&amp;gt;sync) {
      // Do not include a sync write into a batch handled by a non-sync write.
      break;
    }

    if (w-&amp;gt;batch != NULL) {
      size += WriteBatchInternal::ByteSize(w-&amp;gt;batch);
      if (size &amp;gt; max_size) {
        // Do not make batch too big
        break;
      }

      // Append to *result
      // 把合并的写请求保存在成员变量 tmp_batch_ 中，避免和调用者的写请求混淆在一起
      if (result == first-&amp;gt;batch) {
        // Switch to temporary batch instead of disturbing caller&amp;#39;s batch
        result = tmp_batch_;
        assert(WriteBatchInternal::Count(result) == 0);
        WriteBatchInternal::Append(result, first-&amp;gt;batch);
      }
      WriteBatchInternal::Append(result, w-&amp;gt;batch);
    }
    *last_writer = w;
  }
  return result;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status WriteBatchInternal::InsertInto(const WriteBatch* b,
                                      MemTable* memtable) {
  MemTableInserter inserter;
  inserter.sequence_ = WriteBatchInternal::Sequence(b);
  inserter.mem_ = memtable;
  return b-&amp;gt;Iterate(&amp;amp;inserter);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status WriteBatch::Iterate(Handler* handler) const {
  Slice input(rep_);
  if (input.size() &amp;lt; kHeader) {
    return Status::Corruption(&amp;quot;malformed WriteBatch (too small)&amp;quot;);
  }

  input.remove_prefix(kHeader);
  Slice key, value;
  int found = 0;
  while (!input.empty()) {
    found++;
    char tag = input[0];
    input.remove_prefix(1);
    switch (tag) {
      case kTypeValue:
        if (GetLengthPrefixedSlice(&amp;amp;input, &amp;amp;key) &amp;amp;&amp;amp;
            GetLengthPrefixedSlice(&amp;amp;input, &amp;amp;value)) {
          handler-&amp;gt;Put(key, value);
        } else {
          return Status::Corruption(&amp;quot;bad WriteBatch Put&amp;quot;);
        }
        break;
      case kTypeDeletion:
        if (GetLengthPrefixedSlice(&amp;amp;input, &amp;amp;key)) {
          handler-&amp;gt;Delete(key);
        } else {
          return Status::Corruption(&amp;quot;bad WriteBatch Delete&amp;quot;);
        }
        break;
      default:
        return Status::Corruption(&amp;quot;unknown WriteBatch tag&amp;quot;);
    }
  }
  if (found != WriteBatchInternal::Count(this)) {
    return Status::Corruption(&amp;quot;WriteBatch has wrong count&amp;quot;);
  } else {
    return Status::OK();
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;Compaction&lt;/h3&gt;

&lt;p&gt;Compaction 触发时机：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Immutable MemTable 不为空&lt;/li&gt;
&lt;li&gt;指定了 Manual Compaction&lt;/li&gt;
&lt;li&gt;VersionSet NeedsCompaction 返回 True

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;compaction_score_&lt;/code&gt; 大于 1&lt;/li&gt;
&lt;li&gt;&lt;code&gt;file_to_compact_&lt;/code&gt; 不为空&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;void DBImpl::MaybeScheduleCompaction() {
  mutex_.AssertHeld();
  if (bg_compaction_scheduled_) {
    // Already scheduled
  } else if (shutting_down_.Acquire_Load()) {
    // DB is being deleted; no more background compactions
  } else if (!bg_error_.ok()) {
    // Already got an error; no more changes
  } else if (imm_ == NULL &amp;amp;&amp;amp;
             manual_compaction_ == NULL &amp;amp;&amp;amp;
             !versions_-&amp;gt;NeedsCompaction()) {
    // No work to be done
  } else {
    bg_compaction_scheduled_ = true;
    env_-&amp;gt;Schedule(&amp;amp;DBImpl::BGWork, this);
  }
}

bool VersionSet::NeedsCompaction() const {
  Version* v = current_;
  return (v-&amp;gt;compaction_score_ &amp;gt;= 1) || (v-&amp;gt;file_to_compact_ != NULL);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;compaction_score_ 的计算如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;void VersionSet::Finalize(Version* v) {
  // Precomputed best level for next compaction
  int best_level = -1;
  double best_score = -1;

  for (int level = 0; level &amp;lt; config::kNumLevels-1; level++) {
    double score;
    if (level == 0) {
      // We treat level-0 specially by bounding the number of files
      // instead of number of bytes for two reasons:
      //
      // (1) With larger write-buffer sizes, it is nice not to do too
      // many level-0 compactions.
      //
      // (2) The files in level-0 are merged on every read and
      // therefore we wish to avoid too many files when the individual
      // file size is small (perhaps because of a small write-buffer
      // setting, or very high compression ratios, or lots of
      // overwrites/deletions).
      score = v-&amp;gt;files_[level].size() /
          static_cast&amp;lt;double&amp;gt;(config::kL0_CompactionTrigger);
    } else {
      // Compute the ratio of current size to size limit.
      const uint64_t level_bytes = TotalFileSize(v-&amp;gt;files_[level]);
      score = static_cast&amp;lt;double&amp;gt;(level_bytes) / MaxBytesForLevel(level);
    }

    if (score &amp;gt; best_score) {
      best_level = level;
      best_score = score;
    }
  }

  v-&amp;gt;compaction_level_ = best_level;
  v-&amp;gt;compaction_score_ = best_score;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;file_to_compact_ 则是由 allowed_seeks 来控制。从下面代码的注释可知 25 次 seek 的开销和一次 compaction 的开销差不多。allowed_seeks 可以理解为文件剩余查找次数，每次查找失败allowed_seeks 就会减 1。当 allowed_seeks 小于等于 0，意味着应该启动 compaction 来减少查找未命中带来的 seek 的开销了：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;bool Version::UpdateStats(const GetStats&amp;amp; stats) {
  FileMetaData* f = stats.seek_file;
  if (f != NULL) {
    f-&amp;gt;allowed_seeks--;
    if (f-&amp;gt;allowed_seeks &amp;lt;= 0 &amp;amp;&amp;amp; file_to_compact_ == NULL) {
      file_to_compact_ = f;
      file_to_compact_level_ = stats.seek_file_level;
      return true;
    }
  }
  return false;
}

// Apply all of the edits in *edit to the current state.
void Builder::Apply(VersionEdit* edit) {
  // Update compaction pointers
  for (size_t i = 0; i &amp;lt; edit-&amp;gt;compact_pointers_.size(); i++) {
    const int level = edit-&amp;gt;compact_pointers_[i].first;
    vset_-&amp;gt;compact_pointer_[level] =
        edit-&amp;gt;compact_pointers_[i].second.Encode().ToString();
  }

  // Delete files
  const VersionEdit::DeletedFileSet&amp;amp; del = edit-&amp;gt;deleted_files_;
  for (VersionEdit::DeletedFileSet::const_iterator iter = del.begin();
        iter != del.end();
        ++iter) {
    const int level = iter-&amp;gt;first;
    const uint64_t number = iter-&amp;gt;second;
    levels_[level].deleted_files.insert(number);
  }

  // Add new files
  for (size_t i = 0; i &amp;lt; edit-&amp;gt;new_files_.size(); i++) {
    const int level = edit-&amp;gt;new_files_[i].first;
    FileMetaData* f = new FileMetaData(edit-&amp;gt;new_files_[i].second);
    f-&amp;gt;refs = 1;

    // We arrange to automatically compact this file after
    // a certain number of seeks.  Let&amp;#39;s assume:
    //   (1) One seek costs 10ms
    //   (2) Writing or reading 1MB costs 10ms (100MB/s)
    //   (3) A compaction of 1MB does 25MB of IO:
    //         1MB read from this level
    //         10-12MB read from next level (boundaries may be misaligned)
    //         10-12MB written to next level
    // This implies that 25 seeks cost the same as the compaction
    // of 1MB of data.  I.e., one seek costs approximately the
    // same as the compaction of 40KB of data.  We are a little
    // conservative and allow approximately one seek for every 16KB
    // of data before triggering a compaction.
    f-&amp;gt;allowed_seeks = (f-&amp;gt;file_size / 16384);
    if (f-&amp;gt;allowed_seeks &amp;lt; 100) f-&amp;gt;allowed_seeks = 100;

    levels_[level].deleted_files.erase(f-&amp;gt;number);
    levels_[level].added_files-&amp;gt;insert(f);
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;看看 Compaction 做了哪些工作：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;void DBImpl::BackgroundCompaction() {
  mutex_.AssertHeld();

  if (imm_ != NULL) {
    CompactMemTable();
    return;
  }
  // 这里去掉了 manual compaction 的代码 不关心
  Compaction* c = versions_-&amp;gt;PickCompaction();

  Status status;
  if (c == NULL) {
    // Nothing to do
  } else if (c-&amp;gt;IsTrivialMove()) {
    // Move file to next level
    // IsTrivialMove 返回 True 则直接将文件移入 level + 1 层即可
    assert(c-&amp;gt;num_input_files(0) == 1);
    FileMetaData* f = c-&amp;gt;input(0, 0);
    c-&amp;gt;edit()-&amp;gt;DeleteFile(c-&amp;gt;level(), f-&amp;gt;number);
    c-&amp;gt;edit()-&amp;gt;AddFile(c-&amp;gt;level() + 1, f-&amp;gt;number, f-&amp;gt;file_size,
                       f-&amp;gt;smallest, f-&amp;gt;largest);
    status = versions_-&amp;gt;LogAndApply(c-&amp;gt;edit(), &amp;amp;mutex_);
    if (!status.ok()) {
      RecordBackgroundError(status);
    }
  } else {
    CompactionState* compact = new CompactionState(c);
    status = DoCompactionWork(compact);
    if (!status.ok()) {
      RecordBackgroundError(status);
    }
    CleanupCompaction(compact);
    c-&amp;gt;ReleaseInputs();
    DeleteObsoleteFiles();
  }
  delete c;

  if (status.ok()) {
    // Done
  } else if (shutting_down_.Acquire_Load()) {
    // Ignore compaction errors found during shutting down
  } else {
    Log(options_.info_log,
        &amp;quot;Compaction error: %s&amp;quot;, status.ToString().c_str());
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Compaction* VersionSet::PickCompaction() {
  Compaction* c;
  int level;

  // We prefer compactions triggered by too much data in a level over
  // the compactions triggered by seeks.
  // 判断是 size_compaction 还是 seek_compaction
  const bool size_compaction = (current_-&amp;gt;compaction_score_ &amp;gt;= 1);
  const bool seek_compaction = (current_-&amp;gt;file_to_compact_ != NULL);
  if (size_compaction) {
    level = current_-&amp;gt;compaction_level_;
    assert(level &amp;gt;= 0);
    assert(level+1 &amp;lt; config::kNumLevels);
    c = new Compaction(level);

    // Pick the first file that comes after compact_pointer_[level]
    // compact_pointer_[level] 记录上次 compact 时最大的 key
    for (size_t i = 0; i &amp;lt; current_-&amp;gt;files_[level].size(); i++) {
      FileMetaData* f = current_-&amp;gt;files_[level][i];
      if (compact_pointer_[level].empty() ||
          icmp_.Compare(f-&amp;gt;largest.Encode(), compact_pointer_[level]) &amp;gt; 0) {
        c-&amp;gt;inputs_[0].push_back(f);
        break;
      }
    }
    if (c-&amp;gt;inputs_[0].empty()) {
      // Wrap-around to the beginning of the key space
      c-&amp;gt;inputs_[0].push_back(current_-&amp;gt;files_[level][0]);
    }
  } else if (seek_compaction) {
    level = current_-&amp;gt;file_to_compact_level_;
    c = new Compaction(level);
    c-&amp;gt;inputs_[0].push_back(current_-&amp;gt;file_to_compact_);
  } else {
    return NULL;
  }

  c-&amp;gt;input_version_ = current_;
  c-&amp;gt;input_version_-&amp;gt;Ref();

  // Files in level 0 may overlap each other, so pick up all overlapping ones
  if (level == 0) {
    InternalKey smallest, largest;
    GetRange(c-&amp;gt;inputs_[0], &amp;amp;smallest, &amp;amp;largest);
    // Note that the next call will discard the file we placed in
    // c-&amp;gt;inputs_[0] earlier and replace it with an overlapping set
    // which will include the picked file.
    current_-&amp;gt;GetOverlappingInputs(0, &amp;amp;smallest, &amp;amp;largest, &amp;amp;c-&amp;gt;inputs_[0]);
    assert(!c-&amp;gt;inputs_[0].empty());
  }

  // 填充 level + 1 的文件，更新 compact_pointer_ 
  SetupOtherInputs(c);

  return c;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;IsTrivialMove 判断能否直接将文件移入 level + 1 层：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;bool Compaction::IsTrivialMove() const {
  // Avoid a move if there is lots of overlapping grandparent data.
  // Otherwise, the move could create a parent file that will require
  // a very expensive merge later on.
  return (num_input_files(0) == 1 &amp;amp;&amp;amp;
          num_input_files(1) == 0 &amp;amp;&amp;amp;
          TotalFileSize(grandparents_) &amp;lt;= kMaxGrandParentOverlapBytes);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;具体的合并操作在 DoCompactionWork 方法：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status DBImpl::DoCompactionWork(CompactionState* compact) {
  if (snapshots_.empty()) {
    compact-&amp;gt;smallest_snapshot = versions_-&amp;gt;LastSequence();
  } else {
    compact-&amp;gt;smallest_snapshot = snapshots_.oldest()-&amp;gt;number_;
  }

  // Release mutex while we&amp;#39;re actually doing the compaction work
  mutex_.Unlock();

  Iterator* input = versions_-&amp;gt;MakeInputIterator(compact-&amp;gt;compaction);
  input-&amp;gt;SeekToFirst();
  Status status;
  ParsedInternalKey ikey;
  std::string current_user_key;
  bool has_current_user_key = false;
  SequenceNumber last_sequence_for_key = kMaxSequenceNumber;
  for (; input-&amp;gt;Valid() &amp;amp;&amp;amp; !shutting_down_.Acquire_Load(); ) {
    // Prioritize immutable compaction work
    if (has_imm_.NoBarrier_Load() != NULL) {
      mutex_.Lock();
      if (imm_ != NULL) {
        CompactMemTable();  // 总是优先处理 CompactMemTable 避免阻塞 MemTable 的写入
        bg_cv_.SignalAll();  // Wakeup MakeRoomForWrite() if necessary
      }
      mutex_.Unlock();
    }

    Slice key = input-&amp;gt;key();
    if (compact-&amp;gt;compaction-&amp;gt;ShouldStopBefore(key) &amp;amp;&amp;amp;
        compact-&amp;gt;builder != NULL) {
      status = FinishCompactionOutputFile(compact, input);
      if (!status.ok()) {
        break;
      }
    }

    // Handle key/value, add to state, etc.
    bool drop = false;
    if (!ParseInternalKey(key, &amp;amp;ikey)) {
      // Do not hide error keys
      current_user_key.clear();
      has_current_user_key = false;
      last_sequence_for_key = kMaxSequenceNumber;
    } else {
      if (!has_current_user_key ||
          user_comparator()-&amp;gt;Compare(ikey.user_key,
                                     Slice(current_user_key)) != 0) {
        // First occurrence of this user key
        current_user_key.assign(ikey.user_key.data(), ikey.user_key.size());
        has_current_user_key = true;
        last_sequence_for_key = kMaxSequenceNumber;
      }

      if (last_sequence_for_key &amp;lt;= compact-&amp;gt;smallest_snapshot) {
        // Hidden by an newer entry for same user key
        drop = true;    // (A)
      } else if (ikey.type == kTypeDeletion &amp;amp;&amp;amp;
                 ikey.sequence &amp;lt;= compact-&amp;gt;smallest_snapshot &amp;amp;&amp;amp;
                 compact-&amp;gt;compaction-&amp;gt;IsBaseLevelForKey(ikey.user_key)) {
        // For this user key:
        // (1) there is no data in higher levels
        // (2) data in lower levels will have larger sequence numbers
        // (3) data in layers that are being compacted here and have
        //     smaller sequence numbers will be dropped in the next
        //     few iterations of this loop (by rule (A) above).
        // Therefore this deletion marker is obsolete and can be dropped.
        // 如果高层还有记录，则 kTypeDeletion 标记不能丢掉。
        // smallest_snapshot 主要是为了快照功能服务
        // 但 ikey.sequence &amp;lt;= compact-&amp;gt;smallest_snapshot 这个判断没看懂
        drop = true;
      }

      last_sequence_for_key = ikey.sequence;
    }

    if (!drop) {
      // Open output file if necessary
      if (compact-&amp;gt;builder == NULL) {
        status = OpenCompactionOutputFile(compact);
        if (!status.ok()) {
          break;
        }
      }
      if (compact-&amp;gt;builder-&amp;gt;NumEntries() == 0) {
        compact-&amp;gt;current_output()-&amp;gt;smallest.DecodeFrom(key);
      }
      compact-&amp;gt;current_output()-&amp;gt;largest.DecodeFrom(key);
      compact-&amp;gt;builder-&amp;gt;Add(key, input-&amp;gt;value());

      // Close output file if it is big enough
      if (compact-&amp;gt;builder-&amp;gt;FileSize() &amp;gt;=
          compact-&amp;gt;compaction-&amp;gt;MaxOutputFileSize()) {
        status = FinishCompactionOutputFile(compact, input);  // 输出新的 SST 文件
        if (!status.ok()) {
          break;
        }
      }
    }

    input-&amp;gt;Next();
  }

  // 中间省略一坨代码

  mutex_.Lock();
  stats_[compact-&amp;gt;compaction-&amp;gt;level() + 1].Add(stats);

  if (status.ok()) {
    status = InstallCompactionResults(compact);
  }

  return status;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;最后调用 InstallCompactionResults，记录版本变化：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;Status DBImpl::InstallCompactionResults(CompactionState* compact) {
  mutex_.AssertHeld();
  Log(options_.info_log,  &amp;quot;Compacted %d@%d + %d@%d files =&amp;gt; %lld bytes&amp;quot;,
      compact-&amp;gt;compaction-&amp;gt;num_input_files(0),
      compact-&amp;gt;compaction-&amp;gt;level(),
      compact-&amp;gt;compaction-&amp;gt;num_input_files(1),
      compact-&amp;gt;compaction-&amp;gt;level() + 1,
      static_cast&amp;lt;long long&amp;gt;(compact-&amp;gt;total_bytes));

  // Add compaction outputs
  compact-&amp;gt;compaction-&amp;gt;AddInputDeletions(compact-&amp;gt;compaction-&amp;gt;edit());
  const int level = compact-&amp;gt;compaction-&amp;gt;level();
  for (size_t i = 0; i &amp;lt; compact-&amp;gt;outputs.size(); i++) {
    const CompactionState::Output&amp;amp; out = compact-&amp;gt;outputs[i];
    compact-&amp;gt;compaction-&amp;gt;edit()-&amp;gt;AddFile(
        level + 1,
        out.number, out.file_size, out.smallest, out.largest);
  }
  return versions_-&amp;gt;LogAndApply(compact-&amp;gt;compaction-&amp;gt;edit(), &amp;amp;mutex_);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Fri, 23 Jun 2017 15:53:23 +0800</pubDate>
        <link>http://masutangu.com/2017/06/leveldb_1/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/06/leveldb_1/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>链接和装载</title>
        <description>&lt;p&gt;本文是读《程序员的自我修养: 链接、装载与库》所整理的读书笔记。&lt;/p&gt;

&lt;h1&gt;概论&lt;/h1&gt;

&lt;p&gt;从源文件到可执行文件，可以分解为四个过程：&lt;strong&gt;预处理&lt;/strong&gt;，&lt;strong&gt;编译&lt;/strong&gt;，&lt;strong&gt;汇编&lt;/strong&gt;，&lt;strong&gt;链接&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;预处理主要完成以下工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;展开所有宏定义，删除 #define&lt;/li&gt;
&lt;li&gt;处理所有条件预编译指令&lt;/li&gt;
&lt;li&gt;处理 #include 预编译指令。将被包含的文件插入到该预编译指令的位置&lt;/li&gt;
&lt;li&gt;删除所有注释&lt;/li&gt;
&lt;li&gt;添加行号和文件名标识，以便编译时编辑器产生调试用的行号信息以及编译产生错误或警告时的行号信息&lt;/li&gt;
&lt;li&gt;保留所有 #pragma 编译器指令&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;编译的过程即把预处理完的文件进行一系列的词法分析、语法分析、语义分析以及优化后产生相应的汇编代码文件。&lt;/p&gt;

&lt;p&gt;汇编器将汇编代码转变为机器可以执行的指令，即目标文件，再由链接器将多个目标文件输出成最后的可执行文件。链接器负责解决&lt;strong&gt;模块间符号引用&lt;/strong&gt;的问题，链接的过程包括了&lt;strong&gt;地址和空间分配&lt;/strong&gt;、&lt;strong&gt;符号决议&lt;/strong&gt;和&lt;strong&gt;重定位&lt;/strong&gt;。&lt;/p&gt;

&lt;h1&gt;目标文件&lt;/h1&gt;

&lt;p&gt;目标文件和可执行文件的格式很相似，在 Linux 下统称为 ELF 文件。ELF 文件格式的核心思想是按不同属性分段（section）存储。&lt;/p&gt;

&lt;p&gt;编译后的目标文件格式如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;程序源代码编译后的机器指令通常放在代码段（.text），已初始化的全局变量和静态局部变量放在数据段（.data），.bss 段用于为未初始化的全局变量和静态局部变量预留空间，因此该段在文件中不占据空间。.rodata 段存放的是只读数据，一般是只读变量和字符串常量。&lt;/p&gt;

&lt;p&gt;分段的好处在于：&lt;strong&gt;方便权限控制&lt;/strong&gt;、&lt;strong&gt;提高 CPU 缓存命中率&lt;/strong&gt;和&lt;strong&gt;节省内存&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;下面看个实际的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/*
simplesection.c
linux: gcc -c simplesection.c -o simplesection.o
*/

int printf(const char* format, ...);

int global_init_var = 84;
int global_uninit_var;

void func1(int i) 
{
    printf(&amp;quot;%d\n&amp;quot;, i);
}

int main(void) 
{
    static int static_var = 85;
    static int static_var2;

    int a = 1;
    int b;

    func1(static_var + static_var2 + a + b);
    return a;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;使用 &lt;code&gt;objdump -h&lt;/code&gt; 查看段表的信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意，&lt;code&gt;objdump -h&lt;/code&gt; 只会显示关键的段，可以用 &lt;code&gt;readelf -S&lt;/code&gt; 查看完整的段表信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-5.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;注意这里的 .rel.text 段是重定位表，.symtab 段是符号表。下面会重点说明。&lt;/p&gt;

&lt;p&gt;可以使用 &lt;code&gt;objdump -s -d&lt;/code&gt; 查看各个段的内容：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;可以看到 .data 段前后四个字节分别是是 54000000 和 55000000，即十进制 84 和 85。正好对应 global_init_var 和 static_var 这两个变量。.rodata 段存放了 25640a00，即 %d\n 的 ASCII 字节序。&lt;/p&gt;

&lt;p&gt;接下来用 &lt;code&gt;readelf -h&lt;/code&gt; 看看 ELF 文件的头部：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-4.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;入口地址（entry point address）标识了 ELF 程序的入口虚拟地址，操作系统在加载完该程序后从这个入口地址开始执行进程的指令。可重定位文件一般没有入口地址，即值为 0。&lt;/p&gt;

&lt;h3&gt;符号表&lt;/h3&gt;

&lt;p&gt;用 &lt;code&gt;readelf -s&lt;/code&gt; 看看 ELF 文件的符号表：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-6.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Type 列含义如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;NOTYPE：未知类型&lt;/li&gt;
&lt;li&gt;OBJECT：数据对象&lt;/li&gt;
&lt;li&gt;FUNC：函数或可执行代码&lt;/li&gt;
&lt;li&gt;SECTION：段&lt;/li&gt;
&lt;li&gt;FILE：文件名&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bind 列含义如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LOCAL：局部符号，对目标文件的外部不可见&lt;/li&gt;
&lt;li&gt;GLOBAL：全局符号&lt;/li&gt;
&lt;li&gt;WEAK：弱引用&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;如果符号定义在本目标文件中，那 Ndx 列表示符号所在段在段表中的下标，如果不是定义在本目标文件中或是特殊符号，含义如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ABS：表明该符号包含了一个绝对值，例如文件名符号&lt;/li&gt;
&lt;li&gt;COMMON：表明该符号是一个 COMMON 块类型的符号，一般未初始化的全局变量就是这种类型&lt;/li&gt;
&lt;li&gt;UNDEF：表明该符号未定义，在本目标文件被引用但定义在其他目标文件中&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Value 列含义如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果是符号的定义并且不是 COMMON 块，则表示符号在段中的偏移&lt;/li&gt;
&lt;li&gt;如果是 COMMON 块，则表示对齐属性&lt;/li&gt;
&lt;li&gt;可执行文件中，表示符号的虚拟地址，该虚拟地址对动态链接器来说非常有用&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;静态链接&lt;/h1&gt;

&lt;p&gt;链接器一般采用两步链接的方法来分配空间：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;扫描所有输入目标文件，收集各个段的长度、属性和未位置，并将输入目标文件符号表中的所有符号定义和符号引用汇总到全局符号表。&lt;/li&gt;
&lt;li&gt;读取输入文件中段的数据和重定位信息，进行符号解析与重定位。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;来看一个链接的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;/* a.c */

extern int shared;

int main() 
{
    int a = 100;
    swap(&amp;amp;a, &amp;amp;shared);
}

/* b.c */
int shared = 1;

void swap(int *a, int *b) 
{
    *a ^= *b ^= *a ^= *b;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;可以看到 a.c 中引用了 b.c 的两个符号，先用 objdump 看看 a.o 中代码段的反编译结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-11.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当 a.c 被编译成目标文件时，编译器并不知道 share 和 swap 的地址，因此编译器暂时把 地址 0 看成 shared 的地址：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;13: be 00 00 00 00          mov    $0x0,%esi
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;相似的，调用 swap 的时候使用了临时假地址：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;20: e8 00 00 00 00          callq  25 &amp;lt;main+0x25&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;使用 ld 将 a.o 和 b.o 链接起来：&lt;code&gt;ld a.o b.o -e main -o ab&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;再用 objdump 查看链接前后地址分配的情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-8.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-9.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-10.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;VMA 表示虚拟内存地址，LMA 表示加载地址，正常情况下这两个值是一样的。&lt;/p&gt;

&lt;p&gt;可以发现链接前目标文件所有段的 VMA 都是 0，因为虚拟空间还没分配。链接后可执行文件 ab 的各个段都分配了相应的虚拟地址。&lt;/p&gt;

&lt;p&gt;当链接完成，由于各个段地址已经确定，各个符号在段内的相对地址也是固定的，这样各个符号的绝对地址也已经确定了。可以通过 objdump 观察到 ab 文件中符号地址已经修正了：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-12.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;实际上，链接器是通过 ELF 文件中的重定位表，来找到需要重定位的符号的。&lt;code&gt;objdump -r&lt;/code&gt; 可以查看重定位表的信息：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-13.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;OFFSET 表示该重定位符号在段中的偏移。&lt;/p&gt;

&lt;h1&gt;装载&lt;/h1&gt;

&lt;p&gt;Linux 下创建一个进程，加载可执行文件并执行，大致步骤如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;创建一个独立的虚拟地址空间&lt;/li&gt;
&lt;li&gt;读取可执行文件头，建立虚拟空间与可执行文件的映射关系。&lt;strong&gt;Linux 内核的 VMA 结构就是用与建立虚拟空间和可执行文件的映射关系&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;将 CPU 指令寄存器设置为可执行文件的入口地址，启动运行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;操作系统并不关心可执行文件中各个段的实际内容，只关心段的权限。为了减少内存浪费（映射时以页长作为单位），对于相同权限的段，合并到一起当做一个段进行映射。因此 ELF 可执行文件引入了 segment 的概念。一个 segment 包含一个或多个属性相似的 section。描述 segment 的结构叫程序头（program header），可以使用 &lt;code&gt;readelf -l&lt;/code&gt; 查看 segment 信息。&lt;/p&gt;

&lt;p&gt;VMA 除了用以映射可执行文件的各个 segment 以外，还被用来管理进程的地址空间。进程执行需要的栈和堆，也是以 VMA 形式存在的。可以通过 &lt;code&gt;cat /proc/pid/maps&lt;/code&gt; 查看进程的虚拟空间分布。&lt;/p&gt;

&lt;h1&gt;动态链接&lt;/h1&gt;

&lt;p&gt;为了节省空间，简化程序的更新和发布，引入了动态链接的概念。动态链接的基本思想在于&lt;strong&gt;将链接的过程推迟到运行时&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;由于共享对象的加载地址在编译时是不确定的，因此需要在装载时重定位。但由于装载时重定位会修改指令，没有办法做到同一份指令被多个进程共享，因此引入了&lt;strong&gt;地址无关代码&lt;/strong&gt;（PIC）的概念。其基本思想是把指令中那些需要修改的部分抽离出来放到数据部分，这样的话指令部分可以保持不变，被多个进程共享，而数据部分每个进程都有一个副本。&lt;/p&gt;

&lt;p&gt;当使用 PIC 编译时，模块内的数据引用和函数访问是通过相对寻址的方式。模块间的数据引用和函数访问则通过数据段的全局偏移表（GOT）来实现。&lt;/p&gt;

&lt;p&gt;使用 gcc 编译时，指定 &lt;code&gt;-shared&lt;/code&gt; 使用装载时重定位的方法，如果指定了 &lt;code&gt;fPIC&lt;/code&gt; 则产生地址无关的共享对象。&lt;/p&gt;

&lt;p&gt;为了提高动态链接的效率，引入了 PLT 来实现延迟绑定。&lt;/p&gt;

&lt;p&gt;动态链接需要注意&lt;strong&gt;全局符号介入&lt;/strong&gt;的问题，当一个符号需要被加入全局符号表时，如果相同的符号名已经存在，则后加入的符号将被忽略。来看看下面的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/* a1.c */

#include &amp;lt;stdio.h&amp;gt;

void a()
{
    printf(&amp;quot;a1.c\n&amp;quot;);
}

/* a2.c */
#include &amp;lt;stdio.h&amp;gt;

void a()
{
    printf(&amp;quot;a2.c\n&amp;quot;);
}

/* b1.c */
void a();

void b1()
{
    a();
}

/* b2.c */
void a();

void b2() 
{
    a();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;假设 b1.so 依赖于 a1.so，b2.so 依赖于 a2.so。将 b1.so 与 a1.so 进行链接，b2.so 与 a2.so 进行链接：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;gcc -fPIC -shared a1.c -o a1.so
gcc -fPIC -shared a2.c -o a2.so
gcc -fPIC -shared b1.c a1.so -o b1.so
gcc -fPIC -shared b2.c a2.so -o b2.so
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;当有程序同时使用 b1.c 的函数 b1 和 b2.c 中的函数 b2 时：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/* main.c */

#include &amp;lt;stdio.h&amp;gt;

void b1();
void b2();

int main()
{
    b1();
    b2();
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;编译并运行：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-16.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;观察到输出是两个 a1.c，意味着 a2.c 的 a() 函数被忽略了。&lt;/p&gt;

&lt;p&gt;如果是采用静态编译，则链接时会报重定义的错误：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-17.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再来看看另一个有趣的例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/* foo.c */
#include &amp;lt;stdio.h&amp;gt;

struct {
    int a;
    int b;
} b = { 3, 3 };

int main();

void foo()
{
    b.a = 4;
    b.b = 4;
    printf(&amp;quot;foo: b.a=%d, b.b=%d\n&amp;quot;, b.a, b.b);
}

/* t1.c */
#include &amp;lt;stdio.h&amp;gt;

int b = 1;
int c = 1;

int main()
{
    int count = 5;
    while (count-- &amp;gt; 0) {
        t2();
        foo();
        printf(&amp;quot;t1: b=%d, c=%d\n&amp;quot;, b, c);
        sleep(1);
    }
    return 0;
}

/* t2.c */
#include &amp;lt;stdio.h&amp;gt;

int b;
int c;

int t2()
{
    printf(&amp;quot;t2: b=%d, c=%d\n&amp;quot;, b, c);
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;编译：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;gcc -shared -fPIC foo.c -o foo.so 
gcc  t1.c t2.c foo.so -o test -Xlinker -rpath ./
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;输出结果：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-18.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其实在动态链接时，foo.c 里定义的 struct b 符号被忽略了（因为 t1.c 里已经定义了符号 b）。因此在后续调用 foo() 时，&lt;code&gt;b.a = 4&lt;/code&gt; 中 b.a 的地址其实是 t1.c 文件中变量 b 的地址，&lt;code&gt;b.b = 4&lt;/code&gt; 中 b.b 的地址其实是 t1.c 文件中变量 c 的地址（因为 t1.c 中变量 b 和 c 的地址刚好相邻）。&lt;/p&gt;

&lt;p&gt;由于可能存在全局符号介入的问题，模块内函数的调用不能用相对地址调用，编译器会将其当做模块外部符号来处理，使用 .got.plt 进行重定位。因此为了提高模块内函数调用的效率，&lt;strong&gt;建议使用 static 关键字将被调用的函数设置为编译单元私有函数&lt;/strong&gt;。此时编译器会采用相对地址的编译方式，因为能确保该函数不会被其他模块所覆盖。&lt;/p&gt;

&lt;h1&gt;内存&lt;/h1&gt;

&lt;p&gt;下图为 Linux 进程内存空间的典型布局：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-14.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中 dynamic libraries 用于映射装载的动态链接库。&lt;/p&gt;

&lt;h2&gt;栈&lt;/h2&gt;

&lt;p&gt;栈在程序运行中起了举足轻重的地位。栈保存了一个函数调用所需要的维护信息，通常称为堆栈帧（Stack Frame）。通常有以下内容：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;函数的返回地址和参数&lt;/li&gt;
&lt;li&gt;临时变量，包括函数的非静态局部变量以及编译器自动生成的其他临时变量&lt;/li&gt;
&lt;li&gt;保存的上下文，包括函数调用前后需要保存的寄存器&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;i386 中，esp 寄存器始终指向栈顶，ebp 寄存器指向了堆栈帧的一个固定位置，因此 ebp 又称为帧指针（Frame Pointer），如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linker-loader-library-note/llustration-15.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;i386 的函数调用过程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;把参数压入栈中&lt;/li&gt;
&lt;li&gt;把当前指令的下一条指令的地址压入栈中&lt;/li&gt;
&lt;li&gt;跳转到函数体执行&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;i386 的函数体开头大致如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;push ebp: 把旧的 ebp 压入栈中 &lt;/li&gt;
&lt;li&gt;mov ebp, esp: 将 esp 的值赋给 ebp，此时 ebp 和 esp 都指向栈顶，栈顶保存的就是 old ebp&lt;/li&gt;
&lt;li&gt;sub esp, XXX: 可选，在栈上分配 XXX 字节的临时空间&lt;/li&gt;
&lt;li&gt;push XXX: 可选，如有必要，保存名为 XXX 的寄存器 &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;函数返回的流程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;pop XXX: 可选，如有必要，恢复保存过的寄存器的值&lt;/li&gt;
&lt;li&gt;mov esp, ebp: 恢复 ESP，回收局部变量的空间&lt;/li&gt;
&lt;li&gt;pop ebp: 从栈顶恢复旧的 ebp 的值&lt;/li&gt;
&lt;li&gt;ret: 从栈顶取得返回地址，并跳转到该位置&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;eax 寄存器通常是函数返回值的通道。函数将返回值存储在 eax 中，返回后调用方读取 eax 得到函数的返回值。由于 eax 只有 4 个字节，如果返回的是 5~8 字节对象的情况，惯例是采用 eax 和 edx 联合返回的方式。超过 8 字节的，则通过临时变量的方式来实现：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用者在栈上开辟了一片空间，并且将这块空间的一部分作为传递返回值的临时对象 temp&lt;/li&gt;
&lt;li&gt;将 temp 对象的地址作为隐藏参数传递给被调用的函数&lt;/li&gt;
&lt;li&gt;被调用的函数将返回值拷贝给 temp 对象，并将 temp 对象的地址用 eax 传出&lt;/li&gt;
&lt;li&gt;返回后，调用者只需要拷贝 eax 指向的 temp 对象的内容就能得到返回值&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这也是为什么不能直接对函数返回值进行取址的原因，因为函数返回后临时变量 temp 就被释放掉了。&lt;/p&gt;

&lt;h2&gt;堆&lt;/h2&gt;

&lt;p&gt;Linux 提供了两种堆空间分配的方式：brk() 和 mmap()。&lt;/p&gt;

&lt;p&gt;brk() 的作用是设置进程数据段的结束地址，它可以扩大或缩小数据段。mmap() 的作用是向操作系统申请一段虚拟地址空间，可以是映射到某个文件也可以是匿名空间。&lt;/p&gt;

&lt;p&gt;glibc 的 malloc 函数，对小于 128 KB 的请求来说，会在现有的堆空间里按照堆分配算法分配一块空间并返回。对于大于 128 KB 的请求来说，它会使用 mmap() 函数分配一块匿名空间。&lt;/p&gt;
</description>
        <pubDate>Sat, 25 Feb 2017 10:55:19 +0800</pubDate>
        <link>http://masutangu.com/2017/02/linker-loader-library-note/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/02/linker-loader-library-note/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>Linux 性能监控</title>
        <description>&lt;p&gt;本文是对 &lt;a href=&quot;http://www.vpsee.com/2009/11/linux-system-performance-monitoring-introduction/&quot;&gt;《Linux 性能监测》&lt;/a&gt; 系列文章的读书笔记，并在此基础上丰富。&lt;/p&gt;

&lt;h2&gt;CPU 相关&lt;/h2&gt;

&lt;h3&gt;vmstat&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0 164412 143200  35916 243216    0    0    12    11   46   22  1  1 98  0  0
 0  0 164412 142960  35916 243260    0    0     0     0  583  854  2  1 97  0  0
 0  0 164412 142960  35916 243260    0    0     0     0  940 1184  2  1 97  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;参数说明：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;r:    可运行队列的线程数，这些线程都是可运行状态，只不过 CPU 暂时不可用&lt;/li&gt;
&lt;li&gt;b:    被 blocked 的进程数，正在等待 IO 请求&lt;/li&gt;
&lt;li&gt;in:   被处理过的中断数&lt;/li&gt;
&lt;li&gt;cs:   系统上正在做上下文切换的数目&lt;/li&gt;
&lt;li&gt;us:   用户占用 CPU 的百分比&lt;/li&gt;
&lt;li&gt;sy:   内核和中断占用 CPU 的百分比&lt;/li&gt;
&lt;li&gt;wa:   所有可运行的线程被 blocked 以后都在等待 IO，这时候 CPU 空闲的百分比&lt;/li&gt;
&lt;li&gt;id:   CPU 完全空闲的百分比&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;合理的参数范围：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CPU 利用率：如果 CPU 达到 100％ 利用率，那么 us 和 sy 占比应该达到这样一个平衡：65％－70％ User Time，30％－35％ System Time，0％－5％ Idle Time&lt;/li&gt;
&lt;li&gt;上下文切换：上下文切换应该和 CPU 利用率联系起来看，如果能保持上面的 CPU 利用率平衡，大量的上下文切换是可以接受的&lt;/li&gt;
&lt;li&gt;可运行队列：每个处理器的可运行队列不应该超过3个线程，比如：双处理器系统的可运行队列里不应该超过6个线程&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;案例 1：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 4  0    140 2915476 341288 3951700  0    0     0     0 1057  523 19 81  0  0  0
 4  0    140 2915724 341296 3951700  0    0     0     0 1048  546 19 81  0  0  0
 4  0    140 2915848 341296 3951700  0    0     0     0 1044  514 18 82  0  0  0
 4  0    140 2915848 341296 3951700  0    0     0    24 1044  564 20 80  0  0  0
 4  0    140 2915848 341296 3951700  0    0     0     0 1060  546 18 82  0  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上面的输出可以看出：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;system time（sy）一直保持在 80％ 以上，而且上下文切换较低（cs），说明某个进程可能一直霸占着 CPU&lt;/li&gt;
&lt;li&gt;run queue（r）刚好在4个&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;案例 2：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
14  0    140 2904316 341912 3952308  0    0     0   460 1106 9593 36 64  1  0  0
17  0    140 2903492 341912 3951780  0    0     0     0 1037 9614 35 65  1  0  0
20  0    140 2902016 341912 3952000  0    0     0     0 1046 9739 35 64  1  0  0
17  0    140 2903904 341912 3951888  0    0     0    76 1044 9879 37 63  0  0  0
16  0    140 2904580 341912 3952108  0    0     0     0 1055 9808 34 65  1  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上面的输出可以看出：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;context switch（cs）比 interrupts（in）要高得多，说明内核不得不来回切换进程&lt;/li&gt;
&lt;li&gt;进一步观察发现 system time（sy）很高而 user time（us）很低，而且加上高频度的上下文切换（cs），说明正在运行的应用程序调用了大量的系统调用&lt;/li&gt;
&lt;li&gt;run queue（r）在14个线程以上，按照这个测试机器的硬件配置（四核），应该保持在12个以内。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;案例 3：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 5  0     92 185724 735036 2736384   0    0     2    11    0    1  2  0 98  0  0
 7  0     92 184980 735044 2736376   0    0     0   124 6682 7806 39  3 58  0  0
 6  0     92 184856 735044 2737064   0    0     0  1888 6721 7601 38  5 49  8  0
 2  0     92 184732 735044 2737064   0    0     0     0 6549 7525 46  4 50  0  0
 3  0     92 183988 735044 2737904   0    0     0     0 6375 7081 45  3 52  0  0
 1  0     92 184360 735048 2738156   0    0     0     0 6764 7601 44  4 51  0  0 
 8  1     92 183368 735048 2738508   0    0     0  1384 6774 8005 42  4 54  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;cpu 利用率上不去，vmstat 输出如上，分析可能的瓶颈：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;si、so 都是 0，free 也有，说明内存足够，排除内存。&lt;/li&gt;
&lt;li&gt;bi、bo 都不大，所以 io 似乎不严重，排除硬盘&lt;/li&gt;
&lt;li&gt;cs、in 都较大，说明 CPU 频于应付上下文切换和中断，而且从 r 的数字来看正在等 CPU 的进程较多，所以猜测服务器上运行的进程较多，CPU 疲于切换进程以及应付中断，猜测瓶颈是 CPU。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;mpstat&lt;/h3&gt;

&lt;p&gt;mpstat 和 vmstat 类似，不同的是 mpstat 可以输出多个处理器的数据。&lt;/p&gt;

&lt;h3&gt;ps&lt;/h3&gt;

&lt;p&gt;ps 用于查看某个程序、进程占用的 CPU 资源。&lt;/p&gt;

&lt;h3&gt;实践：定位 CPU 100% 的问题&lt;/h3&gt;

&lt;p&gt;某个进程 CPU 100% 了，如何定位？&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;如果是多线程，使用 &lt;code&gt;ps -eL |grep 进程id&lt;/code&gt;，找出占用 CPU 最长时间的线程 id&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;strace -p 线程id -tt&lt;/code&gt; 观察调用的系统调用&lt;/li&gt;
&lt;li&gt;使用 &lt;code&gt;perf top&lt;/code&gt; 看看哪个函数占用率最高&lt;/li&gt;
&lt;li&gt;或使用 &lt;code&gt;watch pstack 线程 id&lt;/code&gt; 看看调用堆栈&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;之前工作中遇到过 CPU 使用率很高，通过 &lt;code&gt;perf top&lt;/code&gt; 和 &lt;code&gt;pstack&lt;/code&gt; 观察到写磁盘操作很多，推测是日志打印过多导致 CPU 使用率暴涨，调低了日志等级后顺利解决。&lt;/p&gt;

&lt;h2&gt;内存相关&lt;/h2&gt;

&lt;p&gt;kswapd daemon 用来检查 pages_high 和 pages_low，如果可用内存少于 pages_low，kswapd 就开始扫描并试图释放 32个页面，并且重复扫描释放的过程直到可用内存大于 pages_high 为止。&lt;/p&gt;

&lt;p&gt;扫描的时候检查3件事：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;如果页面没有修改，把页放到可用内存列表里&lt;/li&gt;
&lt;li&gt;如果页面被文件系统修改，把页面内容写到磁盘上&lt;/li&gt;
&lt;li&gt;如果页面被修改了，但不是被文件系统修改的，把页面写到交换空间&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;pdflush daemon 用来同步文件相关的内存页面，把内存页面及时同步到硬盘上。比如打开一个文件，文件被导入到内存里，对文件做了修改后并保存后，内核并不马上保存文件到硬盘，由 pdflush 决定什么时候把相应页面写入硬盘，这由一个内核参数 vm.dirty_background_ratio 来控制，比如下面的参数显示脏页面（dirty pages）达到所有内存页面10％的时候开始写入硬盘。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# /sbin/sysctl -n vm.dirty_background_ratio
10
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;vmstat&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 0  0 164412 143200  35916 243216    0    0    12    11   46   22  1  1 98  0  0
 0  0 164412 142960  35916 243260    0    0     0     0  583  854  2  1 97  0  0
 0  0 164412 142960  35916 243260    0    0     0     0  940 1184  2  1 97  0  0
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;swpd: 已使用的 SWAP 空间大小，KB 为单位&lt;/li&gt;
&lt;li&gt;free: 可用的物理内存大小，KB 为单位&lt;/li&gt;
&lt;li&gt;buff: 物理内存用来缓存读写操作的 buffer 大小，KB 为单位&lt;/li&gt;
&lt;li&gt;cache: 物理内存用来缓存进程地址空间的 cache 大小，KB 为单位&lt;/li&gt;
&lt;li&gt;si: 数据从 SWAP 读取到 RAM（swap in）的大小，KB 为单位&lt;/li&gt;
&lt;li&gt;so: 数据从 RAM 写到 SWAP（swap out）的大小，KB 为单位&lt;/li&gt;
&lt;li&gt;bi: 从块设备读取（block in）的大小，block 为单位&lt;/li&gt;
&lt;li&gt;bo: 写入块设备（block out）的大小，block 为单位&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;# vmstat 1
procs -----------memory---------- ---swap-- -----io---- --system-- -----cpu------
 r  b   swpd   free   buff  cache    si    so    bi    bo   in   cs us sy id  wa st
 0  3 252696   2432    268   7148  3604  2368  3608  2372  288  288  0  0 21  78  1
 0  2 253484   2216    228   7104  5368  2976  5372  3036  930  519  0  0  0 100  0
 0  1 259252   2616    128   6148 19784 18712 19784 18712 3821 1853  0  1  3  95  1
 1  2 260008   2188    144   6824 11824  2584 12664  2584 1347 1174 14  0  0  86  0
 2  1 262140   2964    128   5852 24912 17304 24952 17304 4737 2341 86 10  0   0  4
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上面是一个频繁读写交换区的例子，可以观察到：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;buff 稳步减少说明系统知道内存不够了，kwapd 正在从 buff 那里借用部分内存&lt;/li&gt;
&lt;li&gt;kswapd 持续把脏页面写到 swap 交换区（so），并且从 swapd 逐渐增加看出确实如此。根据上面讲的 kswapd 扫描时检查的三件事，如果页面被修改了，但不是被文件系统修改的，把页面写到 swap，所以这里 swapd 持续增加&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;free&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ free
             total       used       free     shared    buffers     cached
Mem:       1014432     884460     129972      10168      43468     248580
-/+ buffers/cache:     592412     422020
Swap:      1046524     164376     882148
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;total: 总内存大小&lt;/li&gt;
&lt;li&gt;used: 已经使用的内存大小，包含 cached、buffers 和 shared 部分&lt;/li&gt;
&lt;li&gt;free: 空闲的内存大小&lt;/li&gt;
&lt;li&gt;shared: 进程间共享内存&lt;/li&gt;
&lt;li&gt;buffers: buffer cache&lt;/li&gt;
&lt;li&gt;cached: page cache&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;-/+ buffers/cache 看作两部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;-buffers/cache：正在使用的内存大小，其值等于used1 减去 buffers1 再减去 cached1&lt;/li&gt;
&lt;li&gt;+buffers/cache：可用的内存大小，其值等于 free1 加上 buffers1 再加上 cached&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当空闲物理内存不多时，不一定表示系统运行状态很差，因为内存的 cached 及 buffers 部分可以随时被重用。swap 如果被频繁调用，bi 和 bo 长时间不为 0，才是内存资源是否紧张的依据。通过 free 看资源时，实际主要关注 -/+ buffers/cache 的值就可以知道内存到底够不够了。&lt;/p&gt;

&lt;h3&gt;valgrind&lt;/h3&gt;

&lt;p&gt;valgrind 是定位内存泄漏的好工具，使用 &lt;code&gt;valgrind --lead-check=full --log-file=valgrind.log ./a.out&lt;/code&gt; 即可在进程结束运行后输出内存泄露报告。&lt;/p&gt;

&lt;h3&gt;maps, smaps and status&lt;/h3&gt;

&lt;p&gt;参考这篇文章：&lt;a href=&quot;https://jameshunt.us/writings/smaps.html&quot;&gt;maps, smaps and Memory Stats!&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;pmap&lt;/h3&gt;

&lt;p&gt;待补充&lt;/p&gt;

&lt;h2&gt;IO 相关&lt;/h2&gt;

&lt;h3&gt;Buffers &amp;amp; Cached&lt;/h3&gt;

&lt;p&gt;Linux 利用虚拟内存极大的扩展了程序地址空间，使得原来物理内存不能容下的程序也可以通过内存和硬盘之间的不断交换（把暂时不用的内存页交换到硬盘，把需要的内存页从硬盘读到内存）来赢得更多的内存，看起来就像物理内存被扩大了一样。如果数据不在内存里就引起一个缺页中断（Page Fault），然后从硬盘读取缺页，并把缺页缓存到物理内存里。缺页中断可分为主缺页中断（Major Page Fault）和次缺页中断（Minor Page Fault），要&lt;strong&gt;从磁盘读取数据而产生的中断是主缺页中断&lt;/strong&gt;；数据已经被读入内存并被缓存起来，&lt;strong&gt;从内存缓存区中而不是直接从硬盘中读取数据而产生的中断是次缺页中断&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;从内存缓存区（页高速缓存）读取页比从硬盘读取页要快得多，所以 Linux 内核希望能尽可能产生次缺页中断（从页高速缓存读），并且尽可能避免主缺页中断（从硬盘读），这样随着次缺页中断的增多，缓存区也逐步增大，直到系统只有少量可用物理内存的时候 Linux 才开始释放一些不用的页。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ cat /proc/meminfo
MemTotal:        1014432 kB
MemFree:          137884 kB
Buffers:           43732 kB
Cached:           248744 kB
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这台服务器总共有 10GB 物理内存（MemTotal），1GB 左右可用内存（MemFree），43 MB 左右用来做磁盘缓存（Buffers），248 MB 左右用来做文件缓存区（Cached）。&lt;/p&gt;

&lt;p&gt;Linux 中内存页面有三种类型：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Read pages: 只读页（或代码页），通过主缺页中断从硬盘读取的页面，包括不能修改的静态文件、可执行文件、库文件等。当内核需要它们的时候把它们读到内存中，当内存不足的时候，内核就释放它们到空闲列表，当程序再次需要它们的时候需要通过缺页中断再次读到内存。&lt;/li&gt;
&lt;li&gt;Dirty pages: 脏页，指在内存中被修改过的数据页，比如文本文件等。这些文件由 pdflush 负责同步到硬盘，内存不足的时候由 kswapd 和 pdflush 把数据写回硬盘并释放内存。&lt;/li&gt;
&lt;li&gt;Anonymous pages: 匿名页，属于某个进程但是又和任何文件无关联，不能被同步到硬盘上，内存不足的时候由 kswapd 负责将它们写到交换分区并释放内存。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;顺序 IO 和 随机 IO&lt;/h3&gt;

&lt;p&gt;IO 可分为顺序 IO 和 随机 IO 两种。顺序 IO 重视每次 IO 的吞吐能力（KB per IO），而随机 IO 重视的是每秒能 IOPS 的次数，而不是每次 IO 的吞吐能力（KB per IO）。&lt;/p&gt;

&lt;h3&gt;Swap&lt;/h3&gt;

&lt;p&gt;当系统没有足够物理内存来应付所有请求的时候就会用到 swap 设备，swap 设备可以是一个文件，也可以是一个磁盘分区。使用 swap 的代价非常大，如果系统没有物理内存可用，就会频繁 swapping。如果 swap 设备和程序正要访问的数据在同一个文件系统上，那会碰到严重的 IO 问题，最终导致整个系统迟缓，甚至崩溃。swap 设备和内存之间的 swapping 状况是判断 Linux 系统性能的重要参考，我们已经有很多工具可以用来监测 swap 和 swapping 情况，比如：top、cat /proc/meminfo、vmstat。&lt;/p&gt;

&lt;h2&gt;Network 相关&lt;/h2&gt;

&lt;h3&gt;iptraf&lt;/h3&gt;

&lt;p&gt;两台主机之间有网线（或无线）、路由器、交换机等设备，测试两台主机之间的网络性能的一个办法就是在这两个系统之间互发数据并统计结果，看看吞吐量、延迟、速率如何。iptraf 就是一个很好的查看本机网络吞吐量的好工具。&lt;/p&gt;

&lt;h3&gt;tcpdump&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;sudo tcpdump -i eth0 port 80  -w output.dump    // 指定端口
sudo tcpdump -i eth0 src port 80                // 指定源端口
sudo tcpdump -i eth0 dst port 80                // 指定目的端口
sudo tcpdump -i eth0 src host 192.168.1.1       // 指定源地址
sudo tcpdump -i eth0 dst host 192.168.1.1       // 指定目的地址
sudo tcpdump -i eth0 tcp                        // 协议过滤
sudo tcpdump -i eth0 udp                        // 协议过滤
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;netstat&lt;/h3&gt;

&lt;p&gt;使用 netstat 实时监控 udp 网络收发包情况：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;$ watch netstat -su

IcmpMsg:
    InType0: 19
    InType3: 55
    InType8: 918828
    InType11: 5
    OutType0: 918828
    OutType3: 55
    OutType8: 20
Udp:
    101881 packets received
    51 packets to unknown port received.
    0 packet receive errors  // 关注该项 如果持续增长，说明在丢包。网卡收到了，但是应用层来不及处理
    164740 packets sent
UdpLite:
IpExt:
    InNoRoutes: 8
    OutMcastPkts: 2
    InBcastPkts: 1938486
    InOctets: 26851362935
    OutOctets: 18903227033
    OutMcastOctets: 80
    InBcastOctets: 300768203
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;常用工具汇总&lt;/h2&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;工具&lt;/th&gt;
&lt;th&gt;简单介绍&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;top&lt;/td&gt;
&lt;td&gt;查看进程活动状态以及一些系统状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;vmstat&lt;/td&gt;
&lt;td&gt;查看系统状态、硬件和系统信息等&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;iostat&lt;/td&gt;
&lt;td&gt;查看CPU 负载，硬盘状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sar&lt;/td&gt;
&lt;td&gt;综合工具，查看系统状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mpstat&lt;/td&gt;
&lt;td&gt;查看多处理器状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;netstat&lt;/td&gt;
&lt;td&gt;查看网络状况&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;iptraf&lt;/td&gt;
&lt;td&gt;实时网络状况监测&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tcpdump&lt;/td&gt;
&lt;td&gt;抓取网络数据包，详细分析&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;tcptrace&lt;/td&gt;
&lt;td&gt;数据包分析工具&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;netperf&lt;/td&gt;
&lt;td&gt;网络带宽工具&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;dstat&lt;/td&gt;
&lt;td&gt;综合工具，综合了 vmstat, iostat, ifstat, netstat 等多个信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;相关资料&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://www.thomas-krenn.com/en/wiki/Linux_Performance_Measurements_using_vmstat&quot;&gt;《Linux Performance Measurements using vmstat》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://linuxwiki.github.io/NetTools/tcpdump.html&quot;&gt;《tcpdump使用技巧》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.ibm.com/developerworks/cn/linux/l-cn-perf1/&quot;&gt;《Perf -- Linux下的系统性能调优工具》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.51testing.com/html/56/490256-3711169.html&quot;&gt;《通过/proc查看Linux内核态调用栈来定位问题》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://linuxtools-rst.readthedocs.io/zh_CN/latest/advance/03_optimization.html&quot;&gt;《Linux性能优化》&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Feb 2017 22:57:39 +0800</pubDate>
        <link>http://masutangu.com/2017/02/linux-performance-monitor/</link>
        <guid isPermaLink="true">http://masutangu.com/2017/02/linux-performance-monitor/</guid>
        
        
        <category>工作</category>
        
      </item>
    
      <item>
        <title>我的 2016</title>
        <description>&lt;p&gt;时间飞逝，又到了写年终总结的时候了。翻回看去年的总结和展望，回想起去年的雄心壮志，今年则是坎坷、困惑与焦虑的一年。&lt;/p&gt;

&lt;h1&gt;回顾过去&lt;/h1&gt;

&lt;p&gt;在这整整一年中，我所思考的和困扰的，可以由三个词来概括：&lt;strong&gt;成绩&lt;/strong&gt;、&lt;strong&gt;成长&lt;/strong&gt;和&lt;strong&gt;价值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;工作已经两年半，对自己目前取得的成绩，对自己技术成长的预期，对自己为团队创造的价值，实话实说，都不满意。&lt;/p&gt;

&lt;p&gt;从今年年初开始，我就有点焦虑，觉得自己没有太多的成长，一直在原地踏步，已经没有刚入职时那种回顾过去会觉得自己突飞猛进的感觉（工作后做的每个比较大的需求，我都会整理保存下来 ppt，回看时就会清楚自己相比起过去进步了多少）。困于瓶颈期时，我尝试更加主动的去做事情。在那段时间，我开始关注些不仅仅是技术上的知识，例如关注了&lt;a href=&quot;https://wanqu.co/&quot;&gt;《湾区日报》&lt;/a&gt;，做了些读书笔记&lt;a href=&quot;http://masutangu.com/2015/12/dewdrop-note-1/&quot;&gt;《水滴石穿》&lt;/a&gt;。那段时间有些收获，但当我尝试把我阅读中收获的这些想法，运用到工作中时，却发现有层层阻碍。其中细节就不展开了，这让我非常沮丧。一方面，我理解在大公司工作，最重要是“稳”。有新的方案，新的想法，首要考虑的不是这个新的方案、新的想法的收益，而是运维成本。另一方面，这也让我觉得在大公司工作非常乏味，每个人的贡献都是固定的，尤其是工程师，你的定位就是执行者。公司也已经有很多很成熟的组件，即使不太适应于业务场景，也能勉强用用，你的工作就是做做接入，其它不需要操心。&lt;/p&gt;

&lt;p&gt;这种状况让我觉得非常的不适应。在学生时代，每一阶段、每个学期你都会学习到新的知识。而在工作中，更多的时候你是在重复做些体力活，例如，复制粘贴的完成一些需求。又例如，一遍遍的用已经成熟的方案去解决一些问题。而我其实不太喜欢这样的工作方式。我蛮希望自己是一个比较有创造力的工程师，我倾向于用不同的方案去完成类似的需求，通过真正的实践来对比不同的方案的优劣性。但在大公司来说，&lt;strong&gt;进度&lt;/strong&gt;和&lt;strong&gt;稳定性&lt;/strong&gt;是首要目标。只有在发展迅猛的前沿/明星项目中，你才有可能遇到各种新的问题，才有得到锻炼的机会。&lt;/p&gt;

&lt;p&gt;互联网不是按照工龄来排资论辈，同样工作三五年，差距可能非常大。有一句话说得好，&lt;strong&gt;“Good judgment comes from experience, experience comes from bad judgment.”&lt;/strong&gt;（正确的判断来自于丰富的经验,而丰富的经验来自错误的判断）。如果工作中没有太多挑战，不能促使你学习进步以应对工作的要求，一味追求保守无法得到犯错踩坑进步的机会，那你就应该停下来思考自己的未来了。我非常不希望把工作当做是一个任务，我希望工作是融于生活的，能带给我挑战和战胜难题的动力，能带给我解决问题后的成就感。如果说做为工程师，工作于己如同体力劳动般每日重复，那和流水线工人又有什么区别呢？&lt;/p&gt;

&lt;p&gt;再一个让我不适应的，是大公司的考核机制。并不像在学生时代，你的排名和你考出来的成绩相关，和你上课积不积极听讲，有没经常举手回答问题，一点关系都没有。所以你的成绩很差，抱歉，是你不够努力，你知道是自己的原因，所以你会努力去学习让自己进步。工作则不是如此简单纯粹。由于工作中有挑战的难点并不多，每个人做的事情都差不多，那只好看谁做事比较积极主动（并非吐槽，我也非常理解）。而我不太喜欢“伪加班”，也希望工作完成后能有更多自己的时间去学习充电。因此，工作后自己取得的绩效非常平庸。我意识到再这样下去，职业生涯也许就这样了。做为一个已经不算新人的员工来说，我渴望做出成绩，希望能为团队贡献更多的价值。我觉得自己还有很多的能量，我能做的不仅仅是完成我手上的工作。我也意识需要到达一定的职位，才能去推动些什么，去改变些什么。但以我这平庸的考核，我对自己未来的发展不抱有太多的信心，所以我开始寻求改变。&lt;/p&gt;

&lt;p&gt;既然不想再在大公司做了，我开始寻找一些有意思的创业公司。在 v2ex 上逛的时候，&lt;a href=&quot;https://www.xiaohongshu.com/&quot;&gt;小红书&lt;/a&gt; 吸引了我的注意。CTO 来自前谷歌中国工程院副院长，团队很多海归名校的背景，非常有吸引力。在经过电面，飞到上海去面试后，我拿到了offer。然而犹豫再三，我还是放弃了。放弃的原因主要是因为我资历尚浅，5月份拿到 offer，那时我才工作了一年多，当时小红书的开发团队已经有几十人，已经算是个大团队了。但不得不说，面试官给我的感觉非常的好，如果是在更早期，团队还是小规模的时候，我一定愿意加入这样的团队。&lt;/p&gt;

&lt;p&gt;之后就在公司内部寻找些机会，7月份到了现在的游戏工作室。小团队，后台只有几个人，听起来很有成就感。转岗之前我也有点小担心，担心难以融入，担心过来后也是打打杂，幸好过来后发现多虑了。工作室给我的感觉，很明显，大家共同的目标就是把游戏做好。当然从做社交，到做游戏，一开始还是有些不适应。做社交，本质上是各类存储的设计。游戏则不太一样，复杂的都是在业务逻辑。&lt;/p&gt;

&lt;p&gt;下半年的工作，新的环境，新的方向。学习了新的后台框架，对比之前用的框架，自己造了个轮子，写了篇文章&lt;a href=&quot;http://masutangu.com/2016/08/simple-async-framework/&quot;&gt;《简单异步应用框架的实现》&lt;/a&gt;，对后台异步框架的设计有一些了解，不再局限于只会用框架了。浅读了 libuv 和 libco 的源码，同样写了两篇文章&lt;a href=&quot;http://masutangu.com/2016/10/libuv-source-code/&quot;&gt;《Libuv 源码阅读》&lt;/a&gt; 和 &lt;a href=&quot;http://masutangu.com/2016/10/learn-libco/&quot;&gt;《浅读 Libco》&lt;/a&gt;，对异步和协程两种模式都有了进一步的认识。之后，在日常查问题的时候，我意识到自己定位问题的能力有所缺失，主要是对 linux 的各种监控系统状态的命令还不熟悉，操作系统和网络的知识也忘掉差不多了，所以决定重新翻读下 《UNIX 环境高级编程》、《现代操作系统》，并结合 《Linux 内核设计与实现》，了解些操作系统的理论和实现，这个系列的文章&lt;a href=&quot;http://masutangu.com/2016/11/linux-kernel-serial-1/&quot;&gt;《Linux 内核系列－进程》&lt;/a&gt; 还没写完。&lt;/p&gt;

&lt;p&gt;经过这阵子的摸索，我明确了之后的突破点，找到了进步的方向。虽然说，这一年，我有很多困惑、迷茫和焦虑，心情经常非常差，情绪起伏也很大。我明白这些都是成长的必经之路，这么看来，这些起起伏伏，也是蛮值得的。&lt;/p&gt;

&lt;h1&gt;展望未来&lt;/h1&gt;

&lt;p&gt;新的一年，工作上认真努力，不必多说。这里来聊聊新的一年，个人方面，我想做些什么。&lt;/p&gt;

&lt;p&gt;今年我意识到，对于大多数项目来说，技术并不是最重要的，只要不出问题就好（虽然我热爱技术，但我也不得不承认这点）。那技术人员应该如何发挥更大的价值呢？&lt;/p&gt;

&lt;p&gt;我给自己定的目标是：&lt;strong&gt;提高核心竞争力&lt;/strong&gt;和&lt;strong&gt;变得更全面&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;提升技术能力，这是首要目标。我希望新的一年可以把基础打扎实了，作为后台开发，操作系统和网络知识要打牢。另外了解业界流行的中间件（消息队列、数据库等）的实现，比较深入的选择一个方向（游戏引擎、数据分析、图形学、编程语言等）去研究。&lt;/p&gt;

&lt;p&gt;另外在公司工作，技能点很容易变得非常窄。我希望自己可以变得更加全面，不希望把自己局限于后台开发，也不仅局限于技术。新的一年，我希望自己能够做一个上线的 side project 并用心运营。目前看来我应该会选择做一款独立游戏，技术上独立完成前台－接入层－后台的实现，也借此学习下游戏策划的一些思想，让自己更加了解游戏这个行业。&lt;/p&gt;

&lt;h1&gt;总结心得&lt;/h1&gt;

&lt;p&gt;今天读了陈皓的&lt;a href=&quot;http://coolshell.cn/articles/17583.html&quot;&gt;《技术人员的发展之路》&lt;/a&gt;，写的很好，推荐大家都读一读。这一年，有两句话，我经常对自己说的，一是：&lt;strong&gt;不忘初心&lt;/strong&gt;，二是：&lt;strong&gt;Pursue excellence, and success will follow&lt;/strong&gt; (追求卓越，成功就会如期而至)。&lt;/p&gt;

&lt;p&gt;不忘初心，是提醒自己，选择了计算机的道路，是因为我喜欢编程，喜欢创造。不要因为眼前的失意去妥协自己。希望自己工作三年，五年，十年，都能保持学生的心态。&lt;strong&gt;stay hungry, stay foolish&lt;/strong&gt;。 &lt;/p&gt;

&lt;p&gt;追求卓越，是因为我相信，让自己成为一个优秀的工程师，比拿到好的绩效更加重要。自己要为自己的职业生涯负责，更勇敢的去追求梦想。&lt;/p&gt;

&lt;p&gt;大公司工作，可以带给你光环，但自己要想清楚，去掉光环后，自己还剩下些什么。也许我们都是平凡人，但平凡人也希望做出稍微那么不平凡的成绩。2017 年，希望自己不留遗憾！&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Dec 2016 22:19:43 +0800</pubDate>
        <link>http://masutangu.com/2016/12/review/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/12/review/</guid>
        
        
        <category>随笔</category>
        
      </item>
    
      <item>
        <title>Linux 内核系列－文件系统和 IO</title>
        <description>&lt;p&gt;本系列文章为阅读《现代操作系统》和《Linux 内核设计与实现》所整理的读书笔记，源代码取自 Linux-kernel 2.6.34 版本并有做简化。&lt;/p&gt;

&lt;h1&gt;概念&lt;/h1&gt;

&lt;p&gt;如果能把文件看成是一种地址空间，那么就离理解文件不远了。（文件类似虚拟地址空间，相应的磁盘地址对应内存物理地址，通过 inode 来管理映射关系，类似页表的作用）。&lt;/p&gt;

&lt;h2&gt;文件系统的实现&lt;/h2&gt;

&lt;p&gt;文件系统存放在磁盘上。多数磁盘划分为一个或多个区，每个分区有一个独立的文件系统。磁盘的 0 号扇区称为主引导记录（MBR），用来引导计算机。在 MBR 结尾是分区表，给出每个分区的起始和结束地址。&lt;/p&gt;

&lt;p&gt;文件系统通常包含了超级块（包含文件系统的关键参数）、空闲空间管理、i节点、根目录以及文件存储区。&lt;/p&gt;

&lt;h3&gt;文件的实现&lt;/h3&gt;

&lt;p&gt;文件存储的实现关键问题是记录各个文件分别用到哪些磁盘块。&lt;/p&gt;

&lt;h4&gt;连续分配&lt;/h4&gt;

&lt;p&gt;最简单的分配方案是把每个文件作为一连串连续数据块存储在磁盘上。&lt;/p&gt;

&lt;h4&gt;链表分配&lt;/h4&gt;

&lt;p&gt;链表分配不会有磁盘碎片的问题，顺序读取非常方便，但随即存取却相当缓慢。而且由于指针占了一些字节，磁盘块存储数据的字节数不再是 2 的整数幂。&lt;/p&gt;

&lt;h4&gt;在内存中采用的链表分配&lt;/h4&gt;

&lt;p&gt;将每个磁盘块的指针放在内存的一张表中，可以解决上面的两个不足。随机存取虽然依然需要遍历，但不再需要任何磁盘引用。缺点在于整张表必须放在内存，对大磁盘来说（表太大）不太合适。&lt;/p&gt;

&lt;h4&gt;i 节点&lt;/h4&gt;

&lt;p&gt;最后一个解决方案是给每个文件赋予一个 i 节点，包含文件属性和文件块的磁盘地址。只有文件打开时，i 节点才会加载到内存。&lt;/p&gt;

&lt;h3&gt;目录的实现&lt;/h3&gt;

&lt;p&gt;对于 i 节点系统，目录项只包括文件名和相应的 i 节点号。查找文件名时，可以在每个目录使用散列表来加快查找速度。另外一种方法是将查找结果放入高速缓存。&lt;/p&gt;

&lt;h3&gt;虚拟文件系统&lt;/h3&gt;

&lt;p&gt;UNIX 使用虚拟文件系统的概念，关键思想在于抽象出所有文件系统的共有部分，把这部分代码放在单独的一层，该层调用底层的实际文件系统来管理数据。&lt;/p&gt;

&lt;h1&gt;Linux 中的实现&lt;/h1&gt;

&lt;h2&gt;虚拟文件系统&lt;/h2&gt;

&lt;p&gt;虚拟文件系统（VPS）作为内核子系统，为用户空间程序提供了文件系统相关的接口。通过虚拟文件系统，程序可以利用标准的 UNIX 文件系统调用对不同介质的不同文件系统进行读写操作。&lt;/p&gt;

&lt;h3&gt;通用文件系统接口&lt;/h3&gt;

&lt;p&gt;VFS 使用户可以直接使用 open()、read() 和 write() 这样的系统调用而无需考虑具体文件系统和实际物理介质。&lt;/p&gt;

&lt;h3&gt;文件系统抽象层&lt;/h3&gt;

&lt;p&gt;VFS 抽象层定义了所有文件系统都支持的基本的、概念上的接口和数据结构，因此能衔接各种各样的文件系统。&lt;/p&gt;

&lt;p&gt;在内核中，除了文件系统本身外，并不需要了解文件系统的内部细节。例如用户空间程序执行如下的操作：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;write(f, &amp;amp;buf, len);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;该代码将 &amp;amp;buf 指针指向的、长度为 len 字节的数据写入文件描述符 f 对应的文件的当前位置。该用户调用首先被一个通用系统调用 &lt;code&gt;sys_write()&lt;/code&gt; 处理，&lt;code&gt;sys_write()&lt;/code&gt; 函数要找到 f 所在的文件系统对应的写操作，然后执行该操作。&lt;/p&gt;

&lt;h3&gt;Unix 文件系统&lt;/h3&gt;

&lt;p&gt;Unix 使用了四种和文件系统相关的传统抽象概念：文件、目录项、索引节点和安装点（mount point）。从本质上讲，文件系统是特殊的数据分层存储结构，它包含文件、目录和相关的控制信息。文件系统的通用操作包含创建、删除和安装等等。在 Unix 中，文件系统被安装在一个特定的安装点上，该安装点在全局层次结构中被称为命名空间，所有的已安装文件系统都作为根文件系统树的枝叶出现在系统中。&lt;/p&gt;

&lt;p&gt;Unix 中，目录属于普通文件，它列出包含在其中的所有文件。因此可以对目录执行和文件相同的操作。 &lt;/p&gt;

&lt;p&gt;Unix 将文件的相关信息和文件本身着两个概念加以区分，例如访问控制权限、大小、拥有者、创建时间等信息。文件相关信息有时被称为索引节点（inode）。&lt;/p&gt;

&lt;p&gt;文件系统的控制信息存储在超级块中，超级块是一种包含文件系统信息的数据结构。我们将文件信息和文件系统的信息统称为文件系统数据元。&lt;/p&gt;

&lt;p&gt;Unix 文件系统在他们物理磁盘布局中也是按照上述的概念实现的。文件信息按照索引节点形式存储在单独的块中，控制信息集中存储在磁盘的超级块中。&lt;/p&gt;

&lt;h3&gt;VFS 对象及其数据结构&lt;/h3&gt;

&lt;p&gt;VFS 采用的是面向对象的设计思路，使用一族数据结构来代表通用文件对象。VFS 中有四个主要的对象类型：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;超级块对象，代表一个已安装文件系统&lt;/li&gt;
&lt;li&gt;索引节点对象，代表一个文件&lt;/li&gt;
&lt;li&gt;目录项对象，代表一个目录项，是路径的一个组成部分&lt;/li&gt;
&lt;li&gt;文件对象，代表进程打开的文件&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;超级块对象&lt;/h3&gt;

&lt;p&gt;各种文件系统都必须实现超级块，该对象用于存储特定文件系统信息，通常对应存放于磁盘特定扇区中的文件系统超级块或文件系统控制块。对于并非基于磁盘的文件系统，它们会在现场创建超级块并保存到内存中。&lt;/p&gt;

&lt;p&gt;超级块对象由 super_block 结构体表示，定义在文件 &lt;linux/fs.h&gt; 中。&lt;/p&gt;

&lt;h3&gt;索引节点对象&lt;/h3&gt;

&lt;p&gt;索引节点对象包含了内核在操作文件或目录时需要的全部信息，由 inode 结构体表示，定义在文件 &lt;linux/fs.h&gt; 中。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct inode {
    struct hlist_node   i_hash;
    struct list_head    i_list;     // 索引节点链表
    struct list_head    i_sb_list;  // 超级块链表
    struct list_head    i_dentry;   // 目录项链表
    unsigned long       i_ino;      // 节点号
    atomic_t            i_count;
    unsigned int        i_nlink;
    uid_t           i_uid;
    gid_t           i_gid;
    dev_t           i_rdev;         // 实际设备标识符
    unsigned int    i_blkbits;      // 以位为单位的块大小
    u64             i_version;
    loff_t          i_size;         // 以字节为单位的文件大小
#ifdef __NEED_I_SIZE_ORDERED
    seqcount_t      i_size_seqcount;
#endif
    struct timespec     i_atime;  // 最后访问时间
    struct timespec     i_mtime;  // 最后修改时间
    struct timespec     i_ctime;  // 最后改变时间
    blkcnt_t        i_blocks;     // 文件块数
    unsigned short  i_bytes;      // 使用的字节数
    umode_t         i_mode;       // 访问权限
    spinlock_t      i_lock; /* i_blocks, i_bytes, maybe i_size */
    struct mutex        i_mutex;
    struct rw_semaphore i_alloc_sem;
    const struct inode_operations   *i_op;  // 索引节点操作表
    const struct file_operations    *i_fop; /* former -&amp;gt;i_op-&amp;gt;default_file_ops */
    struct super_block  *i_sb;
    struct file_lock    *i_flock;
    struct address_space    *i_mapping;
    struct address_space    i_data;

    struct list_head    i_devices;
    union {
        struct pipe_inode_info  *i_pipe;
        struct block_device *i_bdev;
        struct cdev     *i_cdev;
    };
    unsigned long       i_state;
    unsigned long       dirtied_when;   // 第一次弄脏数据的时间
    unsigned int        i_flags;        // 文件系统标识
    atomic_t        i_writecount;       // 写者计数
    void            *i_private; /* fs or device private pointer */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;目录项对象&lt;/h3&gt;

&lt;p&gt;VFS 经常需要执行目录相关的操作，例如路径名查找等。路径名查找需要解析路径中的每一个组成部分。为了方便查找操作，VFS 引入目录项的概念。每个 dentry 代表路径中的一个特定部分。在路径中，包括普通文件在内，每一个部分都是目录项对象。&lt;/p&gt;

&lt;p&gt;目录项由对象 dentry 结构体表示，定义在文件 &lt;linux/dcache.h&gt; 中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct dentry {
    atomic_t d_count;       // 使用记账
    unsigned int d_flags;   /* protected by d_lock */
    spinlock_t d_lock;      /* per dentry lock */
    int d_mounted;
    struct inode *d_inode;      /* Where the name belongs to - NULL is * negative */
    /*
     * The next three fields are touched by __d_lookup.  Place them here
     * so they all fit in a cache line.
     */
    struct hlist_node d_hash;   // dcache中的所有dentry对象都通过d_hash指针域链到相应的dentry哈希链表中。
    struct dentry *d_parent;    /* parent directory */
    struct qstr d_name;

    struct list_head d_lru;     /* LRU list */
    /*
     * d_child and d_rcu can share memory
     */
    union {
        struct list_head d_child;   /* child of parent list */
        struct rcu_head d_rcu;
    } d_u;
    struct list_head d_subdirs; /* our children */
    struct list_head d_alias;   /* inode alias list */
    unsigned long d_time;       /* used by d_revalidate */
    const struct dentry_operations *d_op;
    struct super_block *d_sb;   /* The root of the dentry tree */
    void *d_fsdata;         /* fs-specific data */

    unsigned char d_iname[DNAME_INLINE_LEN_MIN];    /* small names */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;不同于前面的两个对象，目录项对象没有对应的磁盘数据结构，VFS 根据字符串形式的路径名现场创建它。&lt;/p&gt;

&lt;h4&gt;目录项状态&lt;/h4&gt;

&lt;p&gt;目录项对象有三种有效状态：被使用、未被使用和负状态。&lt;/p&gt;

&lt;p&gt;一个被使用的目录项对应一个有效的索引节点（d_inode 指向相应的索引节点）并表明该对象存在一个或多个使用者（d_count 为正值）。&lt;/p&gt;

&lt;p&gt;一个未被使用的目录项对应一个有效的索引节点（d_inode 指向一个索引节点）但 VFS 当前并未使用它（d_count 为 0)。该目录项对象仍然指向一个有效对象，而且被保留在缓存中以便需要时再使用。&lt;/p&gt;

&lt;p&gt;一个负状态的目录项没有对应的有效索引节点（d_inode 为 NULL），因为索引节点已被删除或路径不再正确。&lt;/p&gt;

&lt;h4&gt;目录项缓存&lt;/h4&gt;

&lt;p&gt;内核将目录项对象缓存在目录项缓存（dcache）中。目录项缓存包含三个主要部分：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;“被使用的”目录项链表：该链表通过索引节点对象中的 i_dentry 项连接相关的索引节点。一个给定的索引节点可能有多个链接，就可能有多个目录项对象，因此用链表来连接。&lt;/li&gt;
&lt;li&gt;“最近被使用的”双向链表：该链表含有未被使用的和负状态的目录项对象。该链表以时间顺序插入，所以链头的节点是最新数据。当内核必须通过删除节点项回收内存时，会从链尾删除节点项。&lt;/li&gt;
&lt;li&gt;散列表和相应的散列函数用来快速将给定路径解析为相关目录项对象。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;文件对象&lt;/h3&gt;

&lt;p&gt;文件对象表示进程已打开的文件，由结构体 file 表示，定义在文件 &lt;linux/fs.h&gt; 中。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct file {
    /*
     * fu_list becomes invalid after file_free is called and queued via
     * fu_rcuhead for RCU freeing
     */
    union {
        struct list_head    fu_list;    // 文件对象链表
        struct rcu_head     fu_rcuhead; // 释放后 rcu 链表
    } f_u;
    struct path     f_path;   // 包含目录项
#define f_dentry    f_path.dentry
#define f_vfsmnt    f_path.mnt
    const struct file_operations    *f_op;  // 文件操作表
    spinlock_t      f_lock;   /* f_ep_links, f_flags, no IRQ */
    atomic_long_t   f_count;  // 文件对象使用计数
    unsigned int    f_flags;  //打开文件指定的标志位
    fmode_t         f_mode;   // 文件访问模式
    loff_t          f_pos;    // 文件当前的位移量
    struct fown_struct  f_owner;
    u64         f_version;
    struct address_space    *f_mapping;  // 页缓存映射
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;文件对象通过 f_dentry 指针指向相关的目录项对象，目录项会指向相关的索引节点，索引节点会记录文件是否为脏。&lt;/p&gt;

&lt;h3&gt;文件系统相关的数据结构&lt;/h3&gt;

&lt;p&gt;struct file_system_type 用来描述每种文件系统的功能和行为：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct file_system_type {
    const char *name;               /* 文件系统的名字 */
    int fs_flags;                   /* 文件系统类型标志 */

    /* 从磁盘读取超级块 */
    int (*get_sb) (struct file_system_type *, int,
               const char *, void *, struct vfsmount *);

    /* 终止访问超级块 */
    void (*kill_sb) (struct super_block *);

    struct module *owner;           /* 文件系统模块 */
    struct file_system_type * next; /* 链表中下一个 */
    struct list_head fs_supers;     /* 超级块对象链表 */

};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;当文件系统被实际安装时，将有一个 vfsmount 结构体在安装点被创建。该结构体用来代表文件系统的实例：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct vfsmount {
    struct list_head mnt_hash;
    struct vfsmount *mnt_parent;    /* fs we are mounted on */
    struct dentry *mnt_mountpoint;  /* dentry of mountpoint */
    struct dentry *mnt_root;    /* root of the mounted tree */
    struct super_block *mnt_sb; /* pointer to superblock */
    struct list_head mnt_mounts;    /* list of children, anchored here */
    struct list_head mnt_child; /* and going through their mnt_child */
    int mnt_flags;
    /* 4 bytes hole on 64bits arches */
    const char *mnt_devname;    /* Name of device e.g. /dev/dsk/hda1 */
    struct list_head mnt_list;
    struct mnt_namespace *mnt_ns;   /* containing namespace */
    int mnt_id;         /* mount identifier */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;进程相关的数据结构&lt;/h3&gt;

&lt;p&gt;有三个数据结构将 VFS 层和系统进程紧密联系在一起，分别是：files_struct、fs_struct 和 namespace 结构体。&lt;/p&gt;

&lt;p&gt;files_structt 结构体定义在文件 &lt;linux/file.h&gt; 中。该结构体由进程描述符中的 files 域指向。所有与每个进程（per-process）相关的信息如果打开的文件和文件描述符都在其中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct fdtable {
    unsigned int max_fds;
    struct file ** fd;      /* current fd array */
    fd_set *close_on_exec;
    fd_set *open_fds;
    struct rcu_head rcu;
    struct fdtable *next;
};

struct files_struct {
  /*
   * read mostly part
   */
    atomic_t count;
    struct fdtable *fdt;
    struct fdtable fdtab;
    int next_fd;
    struct embedded_fd_set close_on_exec_init;
    struct embedded_fd_set open_fds_init;
    struct file * fd_array[NR_OPEN_DEFAULT];
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;fd 数组指针指向已打开的文件对象链表，默认情况下指向 fd_array 数组。因为 NR_OPEN_DEFAULT 等于 32，如果一个进程打开的文件对象超过 32 个，内核将分配一个新数组并将 fd 指针指向它。&lt;/p&gt;

&lt;p&gt;下图是 APUE 中进程打开文件的图例：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linux-kernel-serial-5/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;其中 process table entry 表项对应 files_struct 对象，file table 表项对应 file 对象，v-node table 表项可以看成两部分，一部分是文件操作函数的指针，由 file 对象的 f_op 字段指向，另一部分 inode 信息，由 file 对象的 f_dentry 字段指向的目录项对象的 d_inode 关联到相关的 inode 节点：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linux-kernel-serial-5/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;注：上图取自&lt;a href=&quot;https://www.zhihu.com/question/39148572&quot;&gt;知乎&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;和进程相关的第二个结构体是 fs_struct。该结构由进程描述符 fs 域指向。它包含文件系统和进程相关的信息，定义在 &lt;linux/fs_struct.h&gt; 中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct path {
    struct vfsmount *mnt;
    struct dentry *dentry;
};

struct fs_struct {
    int users;                  /* 结构的使用计数 */
    rwlock_t lock;   
    int umask;                  /* 默认的文件访问权限 */
    int in_exec;             
    struct path root, pwd;     /* 根目录和当前目录的目录项对象和安装点对象 */  
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;最后一个结构体是 mnt_namespace，定义在 &lt;linux/mnt_namespace.h&gt; 中，由进程描述符中的 namespace 指向。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct mnt_namespace {
    atomic_t        count;          /* 结构的使用计数 */
    struct vfsmount *   root;       /* 根目录的安装点对象 */
    struct list_head    list;       /* 安装点链表 */
    wait_queue_head_t poll; 
    int event;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;对大多数进程来说，它们的描述符会指向唯一的 files_struct 和 fs_struct 结构体。对于使用克隆标志 CLONE_FILES 或 CLONE_FS 创建的进程，会共享这两个结构体。所以多个进程描述符可能会指向同一个 files_struct 或 fs_struct 结构体。因此每个结构体维护一个 count 域（或 users 域）作为引用计数。&lt;/p&gt;

&lt;p&gt;namespace 结构体则不同，默认情况下，所有进程共享同样的命名空间。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://bean-li.github.io/vfs-inode-dentry/&quot;&gt;http://bean-li.github.io/vfs-inode-dentry/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://unicornx.github.io/2016/03/20/20160320-lk-vfs/&quot;&gt;http://unicornx.github.io/2016/03/20/20160320-lk-vfs/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;APUE 对应进程打开文件的图例&lt;/p&gt;

&lt;h2&gt;块 I/O 层&lt;/h2&gt;

&lt;p&gt;系统能随机访问固定大小数据片（chunk）的设备被称作块设备。另一种基本的设备类型是字符设备，字符设备按照字符流的方式被有序访问，例如串口和键盘。&lt;/p&gt;

&lt;h3&gt;解剖一个块设备&lt;/h3&gt;

&lt;p&gt;块设备中最小的可寻址单元是扇区（sector）。扇区大小一般是 2 的整数倍，最常见的大小是 512 个字节。扇区的大小是设备的物理属性，扇区是所有块设备的基本单元，块设备无法对它还小的单元进行寻址的操作。&lt;/p&gt;

&lt;p&gt;最小逻辑可寻址单元是块（block）。块是文件系统的抽象，只能基于块来访问文件系统。虽然物理磁盘寻址是按照扇区级进行的，但内核执行的所有磁盘操作都是按照块进行的。对块大小的要求是：必须是扇区大小的 2 的整数倍，并且要小于页面大小。所以块大小通常为 512 字节、1K 或 4K。&lt;/p&gt;

&lt;h3&gt;缓冲区和缓冲区头&lt;/h3&gt;

&lt;p&gt;当块被调入内存时，它要存储在一个缓冲区中。缓冲区相当于磁盘块在内存中的表示。由于内核在处理数据时需要一些相关的控制信息（比如块属于哪一个块设备，对于哪个缓冲区等），所以每个缓冲区都有一个对应的描述符，由 buffer_head 结构体表示，称为缓冲区头，在 &lt;linux/buffer_head.h&gt; 中定义。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct buffer_head {
    unsigned long b_state;      /* buffer state bitmap (see above) */
    struct buffer_head *b_this_page;/* circular list of page&amp;#39;s buffers */
    struct page *b_page;        /* the page this bh is mapped to */

    sector_t b_blocknr;     /* start block number */
    size_t b_size;          /* size of mapping */
    char *b_data;           /* pointer to data within the page */

    struct block_device *b_bdev;
    bh_end_io_t *b_end_io;      /* I/O completion */
    void *b_private;        /* reserved for b_end_io */
    struct list_head b_assoc_buffers; /* associated with another mapping */
    struct address_space *b_assoc_map;  /* mapping this buffer is
                           associated with */
    atomic_t b_count;       /* users using this buffer_head */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;与缓冲区对应的磁盘物理块由 b_blocknr 域索引，该值是 b_bdev 域指明的块设备中的逻辑块号。&lt;/p&gt;

&lt;p&gt;与缓冲区对应的内存物理页由 b_page 域表示，另外 b_data 域直接指向相应的块（它位于 b_page 域所指明的页面的某个位置上）。块的大小由 b_size 域表示，所以块在内存中的起始位置在 b_data 处，结束位置在 (b_data + b_size) 处。&lt;/p&gt;

&lt;h3&gt;bio 结构体&lt;/h3&gt;

&lt;p&gt;内核中块 I/O 操作的基本容器由 bio 结构体表示，定义在文件 &lt;linux/bio.h&gt; 中。&lt;/p&gt;

&lt;p&gt;每个块 I/O 请求都通过一个 bio 结构体表示。每个请求包含了一个或多个块，这些块存储在 bio_vec 结构体数组中。这些结构体描述了每个片段在物理页中的实际位置，并且像 vector 一样被组织在一起。I/O 操作的第一个片段由 b_io_vec 结构体所指向，共有 bi_vcnt 个片段。当块 I/O 层开始执行请求、需要使用各个片段时，bi_idx 域会不断更新，从而指向当前片段。&lt;/p&gt;

&lt;p&gt;buffer_head 和 bio 结构体之间存在明显差别。bio 结构体代表的是 I/O 操作，它可以包含内存中的一个或多页；而另一方面，buffer_head 结构体代表的是一个缓冲区，它描述的仅仅是磁盘中的一个块。因为缓冲区头关联的是单独页中的单独磁盘块，所以它可能会引起不必要的分割，将请求按块为单位划分。bio 则不需要连续存储区，也不需要分割 I/O 操作。&lt;/p&gt;

&lt;h3&gt;请求队列&lt;/h3&gt;

&lt;p&gt;块设备将它们挂起的块 I/O 请求保存在请求队列中，该队列由 reques_queue 结构体表示，定义在 &lt;linux/blkdev.h&gt; 中，包含一个双向请求链表以及相关控制信息。请求队列表中的每一项都是一个单独的请求，由 request 结构体表示。一个请求可能要操作多个连续的磁盘块，所以每个请求可以由多个 bio 结构体组成。&lt;/p&gt;

&lt;h3&gt;I/O 调度程序&lt;/h3&gt;

&lt;p&gt;磁盘寻址是整个计算机中最慢的操作之一，缩短寻址时间是提高系统性能的关键。为了优化寻址操作，内核会在提交任务前先执行合并与排序的预操作。在内核中负责提交 I/O 请求的子系统称为 I/O 调度程序。&lt;/p&gt;

&lt;h4&gt;I/O 调度程序的工作&lt;/h4&gt;

&lt;p&gt;I/O 调度程序的工作是管理块设备的请求队列。I/O 调度程序通过&lt;strong&gt;合并&lt;/strong&gt;和&lt;strong&gt;排序&lt;/strong&gt;来减少磁盘寻址时间。&lt;/p&gt;

&lt;h4&gt;Linus 电梯&lt;/h4&gt;

&lt;p&gt;第一个 I/O 调度程序被称为 Linus 电梯。当有新的请求加入队列时，会先检查每一个挂起的请求是否可以和新请求合并。Linus 电梯 I/O 调度程序可以执行向前和向后合并。如果合并失败，那就需要寻找可能的插入点。如果找到就插入，如果没合适的位置，那么新请求就被加入到队列尾部。另外如果队列中有驻留时间过长的请求，那么新请求也将被加入到队列尾部，即使插入后还要排序。这是为了避免由于访问相近磁盘位置的请求太多，从而造成访问磁盘其他位置的请求难以得到执行机会。&lt;/p&gt;

&lt;h4&gt;最终期限 I/O 调度程序&lt;/h4&gt;

&lt;p&gt;最终期限 I/O 调度程序中，每个请求都有一个超时时间。默认情况下，读请求的超时时间是 500 毫秒，写请求的超时时间是 5 秒。最终期限 I/O 调度请求类似于 Linus 电梯，也以磁盘物理位置次序维护请求队列，这个队列称为排序队列。但同时也会根据请求类型将它们插入到额外队列中。读请求按次序被插入特定的读 FIFO 队列中，写请求被插入到特定的写 FIFO 队列中。一般情况下，调度程序从排序队列头部取出请求，再推入到派发队列中。如果在写／读 FIFO 队列头的请求超时，那么调度程序便从 FIFO 队列中提取请求。&lt;/p&gt;

&lt;h2&gt;页高速缓存和页回写&lt;/h2&gt;

&lt;p&gt;页高速缓存是 Linux 内核实现的一种主要磁盘缓存。它主要用来减少对磁盘的 I/O 操作。具体来讲，是通过把磁盘中的数据缓存到物理内存，把对磁盘的访问变成对物理内存的访问。&lt;/p&gt;

&lt;p&gt;页高速缓存是由 RAM 中的物理页组成，每一页都对应磁盘多个块。每当内核开始执行一个页 I/O 操作时，首先会检查需要的数据是否在高速缓存中，如果在，则直接使用高速缓存中的数据。&lt;/p&gt;

&lt;p&gt;也可以通过块 I/O 缓冲区把独立的磁盘块与页高速缓存联系在一起。通过缓存磁盘块以及缓冲块 I/O 操作，页高速缓存同样可以减少块 I/O 操作期间的磁盘访问量。这种缓存通常称为“缓冲区高速缓存”，也是页高速缓存中的一部分。&lt;/p&gt;

&lt;h3&gt;页高速缓存&lt;/h3&gt;

&lt;p&gt;页高速缓存包含了最近被访问过的文件的全部页面，在执行 I/O 操作前，内核会检查数据是否已经在页高速缓存中了，如果在，则不再需要从磁盘读取数据。&lt;/p&gt;

&lt;h4&gt;address_space 对象&lt;/h4&gt;

&lt;p&gt;一个物理页可能由多个不连续的物理磁盘块组成，所以在页高速缓存中检测特定数据是否已经被缓存是件非常困难的工作。&lt;/p&gt;

&lt;p&gt;Liunx 页高速缓存使用 address_space 结构体描述页高速缓存中的页面。该结构定义在 &lt;linux/fs.h&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct address_space {
    struct inode            *host;      /* owner: inode, block_device */
    struct radix_tree_root  page_tree;  /* radix tree of all pages */
    spinlock_t              tree_lock;  /* and lock protecting it */
    unsigned int            i_mmap_writable;/* count VM_SHARED mappings */
    struct prio_tree_root   i_mmap;     /* tree of private and shared mappings */
    struct list_head        i_mmap_nonlinear;/*list VM_NONLINEAR mappings */
    spinlock_t              i_mmap_lock;    /* protect tree, count, list */
    unsigned int            truncate_count; /* Cover race condition with truncate */
    unsigned long           nrpages;    /* number of total pages */
    pgoff_t                 writeback_index;/* writeback starts here */
    const struct address_space_operations *a_ops;   /* methods */
    unsigned long           flags;      /* error bits/gfp mask */
    struct backing_dev_info *backing_dev_info; /* device readahead, etc */
    spinlock_t              private_lock;   /* for use by the address_space */
    struct list_head        private_list;   /* ditto */
    struct address_space    *assoc_mapping; /* ditto */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;i_mmap 字段是个优先搜索树，它的搜索范围包含了在 address_space 中所有共享和私有的映射页面。address_space 结构往往会和某些内核对象关联。通常会与一个索引节点（inode）关联，这时 host 域就指向该索引节点，该索引节点的 i_mapping 域指向到 address_space 对象，方便查找自身文件数据是否已经缓存。&lt;/p&gt;

&lt;p&gt;a_ops 域指向地址空间对象中的操作函数表。&lt;/p&gt;

&lt;p&gt;struct page 中有两个字段：mapping 和 index。其中 mapping 指向该页所有者的 address_space，index 字段表示所有者地址空间中以页大小为单位的偏移量。用这两个字段就能在页高速缓存中查找。&lt;/p&gt;

&lt;p&gt;页高速缓存通过两个参数：address_space 对象和一个偏移量进行搜索。每个 address_space 对象都有唯一一个基树，保存在 page_tree 结构体中。基树是一个二叉树，只要指定了文件偏移量，就可以在基树中迅速检索到希望的数据。&lt;/p&gt;

&lt;p&gt;inode、address space 和 page 三者的关系如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linux-kernel-serial-5/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h1&gt;Linux 中的 I/O 机制&lt;/h1&gt;

&lt;h2&gt;Buffered I/O&lt;/h2&gt;

&lt;p&gt;Buffered I/O 指的是在内核和用户程序之间设置了一层缓冲区，用来提高IO读写的效率：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读取：硬盘---&amp;gt;内核缓冲区---&amp;gt;用户缓冲区---&amp;gt;用户程序&lt;/li&gt;
&lt;li&gt;写回：用户程序---&amp;gt;用户缓冲区---&amp;gt;内核缓冲区---&amp;gt;硬盘&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Unbuffered I/O&lt;/h2&gt;

&lt;p&gt;Unbuffered I/O 没有用户缓冲区，&lt;strong&gt;注意内核缓冲区仍然存在&lt;/strong&gt;：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读取：硬盘---&amp;gt;内核缓冲区---&amp;gt;用户程序&lt;/li&gt;
&lt;li&gt;写回：用户程序---&amp;gt;内核缓冲区---&amp;gt;硬盘&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Direct IO&lt;/h2&gt;

&lt;p&gt;Direct I/O 是真正的什么缓冲区都没有，直接与硬盘交互：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;读取：硬盘---&amp;gt;用户程序&lt;/li&gt;
&lt;li&gt;写回：用户程序---&amp;gt;硬盘&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;使用带有内核缓冲区的 I/O（Buffer I/O 和 Unbuffer I/O），DMA 方式可以将数据直接从磁盘读到页缓存中，或者将数据从页缓存直接写回到磁盘上，而不能直接在应用程序地址空间和磁盘之间进行数据传输。数据在传输过程中需要在应用程序地址空间和页缓存之间进行多次数据拷贝操作，这些数据拷贝操作所带来的 CPU 以及内存开销是非常大的。&lt;/p&gt;

&lt;p&gt;Direct I/O 最主要的优点就是通过减少操作系统内核缓冲区和应用程序地址空间的数据拷贝次数，降低了对文件读取和写入时所带来的 CPU 的使用以及内存带宽的占用。&lt;/p&gt;
</description>
        <pubDate>Fri, 16 Dec 2016 21:37:16 +0800</pubDate>
        <link>http://masutangu.com/2016/12/linux-kernel-serial-5/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/12/linux-kernel-serial-5/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>Linux 内核系列－内存管理</title>
        <description>&lt;p&gt;本系列文章为阅读《现代操作系统》和《Linux 内核设计与实现》所整理的读书笔记，源代码取自 Linux-kernel 2.6.34 版本并有做简化。&lt;/p&gt;

&lt;h1&gt;概念&lt;/h1&gt;

&lt;p&gt;操作系统存储管理方案的演进：&lt;/p&gt;

&lt;h2&gt;无存储抽象&lt;/h2&gt;

&lt;p&gt;早期计算机并没有存储抽象，程序直接访问物理内存地址。使用这种模型，想要同时运行多个程序非常困难。&lt;/p&gt;

&lt;h2&gt;存储抽象：地址空间&lt;/h2&gt;

&lt;h3&gt;地址空间的概念&lt;/h3&gt;

&lt;p&gt;要保证多个应用程序同时处于内存并且互不影响，则需要解决两个问题：&lt;strong&gt;保护&lt;/strong&gt;和&lt;strong&gt;重定位&lt;/strong&gt;。内存块加上保护键并通过装载时重定位程序虽然可以做到，但是是个缓慢和复杂的解决方案。一个更好的方法是创造一个新的内存抽象：地址空间。地址空间是一个进程可用于寻址内存的一套地址集合。进程的地址空间独立于其他进程的地址空间。&lt;/p&gt;

&lt;h3&gt;交换技术&lt;/h3&gt;

&lt;p&gt;有两种处理内存超载的通用方法，最简单的策略是交接（swapping）技术，即把一个进程完整调入内存，运行一段时间后，存回磁盘。另一种策略是虚拟内存。&lt;/p&gt;

&lt;h3&gt;空闲内存管理&lt;/h3&gt;

&lt;p&gt;在动态分配内存时，操作系统通常有两种方式跟踪内存使用情况：&lt;strong&gt;位图&lt;/strong&gt;和&lt;strong&gt;空闲链表&lt;/strong&gt;。&lt;/p&gt;

&lt;h2&gt;虚拟内存&lt;/h2&gt;

&lt;p&gt;虚拟内存的基本思想是：每个程序拥有自己的地址空间，这个空间被分割为许多块，每一块被称为页面（page）。这些页被映射到物理内存，但不是所有页都在内存才能运行程序。&lt;/p&gt;

&lt;h3&gt;分页&lt;/h3&gt;

&lt;p&gt;大部分虚拟内存系统都使用了&lt;strong&gt;分页&lt;/strong&gt;技术。程序产生的地址称为虚拟地址，访问时不是直接由内存总线处理，而是通过内存管理单元（MMU)，MMU 把虚拟地址映射到物理内存。&lt;/p&gt;

&lt;p&gt;虚拟地址空间按照固定大小划分页面，物理内存对应的单元称为页框（page frame）。页面和页框的大小通常是一样的。RAM 和磁盘之间的交换总是以整个页面为单元进行的。&lt;/p&gt;

&lt;p&gt;当进程访问了一个未映射的页面，MMU 注意到该页面没有被映射，于是使 CPU 陷入到操作系统（缺页中断），操作系统找到一个很少使用的页框，将其内容写入磁盘，并把需要访问的页面的内容读到该页框中，修改映射关系后，重新启动引起陷进的指令。&lt;/p&gt;

&lt;h3&gt;页表&lt;/h3&gt;

&lt;p&gt;页表的简单实现：虚拟地址被分成&lt;strong&gt;虚拟页号&lt;/strong&gt;（高位部分）和&lt;strong&gt;偏移量&lt;/strong&gt;（低位部分）。虚拟页号可用作页表的索引，以找到相应的页表项。由页表项可以找到页框号。页框号加上偏移量就是实际的内存物理地址。&lt;/p&gt;

&lt;p&gt;页表项的结构同城包含页框号、“在／不在”位、“保护”位（读写执行权限）、“修改”位、“访问”位和“高速缓存禁止”位。&lt;/p&gt;

&lt;p&gt;若页面不在内存时，该页面对应的磁盘地址不是页表的一部分。这部分信息保存在操作系统内部的软件表格中，硬件不需要。&lt;/p&gt;

&lt;h3&gt;加速分页过程&lt;/h3&gt;

&lt;p&gt;大多数程序总是对少量页面进行多次访问，因此优化方案是为计算机配置一个小型硬件设备 TLB，将虚拟地址直接映射成物理地址，而不必访问页表。&lt;/p&gt;

&lt;h3&gt;针对大内存的页表&lt;/h3&gt;

&lt;p&gt;64位机器上，多级页表不是个好主意。解决方案之一是使用倒排页表。在这种设计中，每一个页框有一个表项，而不是每个页面有一个表项。倒排页表的不足在于从虚拟地址到物理地址的转换变得很困难。可以通过 TLB 和散列表来提升效率。&lt;/p&gt;

&lt;h2&gt;分页系统中的设计问题&lt;/h2&gt;

&lt;h3&gt;分离的指令空间和数据空间&lt;/h3&gt;

&lt;p&gt;大多数计算机只有一个地址空间，即存放程序也存放数据。如果地址空间太小的话，PDP-11的解决方案是为指令和数据设置分离的地址空间，分别称为 I 空间和 D 空间。此时链接器必须将数据重定位到虚拟地址 0，而不是指令段后。&lt;/p&gt;

&lt;h3&gt;共享库&lt;/h3&gt;

&lt;p&gt;传统的链接，会将被调用的外部库的函数加载到二进制文件，当程序载入内存开始执行时，它所需的所有函数都已经准备就绪。&lt;/p&gt;

&lt;p&gt;为了节省磁盘和内存空间，引入了共享库。当程序和共享库链接时，链接器没有加载被调用的函数，而是加载了一小段能够在运行时绑定所调用函数的存根例程（stbu routine）。共享库或和程序一起加载，或在第一次被调用时加载。当其他程序已经加载过，就没有必要再次加载了。共享库不是一次性读入内存，而是以页面为单位装载的。&lt;/p&gt;

&lt;h3&gt;内存映射文件&lt;/h3&gt;

&lt;p&gt;共享库其实是一种更通用的机制：内存映射文件的一个特例。其思想是：进程可以通过系统调用，将一个文件映射到其虚拟地址空间的一部分。在映射共享的页面时不会实际读入页面的内容，而是访问页面时才会被读入，磁盘文件当作后备存储，当进程退出或显式解除文件映射时，所有改动才会写回文件。&lt;/p&gt;

&lt;p&gt;如果两个或以上的进程同时映射了一个文件，它们就可以通过共享内存来通信。&lt;/p&gt;

&lt;h1&gt;Linux 中的实现&lt;/h1&gt;

&lt;h2&gt;内存管理&lt;/h2&gt;

&lt;h3&gt;页&lt;/h3&gt;

&lt;p&gt;内核把物理页作为内存管理的基本单位。尽管处理器最小可寻址单位通常为字，但内存管理单元（MMU)通常以页为单位进行处理。体系结构不同，支持的页大小也不同。大多数 32 位体系结构支持 4 KB 的页，而 64 位体系结构一般支持 8 KB 的页。&lt;/p&gt;

&lt;p&gt;内核用 &lt;code&gt;struct page&lt;/code&gt; 结构表示系统中的每个物理页，该结构位于 &lt;linux/mm_types.h&gt; 中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct page {
    unsigned long flags;    /* Atomic flags, some possibly updated asynchronously */
    atomic_t _count;        /* Usage count, see below. */

    atomic_t _mapcount;     /* Count of ptes mapped in mms,
                             * to show when page is mapped
                             * &amp;amp; limit reverse map searches.
                             */
    };
    union {
        struct {
        unsigned long private;  /* Mapping-private opaque data:
                                 * usually used for buffer_heads
                                 * if PagePrivate set; used for
                                 * swp_entry_t if PageSwapCache;
                                 * indicates order in the buddy
                                 * system if PG_buddy is set.
                                 */
        struct address_space *mapping;  /* If low bit clear, points to
                                         * inode address_space, or NULL.
                                         * If page mapped as anonymous
                                         * memory, low bit is set, and
                                         * it points to anon_vma object:
                                         * see PAGE_MAPPING_ANON below.
                                         */
        };
    union {
        pgoff_t index;      /* Our offset within mapping. */
        void *freelist;     /* SLUB: freelist req. slab lock */
    };
    struct list_head lru;   /* Pageout list, eg. active_list
                             * protected by zone-&amp;gt;lru_lock !
                             */
    void *virtual;          /* Kernel virtual address (NULL if not kmapped, ie. highmem) */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;flage 域用来存放页的状态。这些状态包括页是不是脏的，是不是被锁定在内存中等等。_count 域存放页的引用计数，变成 0 说明当前内核没有引用这一页。页可以由页缓存使用（此时 mapping 域指向和这个页关联的 address_space 对象)，或者作为私有数据（由 private 指向），或者作为进程页表中的映射。&lt;/p&gt;

&lt;p&gt;virtual 域是页的虚拟地址，通常情况下，就是页在虚拟内存中的地址。高端内存并不会永久映射到内核地址空间上，这种情况下，virtual 域的值为 NULL。&lt;/p&gt;

&lt;p&gt;page 结构与物理页相关，并非与虚拟页相关。&lt;/p&gt;

&lt;h3&gt;区&lt;/h3&gt;

&lt;p&gt;由于硬件的限制，内核把页划分为不同的区（zone）。内核使用区对具有相似特性的页进行分组。Linux 必须处理以下两种因硬件存在的缺陷而引起的内存寻址问题：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一些硬件只能用特定的内存地址来执行 DMA（直接内存访问）&lt;/li&gt;
&lt;li&gt;一些体系结构其内存的物理寻址范围比虚拟寻址范围大得多，这样就有些内存不能永久地映射到内核空间上&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为存在这些制约条件，Linux 使用三种区：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ZONE_DMA： 这个区包含的页能用来执行 DMA 操作&lt;/li&gt;
&lt;li&gt;ZONE_NORMAL： 这个区包含的都是能正常映射的页&lt;/li&gt;
&lt;li&gt;ZONE_HIGHMEM： 这个区包含“高端内存”，其中的页并不能永久地映射到内核地址空间。这些区定义于 &lt;linux/mmzone.h&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Linux 把系统的页划分为区，形成不同的内存池。每个区都用 &lt;code&gt;struct zone&lt;/code&gt; 表示，定义在 &lt;linux/mmzone.h&gt; 中。&lt;/p&gt;

&lt;h3&gt;获得页&lt;/h3&gt;

&lt;p&gt;内核提供一种请求内存的底层机制，并提供了对它进行访问的几个接口。所有这些接口都以页为单位分配内存，定义于 &lt;linux/gfp.h&gt;。最核心的函数是：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struc page * alloc_pages(unsigned int gfp_mask, unsigned int order)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;该函数分配 2&lt;sup&gt;order&lt;/sup&gt; 个连续的物理页，并返回一个指针，该指针指向第一个页的 page 结构体；如果出错就返回 NULL。&lt;/p&gt;

&lt;p&gt;下面的函数：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;void *page_address(struct page *page)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;把给定的物理页转换成逻辑地址。如果你不需要使用 struct page，可以直接调用&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;unsigned long__get_free_pages(unsigned int gfp_mask, unsigned int order)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;该函数与 &lt;code&gt;alloc_page()&lt;/code&gt; 作用相同，不过它直接返回请求的第一个页的逻辑地址，因为页是连续的，其他页也会紧随其后。&lt;/p&gt;

&lt;h2&gt;kmalloc()&lt;/h2&gt;

&lt;p&gt;&lt;code&gt;kmalloc()&lt;/code&gt; 函数与用户空间的 &lt;code&gt;malloc()&lt;/code&gt; 一族非常类似，只不过它多了一个 flags 参数。&lt;code&gt;kmalloc()&lt;/code&gt; 函数是一个简单的接口，用它可以获得以字节为单位的一块内核内存。&lt;code&gt;kmalloc()&lt;/code&gt; 在 &lt;linux/slab.h&gt; 中声明：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;void *kmalloc(size_t size, int flags)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这个函数返回一个指向内存块的指针，其内存块至少要有 size 大小。所分配的内存区在物理上是连续的。在出错时返回 NULL。&lt;/p&gt;

&lt;h3&gt;vmalloc()&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;vmalloc()&lt;/code&gt; 函数的工作方式类似于 &lt;code&gt;kmalloc()&lt;/code&gt;，只不过前者分配的内存虚拟地址是连续的，而物理地址无需连续。这也是用户空间分配函数的工作方式：由 &lt;code&gt;malloc()&lt;/code&gt; 返回的页在进程的虚拟地址空间内是连续的，但并不保证它们在物理 RAM 中也连续。&lt;code&gt;kmalloc()&lt;/code&gt; 函数确保页在物理地址上是连续的。&lt;/p&gt;

&lt;p&gt;大多数情况下，只有硬件设备需要得到物理地址连续的内存，硬件设备存在于内存管理单元之外，它根本不理解什么是虚拟内存。因此硬件设备用到的任何内存区都必须是物理上连续的块，而不仅仅是虚拟地址连续的块。而仅供软件使用的内存块（例如进程相关的缓冲区）就可以使用只有虚拟地址连续的内存块。&lt;/p&gt;

&lt;p&gt;尽管在某些情况下才需要物理上连续的内存块，但很多内核代码都用 &lt;code&gt;kmalloc()&lt;/code&gt; 来获得内存，而不是 &lt;code&gt;vmalloc()&lt;/code&gt;。这主要是出于性能的考虑。&lt;code&gt;vmalloc()&lt;/code&gt; 为了把物理上不连续的页转换为虚拟空间上连续的页，必须专门建立页表项，通过 &lt;code&gt;vmalloc()&lt;/code&gt; 获得的页必须一个个进行映射，这会导致比直接内存映射大得多的 TLB 抖动。因此 &lt;code&gt;vmalloc()&lt;/code&gt; 仅在不得已的时候才使用，一般是在为了获得大块内存，例如当模块被动态插入到内核中时，就把模块装载到由 &lt;code&gt;vmalloc()&lt;/code&gt; 分配的内存上。&lt;/p&gt;

&lt;h3&gt;slab 层&lt;/h3&gt;

&lt;p&gt;Linux 内核提供了 slab 层（即 slab 分配器），slab 分配器扮演了通用数据结构缓存层的角色。&lt;/p&gt;

&lt;h4&gt;slab 层的设计&lt;/h4&gt;

&lt;p&gt;slab 层把不同的对象划分为所谓的&lt;strong&gt;高速缓存组&lt;/strong&gt;，其中每个高速缓存都存放不同类型的对象，每种对象类型对应一个高速缓存。例如一个高速缓存用于存放进程描述符，另一个高速缓存存放索引节点对象（struct inode）。&lt;code&gt;kmalloc()&lt;/code&gt; 接口建立在 slab 层之上，使用了一组通用高速缓存。&lt;/p&gt;

&lt;p&gt;这些高速缓存又被划分为 slab。slab 由一个或多个物理上连续的页组成。每个高速缓存由多个 slab 组成。每个 slab 都包含一些对象成员，即被缓存的数据结构。每个 slab 处于三种状态之一：满、部分满或空。当内核需要一个新对象时，先从部分满的 slab 中进行分配，如果没有部分满的 slab，就从空的 slab 进行分配。如果没有空的 slab，就要创建一个 slab。&lt;/p&gt;

&lt;h2&gt;进程地址空间&lt;/h2&gt;

&lt;p&gt;内核除了管理自身的内存外，还必须管理进程的地址空间。Linux 操作系统采用虚拟内存技术，对每个进程来说，它们好像都可以访问整个系统的所有物理内存，即使单独一个进程，它拥有的地址空间也可远大于系统物理内存。&lt;/p&gt;

&lt;p&gt;每个进程都有一个 32 或 64 位的平坦地址空间，空间的具体大小取决于体系结构。每个进程有唯一的平坦地址空间，而且进程地址空间之间彼此互不相干。两个不同的进程可以在它们各自地址空间中国年相同的地址内存存放不同的数据，进程之间也可以选择共享地址空间（线程）。&lt;/p&gt;

&lt;p&gt;进程地址空间中，可被访问的合法地址区间称为内存区域（memory area）。进程只能访问有效范围内的内存地址。每个内存区域也具有进程必须遵循的特定访问属性，如只读、只写、可执行等属性。如果进程访问了不在有效范围中的地址，或以不正确的方式访问有效地址，那么内核就会终止该进程，并返回“段错误”。&lt;/p&gt;

&lt;p&gt;内存区域可以包含各种内存对象：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;可执行文件代码的内存映射，称为代码段（text section）&lt;/li&gt;
&lt;li&gt;可执行文件的已初始化全局变量的内存映射，称为数据段（data section）&lt;/li&gt;
&lt;li&gt;包含未初始化全局变量，即 bss 段的零页的内存映射&lt;/li&gt;
&lt;li&gt;用于进程用户空间栈的零页的内存映射&lt;/li&gt;
&lt;li&gt;每个共享库的代码段、数据段和 bss 也会载入进程的地址空间&lt;/li&gt;
&lt;li&gt;任何内存映射文件&lt;/li&gt;
&lt;li&gt;任何共享内存段&lt;/li&gt;
&lt;li&gt;任何匿名的内存映射，比如由 malloc() 分配的内存&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;内存描述符&lt;/h3&gt;

&lt;p&gt;内核使用内存描述符结构体表示进程的地址空间，该结构包含了和进程地址空间有关的全部心血。内存描述法由 mm_struct 结构体表示，定义在文件 &lt;linux/sched.h&gt; 中。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct mm_struct {
    struct vm_area_struct * mmap;       /* list of VMAs */
    struct rb_root mm_rb;
    struct vm_area_struct * mmap_cache; /* last find_vma result */

    unsigned long free_area_cache;      /* first hole of size cached_hole_size or larger */
    pgd_t * pgd;
    atomic_t mm_users;          /* How many users with user space? */
    atomic_t mm_count;          /* How many references to &amp;quot;struct mm_struct&amp;quot; (users count as 1) */
    int map_count;              /* number of VMAs */
    struct rw_semaphore mmap_sem;
    spinlock_t page_table_lock;     /* Protects page tables and some counters */

    struct list_head mmlist;        /* List of maybe swapped mm&amp;#39;s.  These are globally strung
                                     * together off init_mm.mmlist, and are protected
                                     * by mmlist_lock
                                     */
    unsigned long hiwater_rss;  /* High-watermark of RSS usage */
    unsigned long hiwater_vm;   /* High-water virtual memory usage */

    unsigned long total_vm, locked_vm, shared_vm, exec_vm;
    unsigned long stack_vm, reserved_vm, def_flags, nr_ptes;
    unsigned long start_code, end_code, start_data, end_data;
    unsigned long start_brk, brk, start_stack;
    unsigned long arg_start, arg_end, env_start, env_end;   

    cpumask_t cpu_vm_mask;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;mm_users 域纪录正在使用该地址的进程数目。mm_count 域是 mm_struct 结构体的主引用数。只有当 mm_users 为 0，mm_count 值才会变成 0，表示已经没有任何指向该 mm_struct 结构体的引用，这时该结构体就会被销毁。&lt;/p&gt;

&lt;p&gt;mmap 和 mm_rb 这两个不同数据结构体描述的对象是相同的：该地址空间中的全部内存区域。前者以链表形式存放而后者以红黑树的形式存放。mmap 结构体作为链表，方便简单、高效地遍历所有元素；而 mm_rb 结构体作为红黑树，方便搜索指定元素。&lt;/p&gt;

&lt;p&gt;所有 mm_struct 结构体都通过自身的 mmlist 域链接在一个双向链表中。该链表的首元素是 init_mm 内存描述符，他代表 init 进程的地址空间。&lt;/p&gt;

&lt;h3&gt;分配内存描述符&lt;/h3&gt;

&lt;p&gt;在进程的进程描述符中，mm 域存放着该进程使用的内存描述符。&lt;code&gt;fork()&lt;/code&gt; 函数利用 &lt;code&gt;copy_mm()&lt;/code&gt; 函数复制父进程的内存描述符，也就是 current-&amp;gt;mm 域给其子进程。而子进程的 mm_struct 结构体是通过文件 kernel/fork.c 中的 &lt;code&gt;allcote_mm()&lt;/code&gt; 宏从 mm_cachep slab 缓存中分配得到的。通常每个进程都有唯一的 mm_struct 结构体，即唯一的进程地址空间。&lt;/p&gt;

&lt;p&gt;如果父子进程共享地址空间，可以调用 &lt;code&gt;clone()&lt;/code&gt; 时，设置 CLONE_VM 标志。我们把这样的进程称为线程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;if (clone_flags &amp;amp; CLONE_VM) {
    atomic_inc(&amp;amp;current-&amp;gt;mm-&amp;gt;mm_users);
    tsk-&amp;gt;mm = current-&amp;gt;mm;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;销毁内存描述符&lt;/h3&gt;

&lt;p&gt;进程退出时，内核会调用 &lt;code&gt;exit_mm()&lt;/code&gt; 函数，该函数会调用 &lt;code&gt;mmput()&lt;/code&gt; 函数来减少内存描述符中的 mm_users 用户计数，如果为 0 则调用 &lt;code&gt;mmdrop()&lt;/code&gt; 函数，减少 mm_count 使用计数。如果使用计数也等于 0 了，则调用 &lt;code&gt;free_mm()&lt;/code&gt; 宏通过 &lt;code&gt;kmem_cache_free()&lt;/code&gt; 函数将 mm_struct 结构体归还到 mm_cachep slab 缓存中。&lt;/p&gt;

&lt;h3&gt;mm_struct 与内核线程&lt;/h3&gt;

&lt;p&gt;内核线程没有进程地址空间，也没有相关的内存描述符。所以内核线程对应的进程描述符中的 mm 域为空。&lt;/p&gt;

&lt;p&gt;当进程被调度时，该进程的 mm 域指向的地址空间被装载到内存，进程描述符中的 active_mm 域会被更新，指向新的地址空间。当内核线程被调度时，内核发现他的 mm 域为 NULL，就会保留前一个进程的地址空间，随后更新内核线程对应进程描述符中的 active_mm 域，使其指向前一个进程的内存描述符。因此在需要时，内核线程可以使用前一个进程的页表。因为内核线程不访问用户空间的内存，仅仅使用地址空间中和内核内存相关的信息。&lt;/p&gt;

&lt;h2&gt;内存区域&lt;/h2&gt;

&lt;p&gt;内存区域由 vm_area_struct 结构体描述，定义在文件 &lt;linux/mm.h&gt; 中，内存区域在内核中也经常被称做虚拟内存区域或 VMA。&lt;/p&gt;

&lt;p&gt;vm_area_struct 结构体描述了指定地址空间内连续区间上的一个独立内存范围。内核将每个内存区域作为一个单独的内存对象管理，每个内存区域都拥有一致的属性，比如访问权限等。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct vm_area_struct {
    struct mm_struct * vm_mm;   /* The address space we belong to. */
    unsigned long vm_start;     /* Our start address within vm_mm. */
    unsigned long vm_end;       /* The first byte after our end address within vm_mm. */

    /* linked list of VM areas per task, sorted by address */
    struct vm_area_struct *vm_next;

    pgprot_t vm_page_prot;      /* Access permissions of this VMA. */
    unsigned long vm_flags;     /* Flags, see mm.h. */

    struct rb_node vm_rb;

    /*
     * For areas with an address space and backing store,
     * linkage into the address_space-&amp;gt;i_mmap prio tree, or
     * linkage to the list of like vmas hanging off its node, or
     * linkage of vma in the address_space-&amp;gt;i_mmap_nonlinear list.
     */
    union {
        struct {  
            struct list_head list;
            void *parent;   /* aligns with prio_tree_node parent */
            struct vm_area_struct *head;
        } vm_set;

        struct raw_prio_tree_node prio_tree_node;
    } shared;

    /*
     * A file&amp;#39;s MAP_PRIVATE vma can be in both i_mmap tree and anon_vma
     * list, after a COW of one of the file pages.  A MAP_SHARED vma
     * can only be in the i_mmap tree.  An anonymous MAP_PRIVATE, stack
     * or brk vma (with NULL file) can only be in an anon_vma list.
     */
    struct list_head anon_vma_chain; /* Serialized by mmap_sem &amp;amp; page_table_lock */
    struct anon_vma *anon_vma;       /* Serialized by page_table_lock */

    /* Function pointers to deal with this struct. */
    const struct vm_operations_struct *vm_ops;

    /* Information about our backing store: */
    unsigned long vm_pgoff;     /* Offset (within vm_file) in PAGE_SIZE units, *not* PAGE_CACHE_SIZE */
    struct file * vm_file;      /* File we map to (can be NULL). */
    void * vm_private_data;     /* was vm_pte (shared mem) */
    unsigned long vm_truncate_count;/* truncate_count or restart_addr */
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;vm_mm 域指向和 VMA 相关的 mm_struct 结构体，注意每个 VMA 对其相关的 mm_struct 结构体来说都是唯一的。即使两个独立的进程将同一个文件映射到各自的地址空间，它们分别都有一个 vm_area_struct 结构体来标志自己的内存区域。但如果两个线程共享一个地址空间，那么它们也同时共享其中的所有 vm_area_struct 结构体。&lt;/p&gt;

&lt;h3&gt;VMA 标志&lt;/h3&gt;

&lt;p&gt;VMA 标志是一种位标志，包含在 vm_flags 域内，标志了内存区域所包含的页面的行为和信息：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;标志&lt;/th&gt;
&lt;th&gt;对 VMA 及其页面的影响&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;VM_READ&lt;/td&gt;
&lt;td&gt;页面可读取&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VM_WRITE&lt;/td&gt;
&lt;td&gt;页面可写&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VM_EXEC&lt;/td&gt;
&lt;td&gt;页面可执行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;VM_SHARED&lt;/td&gt;
&lt;td&gt;页面可共享&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;当访问 VMA 时，需要查看其访问权限。比如进程的对象代码映射区域可能会标志为 VM_READ 和 VM_EXEC，而不会标志为 VM_WRITE。另一方面，可执行对象数据段的映射区域被标志为 VM_READ 和 VM_WRITE，而 VM_EXEC 标志对它毫无意义。只读文件数据段的映射区域仅可被标志为 VM_READ。VM_SHARED 指明了内存区域包含的映射是否可以在多进程间共享，如果该标志被设置，则称其为共享映射。如果未被设置，则只有一个进程可以使用该映射的内容，称其为私有映射。&lt;/p&gt;

&lt;p&gt;VM_IO 标志内存区域中的包含对设备 I/O 空间的映射。该标志通常在设备驱动程序执行 &lt;code&gt;mmap()&lt;/code&gt; 函数进行 I/O 空间映射时才被设置。同时该标志也表示该内存区域不能被包含在任何进程的 coredump 中。&lt;/p&gt;

&lt;h3&gt;实际使用中的内存区域&lt;/h3&gt;

&lt;p&gt;可以使用 /proc 文件系统和 pmap 工具查看给定进程的内存空间和其中所含的内存区域。&lt;/p&gt;

&lt;h2&gt;页表&lt;/h2&gt;

&lt;p&gt;当应用程序访问一个虚拟地址时，必须将虚拟地址转化为物理地址，然后处理器才能解析地址访问请求。&lt;/p&gt;

&lt;p&gt;Linux 中使用三级页表完成地址转换。利用多级页表能够节约地址转换需占用的存放空间。&lt;/p&gt;

&lt;p&gt;顶级页表是页全局目录(PGD)，PGD 包含了一个 pgd_t 类型数组，PGD 中的表项指向二级页目录中的表项：PMD。&lt;/p&gt;

&lt;p&gt;二级页表是中间页目录（PMD)，PMD 是一个 pmd_t 类型数组，其中表项指向 PTE 中的表项。&lt;/p&gt;

&lt;p&gt;最后一级的页表简称页表，其中包含 pte_t 类型的页表项，该页表项指向物理页面。&lt;/p&gt;

&lt;p&gt;每个进程都有自己的页表，内存描述符的 pgd 域指向的就是进程的页全局目录。操作和检索页表时必须使用 page_table_lock 锁。&lt;/p&gt;

&lt;p&gt;由于每次对虚拟内存中的页面访问都必须先解析，所以页表操作的性能非常关键。为了加快搜索，多数体系结构都实现了一个翻译后缓冲器（TLB)。TLB 是一个将虚拟地址映射到物理地址的硬件缓存。&lt;/p&gt;

&lt;h1&gt;相关资料&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://duartes.org/gustavo/blog/post/how-the-kernel-manages-your-memory/&quot;&gt;《How the Kernel Manages Your Memory》&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 11 Dec 2016 10:21:16 +0800</pubDate>
        <link>http://masutangu.com/2016/12/linux-kernel-serial-4/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/12/linux-kernel-serial-4/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>Linux 内核系列－进程调度</title>
        <description>&lt;p&gt;本系列文章为阅读《现代操作系统》《UNIX 环境高级编程》和《Linux 内核设计与实现》所整理的读书笔记，源代码取自 Linux-kernel 2.6.34 版本并有做简化。&lt;/p&gt;

&lt;h1&gt;概念&lt;/h1&gt;

&lt;p&gt;许多适用于进程调度的处理方法同样适用于线程调度。当内核管理线程的时候，调度经常是按照线程级别的，与线程所属的进程基本没有关联。&lt;/p&gt;

&lt;p&gt;调度需要考虑 CPU 的利用率，因为进程切换的代价比较高，进程需要从用户态切换到内核态，保存当前状态，包括在进程表中存储寄存器以便之后加载。接着，调度算法选定一个新进程，将新进程的内存映像载入 MMU。除此之外，进程切换会使整个内存高速缓存失效，强迫缓存从内存中动态重新载入两次。&lt;/p&gt;

&lt;h1&gt;Linux 中的实现&lt;/h1&gt;

&lt;p&gt;Linux 提供了抢占式的多任务模式。进程调度策略通常要在两个矛盾的目标中间寻找平衡：&lt;strong&gt;进程响应迅速（响应时间短）&lt;/strong&gt; 和 &lt;strong&gt;最大系统利用率（高吞吐量）&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;进程调度的常用策略如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;进程优先级&lt;/p&gt;

&lt;p&gt;基于优先级的调度是最基本的一类调度算法。优先级高的先运行，相同优先级的进程按轮转方式进行调度。&lt;/p&gt;

&lt;p&gt;Linux 中采用了两种不同的优先级范围。第一种是用 nice 值，他的范围是从 -20 到 +19，默认为 0。越大的 nice 值意味着更低的优先级。Linux 中，nice 值代表时间片比例。可以通过 ps-el 命令来查看，NI 标记位表示进程的 nice 值。第二种是实时优先级，默认情况下变化范围从 0 到 99。越高的实时优先级值意味着进程优先级越高。任何实时进程的优先级都高于普通进程。可以通过 ps-eo 指定 rtprio 查看进程的实时优先级。显示 “-” 表示该进程不是实时进程。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;时间片&lt;/p&gt;

&lt;p&gt;时间片表示进程在被抢占前可以持续运行的时间。Linux 的 CFS 调度器并不是直接分配时间片到进程，而是将处理器的使用比例分给进程，这个比例还会受 nice 值的影响。Linux 的 CFS 调度器，抢占时机取决于新进程消耗的处理器使用比，如果消耗的使用比比当前进程小，则新进程立刻投入运行，抢占当前进程。否则将推迟运行。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Linux 调度算法&lt;/h2&gt;

&lt;p&gt;Linux 调度器是以模块方式提供的，这种模块化结构被称为&lt;strong&gt;调度器类&lt;/strong&gt;。每个调度器都有一个优先级，基础的调度器代码定义在 kernel/sched.c 文件中，其会按照优先级顺序遍历调度类，拥有一个可执行进程的最高优先级的调度器类胜出，由其选择下一个执行的程序。&lt;/p&gt;

&lt;p&gt;完全公平调度（CFS）是一个针对普通进程的调度类，在 Linux 中称为 SCHED_NORMAL，CFS 算法实现定义在 kernel/sched_fair.c 中。&lt;/p&gt;

&lt;p&gt;CFS 基于一个简单的理念：进程调度的效果应如同系统具备一个理想的多进程任务处理器，每个进程都能获得 1/n 的处理器时间（n是指可运行进程的数量）。同时，我们可以调度给他们无限小的时间周期，所以在任何可测量周期内，我们给予 n 个进程中每个进程同样多的运行时间。&lt;/p&gt;

&lt;p&gt;CFS 的做法是允许每个进程运行一段时间、循环轮转、选择运行最少的进程做为下一个运行进程，而不再采用分配给每个进程时间片的做法了。CFS 在所有可运行进程总数的基础上计算出一个进程应该运行多久，而不是依靠 nice 值来计算时间片。nice 值在 CFS 中被作为进程获得处理器运行比的权重。CFS 为完美多任务中的无限小周期的近似值设立了一个小目标。而这个目标称为“目标延迟”。CFS 还引入每个进程获得的时间片底线，称为最小粒度，默认值为 1ms。任何进程获得的处理器时间是由自己和其他可运行所有可运行进程 nice 值的相对差值决定的。nice 值对时间片的作用是几何加权，nice 值对应的绝对时间是处理器的使用比。&lt;/p&gt;

&lt;h2&gt;Linux 调度的实现&lt;/h2&gt;

&lt;h3&gt;时间记账&lt;/h3&gt;

&lt;p&gt;每次系统时钟节拍发送时，时间片都会被减少一个节拍。当进程的时间片被减少到 0 时，它就会被另一个时间片尚未为 0 的可运行进程抢占。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;调度器结构&lt;/p&gt;

&lt;p&gt;CFS 使用调度器结构（定义在&lt;linux/sched.h&gt; 的 &lt;code&gt;struct sched_entity&lt;/code&gt; 中）来追踪进程运行记账。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct sched_entity {
    struct load_weight  load;       /* for load-balancing */
    struct rb_node      run_node;
    struct list_head    group_node;
    unsigned int        on_rq;

    u64         exec_start;
    u64         sum_exec_runtime;
    u64         vruntime;
    u64         prev_sum_exec_runtime;

    u64         last_wakeup;
    u64         avg_overlap;

    u64         nr_migrations;

    u64         start_runtime;
    u64         avg_wakeup;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;进程描述符 &lt;code&gt;struct task_struct&lt;/code&gt; 的成员变量 se 即为 &lt;code&gt;sched_entity&lt;/code&gt; 类型。&lt;/p&gt;

&lt;p&gt;vruntime 变量存放进程的虚拟运行时间，该运行时间的计算经过了所有可运行进程总数的标准化。虚拟时间是以 ns 为单位的，所以 vruntime 和定时器节拍不再相关。定义在 kernel/sched_fair.c 文件的 &lt;code&gt;update_curr()&lt;/code&gt; 函数实现了记账功能：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/* cpu runqueue to which this cfs_rq is attached */
static inline struct rq *rq_of(struct cfs_rq *cfs_rq)
{
    return cfs_rq-&amp;gt;rq;
}

static void update_curr(struct cfs_rq *cfs_rq)
{
    struct sched_entity *curr = cfs_rq-&amp;gt;curr;
    u64 now = rq_of(cfs_rq)-&amp;gt;clock;
    unsigned long delta_exec;

    if (unlikely(!curr))
        return;

    /*
    * Get the amount of time the current task was running
    * since the last time we changed load (this cannot
    * overflow on 32 bits):
    */
    delta_exec = (unsigned long)(now - curr-&amp;gt;exec_start);
    if (!delta_exec)
        return;

    __update_curr(cfs_rq, curr, delta_exec);
    curr-&amp;gt;exec_start = now;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;update_curr()&lt;/code&gt; 计算了当前进程的执行时间，保存在变量 &lt;code&gt;delta_exec&lt;/code&gt; 中，然后又将其传给 &lt;code&gt;__update_curr()&lt;/code&gt; 进行加权计算，最后将权重值与当前运行进程的 vruntime 相加。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/*
* Update the current task&amp;#39;s runtime statistics. Skip current tasks that
* are not in our scheduling class.
*/
static inline void
__update_curr(struct cfs_rq *cfs_rq, struct sched_entity *curr,
        unsigned long delta_exec)
{
    unsigned long delta_exec_weighted;

    schedstat_set(curr-&amp;gt;exec_max, max((u64)delta_exec, curr-&amp;gt;exec_max));

    curr-&amp;gt;sum_exec_runtime += delta_exec;
    schedstat_add(cfs_rq, exec_clock, delta_exec);
    delta_exec_weighted = calc_delta_fair(delta_exec, curr);

    curr-&amp;gt;vruntime += delta_exec_weighted;
    update_min_vruntime(cfs_rq);
}

static void update_min_vruntime(struct cfs_rq *cfs_rq)
{
    u64 vruntime = cfs_rq-&amp;gt;min_vruntime;

    if (cfs_rq-&amp;gt;curr)
        vruntime = cfs_rq-&amp;gt;curr-&amp;gt;vruntime;

    if (cfs_rq-&amp;gt;rb_leftmost) {
        struct sched_entity *se = rb_entry(cfs_rq-&amp;gt;rb_leftmost,
                        struct sched_entity,
                        run_node);

        if (!cfs_rq-&amp;gt;curr)
            vruntime = se-&amp;gt;vruntime;
        else
            vruntime = min_vruntime(vruntime, se-&amp;gt;vruntime);
    }

    cfs_rq-&amp;gt;min_vruntime = max_vruntime(cfs_rq-&amp;gt;min_vruntime, vruntime);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;update_curr()&lt;/code&gt; 是由系统定时器周期性调用的，无论是在进程处于可运行状态还是阻塞处于不可运行状态。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;进程选择&lt;/h3&gt;

&lt;p&gt;当 CFS 需要选择下一个运行进程时，它会挑选一个具有最小 vruntime 的进程。CFS 使用红黑树来组织可运行进程队列，其节点的键值是可运行进程的 vruntime。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;挑选下一个任务&lt;/p&gt;

&lt;p&gt;CFS 选择 vruntime 最小的那个，对应的就是树中最左侧的叶子节点。实现这一过程的函数是 &lt;code&gt;__pick_next_entity()&lt;/code&gt;，定义在 &lt;code&gt;kernel/sched_fair.c&lt;/code&gt; 中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;static struct sched_entity *__pick_next_entity(struct cfs_rq *cfs_rq)
{
    struct rb_node *left = cfs_rq-&amp;gt;rb_leftmost;

    if (!left)
        return NULL;

    return rb_entry(left, struct sched_entity, run_node);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;注意 &lt;code&gt;__pick_next_entity()&lt;/code&gt; 函数并不会遍历数找到最左叶子节点，该值已经缓存在 &lt;code&gt;rb_leftmost&lt;/code&gt; 字段中。如果该函数返回 NULL，表示没有可运行进程，CFS 调度器选择 idle 任务运行。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;添加进程&lt;/p&gt;

&lt;p&gt;添加进程和缓存最左叶子节点，发生在进程变成可运行状态（被唤醒）或者通过 &lt;code&gt;fork()&lt;/code&gt; 调用第一次创建进程时，由调用 &lt;code&gt;enqueue_entity()&lt;/code&gt; 实现：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;static void enqueue_entity(
    struct cfs_rq *cfs_rq, struct sched_entity *se, int flags)
{
    /*
    * Update the normalized vruntime before updating min_vruntime
    * through callig update_curr().
    */
    if (!(flags &amp;amp; ENQUEUE_WAKEUP) || (flags &amp;amp; ENQUEUE_MIGRATE))
        se-&amp;gt;vruntime += cfs_rq-&amp;gt;min_vruntime;  // 这里在下文有解释

    /*
    * Update run-time statistics of the &amp;#39;current&amp;#39;.
    */
    update_curr(cfs_rq);
    account_entity_enqueue(cfs_rq, se);

    if (flags &amp;amp; ENQUEUE_WAKEUP) {
        place_entity(cfs_rq, se, 0);
        enqueue_sleeper(cfs_rq, se);
    }

    update_stats_enqueue(cfs_rq, se);
    check_spread(cfs_rq, se);
    if (se != cfs_rq-&amp;gt;curr)
        __enqueue_entity(cfs_rq, se);
}

static void
place_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int initial)
{
    u64 vruntime = cfs_rq-&amp;gt;min_vruntime;

    /*
    * The &amp;#39;current&amp;#39; period is already promised to the current tasks,
    * however the extra weight of the new task will slow them down a
    * little, place the new task so that it fits in the slot that
    * stays open at the end.
    */
    if (initial &amp;amp;&amp;amp; sched_feat(START_DEBIT))
        vruntime += sched_vslice(cfs_rq, se);

    /* sleeps up to a single latency don&amp;#39;t count. */
    if (!initial &amp;amp;&amp;amp; sched_feat(FAIR_SLEEPERS)) {
        unsigned long thresh = sysctl_sched_latency;

        /*
        * Convert the sleeper threshold into virtual time.
        * SCHED_IDLE is a special sub-class.  We care about
        * fairness only relative to other SCHED_IDLE tasks,
        * all of which have the same weight.
        */
        if (sched_feat(NORMALIZED_SLEEPER) &amp;amp;&amp;amp; (!entity_is_task(se) ||
                task_of(se)-&amp;gt;policy != SCHED_IDLE))
            thresh = calc_delta_fair(thresh, se);

        /*
        * Halve their sleep time&amp;#39;s effect, to allow
        * for a gentler effect of sleepers:
        */
        if (sched_feat(GENTLE_FAIR_SLEEPERS))
            thresh &amp;gt;&amp;gt;= 1;  // /* 补偿减为调度周期的一半 */

        vruntime -= thresh;
    }

    /* ensure we never gain time by being placed backwards. */
    vruntime = max_vruntime(se-&amp;gt;vruntime, vruntime);

    se-&amp;gt;vruntime = vruntime;
}

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;enqueue_entity 更新运行时间和一些统计数据，然后调用 &lt;code&gt;__enqueue_entity()&lt;/code&gt; 进行插入操作。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;/*
* Enqueue an entity into the rb-tree:
*/
static void __enqueue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
{
    struct rb_node **link = &amp;amp;cfs_rq-&amp;gt;tasks_timeline.rb_node;
    struct rb_node *parent = NULL;
    struct sched_entity *entry;
    s64 key = entity_key(cfs_rq, se);
    int leftmost = 1;

    /*
    * Find the right place in the rbtree:
    */
    while (*link) {
        parent = *link;
        entry = rb_entry(parent, struct sched_entity, run_node);
        /*
        * We dont care about collisions. Nodes with
        * the same key stay together.
        */
        if (key &amp;lt; entity_key(cfs_rq, entry)) {
            link = &amp;amp;parent-&amp;gt;rb_left;
        } else {
            link = &amp;amp;parent-&amp;gt;rb_right;
            leftmost = 0;
        }
    }

    /*
    * Maintain a cache of leftmost tree entries (it is frequently
    * used):
    */
    if (leftmost)
        cfs_rq-&amp;gt;rb_leftmost = &amp;amp;se-&amp;gt;run_node;

    rb_link_node(&amp;amp;se-&amp;gt;run_node, parent, link);
    rb_insert_color(&amp;amp;se-&amp;gt;run_node, &amp;amp;cfs_rq-&amp;gt;tasks_timeline);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;如果新进程的 vruntime 初值为 0 的话，那么它在相当长的时间内都会保持抢占CPU的优势，老的进程就会饿死，因此 CFS 在每个 CPU 的运行队列 cfs_rq 都维护一个 min_vruntime 字段，记录该运行队列中所有进程的 vruntime 最小值，新进程的初始 vruntime 值就以它所在运行队列的 min_vruntime 为基础来设置，与老进程保持在合理的差距范围内。&lt;/p&gt;

&lt;p&gt;如果休眠进程的 vruntime 保持不变，而其他运行进程的 vruntime 一直在增加，那么等到休眠进程被唤醒的时候，它的 vruntime 比别人小很多，会使其长时间拥有抢占 CPU 的优势。因此 CFS 在休眠进程被唤醒时重新设置 vruntime 值，以 min_vruntime 值为基础，给予一定的补偿，但不能补偿太多。&lt;/p&gt;

&lt;p&gt;在多 CPU 的系统上，不同的CPU的负载不一样，有的 CPU 更忙一些，而每个 CPU 都有自己的运行队列，每个队列中的进程的 vruntime 也走得有快有慢。如果一个进程从 min_vruntime 更小的 CPU A上迁移到 min_vruntime 更大的 CPU B 上，可能就会占便宜了，因为 CPU B 的运行队列中进程的 vruntime 普遍比较大，迁移过来的进程就会获得更多的 CPU 时间片。为了避免这种场景，当进程从一个 CPU 的运行队列中出来 (调用 &lt;code&gt;dequeue_entity&lt;/code&gt;) 的时候，它的 vruntime 要减去队列的 min_vruntime 值；而当进程加入另一个CPU的运行队列 (调用 &lt;code&gt;enqueue_entity&lt;/code&gt;) 时，它的 vruntime 要加上该队列的 min_vruntime 值。这样，进程从一个 CPU 迁移到另一个 CPU 之后，vruntime 保持相对公平。&lt;/p&gt;

&lt;p&gt;参考自&lt;a href=&quot;http://linuxperf.com/?p=42&quot;&gt;《从几个问题开始理解CFS调度器》&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;删除进程&lt;/p&gt;

&lt;p&gt;删除进程发生在进程阻塞或终止时：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;static void
dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se, int sleep)
{
    /*
    * Update run-time statistics of the &amp;#39;current&amp;#39;.
    */
    update_curr(cfs_rq);

    update_stats_dequeue(cfs_rq, se);
    if (sleep) {
#ifdef CONFIG_SCHEDSTATS
        if (entity_is_task(se)) {
            struct task_struct *tsk = task_of(se);

            if (tsk-&amp;gt;state &amp;amp; TASK_INTERRUPTIBLE)
                se-&amp;gt;sleep_start = rq_of(cfs_rq)-&amp;gt;clock;
            if (tsk-&amp;gt;state &amp;amp; TASK_UNINTERRUPTIBLE)
                se-&amp;gt;block_start = rq_of(cfs_rq)-&amp;gt;clock;
        }
#endif
    }

    clear_buddies(cfs_rq, se);

    if (se != cfs_rq-&amp;gt;curr)
        __dequeue_entity(cfs_rq, se);
    account_entity_dequeue(cfs_rq, se);
    update_min_vruntime(cfs_rq);

    /*
    * Normalize the entity after updating the min_vruntime because the
    * update can refer to the -&amp;gt;curr item and we need to reflect this
    * movement in our normalized position.
    */
    if (!sleep)
        se-&amp;gt;vruntime -= cfs_rq-&amp;gt;min_vruntime;
}

static void __dequeue_entity(struct cfs_rq *cfs_rq, struct sched_entity *se)
{
    if (cfs_rq-&amp;gt;rb_leftmost == &amp;amp;se-&amp;gt;run_node) {
        struct rb_node *next_node;

        next_node = rb_next(&amp;amp;se-&amp;gt;run_node);
        cfs_rq-&amp;gt;rb_leftmost = next_node;
    }

    rb_erase(&amp;amp;se-&amp;gt;run_node, &amp;amp;cfs_rq-&amp;gt;tasks_timeline);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;调度器的入口&lt;/h3&gt;

&lt;p&gt;进程调度的主要入口是函数 &lt;code&gt;schedule()&lt;/code&gt;，定义在 kernel/sched.c 中。schedule() 先找到一个最高优先级的调度类，调度类有各自的可运行队列，由调度类返回最高优先级的进程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;static inline struct task_struct *
    pick_next_task(struct rq *rq)
    {
        const struct sched_class *class;
        struct task_struct *p;

        /*
        * Optimization: we know that if all tasks are in
        * the fair class we can call that function directly:
        */
        if (likely(rq-&amp;gt;nr_running == rq-&amp;gt;cfs.nr_running)) {
            p = fair_sched_class.pick_next_task(rq);
            if (likely(p))
                return p;
        }

        class = sched_class_highest;
        for ( ; ; ) {
            p = class-&amp;gt;pick_next_task(rq);
            if (p)
                return p;
            /*
            * Will never be NULL as the idle class always
            * returns a non-NULL p:
            */
            class = class-&amp;gt;next;
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;函数开始部分的优化，CFS 是普通进程的调度类，如果所有可运行进程数量等于 CFS 类对应的可运行进程数，意味着可以直接选择 CFS 为调度类。&lt;/p&gt;

&lt;p&gt;每个调度类都实现了 &lt;code&gt;pick_next_task()&lt;/code&gt; 函数，其返回下一个可运行进程的指针。&lt;code&gt;pick_next_task()&lt;/code&gt; 实现中会调用 &lt;code&gt;pick_next_entity()&lt;/code&gt;，该函数会调用 &lt;code&gt;__pick_next_entity()&lt;/code&gt; 函数。&lt;/p&gt;

&lt;h3&gt;睡眠和唤醒&lt;/h3&gt;

&lt;p&gt;睡眠时进程把自己标记成休眠状态，从可执行红黑树中移出，放入等待队列中，然后调用 &lt;code&gt;schedule()&lt;/code&gt; 选择和执行下一个进程。唤醒的过程刚好相反：进程被设置为可运行状态，然后从等待队列中移到可执行红黑树中。&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;等待队列&lt;/p&gt;

&lt;p&gt;内核用 wake_queue_head_t 表示等待队列。休眠和唤醒实现比较复杂，因为要避免竞争条件:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;DEFINE_WAIT(wait);

add_wait_queue(q, &amp;amp;wait);
while (!condition) {  /* condition 是我们等待的事件 */
    prepare_to_wait(&amp;amp;q, &amp;amp;wait, TASK_INTERRUPTIBLE);
    if (signal_pending(current))
        /* 处理信号 */
        schedule();
}
finish_wait(&amp;amp;q, &amp;amp;wait);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;步骤如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;1. 调用宏 DEFINE_WAIT() 创建一个等待队列的项
2. 调用 add_wait_queue() 把自己加入到队列中，该队列会在进程等待条件满足时唤醒它
3. 调用 prepare_to_wait() 方法将进程的状态变更为 TASK_INTERRUPTIBLE 或 TASK_UNINTERRUPTIBLE
4. 如果状态被设置为 TASK_INTERRUPTIBLE，则信号唤醒进程，检查并处理信号
5. 当进程被唤醒时，会再次检查条件是否为真。如果是，则退出循环。如果不是，再次调用 schedule() 
6. 当条件满足后，进程设置为 TASK_RUNNING 并调用 finish_wait() 方法将自己移出等待队列
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;位于 fs/notify/inotify/inotify_user.c 的 &lt;code&gt;inotify_read()&lt;/code&gt;，负责从通知文件描述符中读取信息。其实现是等待队列的典型用法：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;static ssize_t inotify_read(struct file *file, char __user *buf,
            size_t count, loff_t *pos)
{
    struct fsnotify_group *group;
    struct fsnotify_event *kevent;
    char __user *start;
    int ret;
    DEFINE_WAIT(wait);

    start = buf;
    group = file-&amp;gt;private_data;

    while (1) {
        prepare_to_wait(&amp;amp;group-&amp;gt;notification_waitq, &amp;amp;wait, TASK_INTERRUPTIBLE);

        mutex_lock(&amp;amp;group-&amp;gt;notification_mutex);
        kevent = get_one_event(group, count);
        mutex_unlock(&amp;amp;group-&amp;gt;notification_mutex);

        if (kevent) {
            ret = PTR_ERR(kevent);
            if (IS_ERR(kevent))
                break;
            ret = copy_event_to_user(group, kevent, buf);
            fsnotify_put_event(kevent);
            if (ret &amp;lt; 0)
                break;
            buf += ret;
            count -= ret;
            continue;
        }

        ret = -EAGAIN;
        if (file-&amp;gt;f_flags &amp;amp; O_NONBLOCK)
            break;
        ret = -EINTR;
        if (signal_pending(current))
            break;

        if (start != buf)
            break;

        schedule();
    }

    finish_wait(&amp;amp;group-&amp;gt;notification_waitq, &amp;amp;wait);
    if (start != buf &amp;amp;&amp;amp; ret != -EFAULT)
        ret = buf - start;
    return ret;
}

void
prepare_to_wait(wait_queue_head_t *q, wait_queue_t *wait, int state)
{
    unsigned long flags;

    wait-&amp;gt;flags &amp;amp;= ~WQ_FLAG_EXCLUSIVE;
    spin_lock_irqsave(&amp;amp;q-&amp;gt;lock, flags);
    if (list_empty(&amp;amp;wait-&amp;gt;task_list))
        __add_wait_queue(q, wait);
    set_current_state(state);
    spin_unlock_irqrestore(&amp;amp;q-&amp;gt;lock, flags);
}

static inline void __add_wait_queue(wait_queue_head_t *head, wait_queue_t *new)
{
    list_add(&amp;amp;new-&amp;gt;task_list, &amp;amp;head-&amp;gt;task_list);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;唤醒&lt;/p&gt;

&lt;p&gt;唤醒操作通过函数 &lt;code&gt;wake_up()&lt;/code&gt; 进行，他会唤醒指定的等待队列上的所有进程。其调用 &lt;code&gt;try_to_wake_up()&lt;/code&gt;，该函数负责将进程设置为 TASK_RUNNING 状态，调用 &lt;code&gt;enqueue_task()&lt;/code&gt; 将进程放入红黑树。如果被唤醒的进程优先级比当前正在执行的进程优先级高，还需要设置 need_resched 标志。通常哪段代码促使条件达成，就负责调用 &lt;code&gt;wake_up()&lt;/code&gt; 函数。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;抢占和上下文切换&lt;/h2&gt;

&lt;p&gt;上下文切换由定义在 kernel/sched.c 中的 &lt;code&gt;context_switch()&lt;/code&gt; 函数负责。每当新进程准备投入运行时，&lt;code&gt;schedule()&lt;/code&gt; 就会调用该函数，它完成两项基本工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用声明在 &lt;asm/mmu_context.h&gt; 中的 switch_mm()，该函数负责把虚拟内存从上一个进程映射切换到新进程中。&lt;/li&gt;
&lt;li&gt;调用声明在 &lt;asm/system.h&gt; 中的 switch_to()，该函数负责从上一个进程的处理器状态切换到新进程的处理器状态，包括保存、恢复栈信息和寄存器信息，还有其他和体系结构相关的状态信息，都必须以每个进程为对象进行管理和保存。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;内核提供 need_resched 标志来表明是否需要重新调度。当某个进程应该被抢占时，&lt;code&gt;scheduler_tick()&lt;/code&gt; 就会设置这个标志；当一个优先级高的进程进入可执行状态时，&lt;code&gt;try_to_wake_up()&lt;/code&gt; 也会设置这个标志。内核检查该标志，当其被设置时调用 &lt;code&gt;schedule()&lt;/code&gt; 来切换到新进程。&lt;/p&gt;

&lt;p&gt;再次返回到用户空间以及从中断返回的时候，内核也会检查 need_resched 标志。如果已被设置，内核会在继续执行前调用调度程序。&lt;/p&gt;

&lt;p&gt;每个进程都包含一个 need_resched 标志，这是因为访问进程描述符内的数值要比访问一个全局变量快（因为 current 宏速度很快并且描述符通常都在高速缓存中）。2.6 版本中 need_resched 被移到 thread_info 结构体里，用一个特别的标志变量中的一位来表示。&lt;/p&gt;

&lt;h3&gt;用户抢占&lt;/h3&gt;

&lt;p&gt;内核即将返回用户空间时，如果 need_resched 标识被设置，会导致 schedule() 被调用，此时就会发生用户抢占。简而言之，用户抢占在以下情况产生：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;从系统调用返回用户空间时&lt;/li&gt;
&lt;li&gt;从中断处理程序返回用户空间时&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;内核抢占&lt;/h3&gt;

&lt;p&gt;Linux 系统中，只要重新调度是安全的，内核就可以在任何时间抢占正在执行的任务。只要没有持有锁，内核就可以抢占。&lt;/p&gt;

&lt;p&gt;为了支持内核抢占，每个进程的 thread_info 引入 preempt_count 计数器。该计数器初始值为 0，每当使用锁的时候数值加 1，释放锁时数值减 1。当数值为 0 时，内核就可以抢占。从中断返回内核空间时，内核会检查 need_resched 和 preempt_count 的值。如果 need_resched 被设置，并且 preempt_count 为 0，此时调度程序会被调用。&lt;/p&gt;

&lt;p&gt;如果内核中的进程被阻塞了，或显式调用了 &lt;code&gt;schedule()&lt;/code&gt;，内核抢占也会显式地发生。 &lt;/p&gt;

&lt;p&gt;简而言之，内核抢占会发生在：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;中断处理程序正在执行，且返回内核空间之前&lt;/li&gt;
&lt;li&gt;内核代码再一次具有可抢占性&lt;/li&gt;
&lt;li&gt;如果内核中的任务显式调用 schedule()&lt;/li&gt;
&lt;li&gt;如果内核中的任务阻塞&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;实时调度策略&lt;/h2&gt;

&lt;p&gt;Linux 提供了两种实时调度策略：SCHED_FIFO 和 SCHED_RR。而普通的、非实时的调度策略是 SCHED_NORMAL。&lt;/p&gt;

&lt;p&gt;SCHED_FIFO 实现了一种简单的先入先出的调度算法。处于可运行状态的 SCHED_FIFO 级的进程会比任何 SCHED_NORMAL 级的进程都先得到调度。一旦一个 SCHED_FIFO 级进程处于可执行状态，就会一直执行，直到受阻塞或显式释放处理器。只有更高优先级的 SCHED_FIFO 或者 SCHED_RR 任务才能抢占 SCHED_FIFO 任务。&lt;/p&gt;

&lt;p&gt;SCHED_RR 与 SCHED_FIFO 大体相同，只是 SCHED_RR 级的进程在耗尽事先分配的时间片后就不再继续执行。SCHED_RR 即带有时间片的 SCHED_FIFO，时间片只能用来重新调度同一优先级的进程。&lt;/p&gt;
</description>
        <pubDate>Thu, 01 Dec 2016 16:40:36 +0800</pubDate>
        <link>http://masutangu.com/2016/12/linux-kernel-serial-3/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/12/linux-kernel-serial-3/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>Linux 内核系列－进程通信和同步</title>
        <description>&lt;p&gt;本系列文章为阅读《现代操作系统》《UNIX 环境高级编程》和《Linux 内核设计与实现》所整理的读书笔记，源代码取自 Linux-kernel 2.6.34 版本并有做简化。&lt;/p&gt;

&lt;h1&gt;概念&lt;/h1&gt;

&lt;h2&gt;竞争条件&lt;/h2&gt;

&lt;p&gt;多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时许，称为竞争条件。&lt;/p&gt;

&lt;h2&gt;忙等待的互斥&lt;/h2&gt;

&lt;p&gt;几种实现互斥的方案：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;屏蔽中断&lt;/p&gt;

&lt;p&gt;在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，包括时钟中断。CPU 只有在发生中断的时候才会进行进程切换，这样在中断被屏蔽后 CPU 将不会被切换到其他进程。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;锁变量&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;严格轮换法&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;while (TRUE) {
    while (turn != 0) 
    critical_region(); 
    turn = 1;
    noncritical_region();
}

while (TRUE) {
    while (turn != 1) 
    critical_region(); 
    turn = 0;
    noncritical_region();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;忙等待检查变量。使用忙等待的锁称为自旋锁。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Peterson 解法&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#define FALSE 0 
#define TRUE  1
#define N     2                    /* number of processes */

int turn;                          /* whose turn is it? */
int interested[N];                 /* all values initially 0 (FALSE) */

void enter_region(int process);    /* process is 0 or 1 */
{
    int other;

    other = 1 - process;
    interested[process] = TRUE;
    turn = process;
    while (turn == process &amp;amp;&amp;amp; interested[other] == TRUE); 
}

void leave_region(int process)     /* process: who is leaving */ 
{
    interested[process] = FALSE;   /* indicate departure from critical region */ 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TSL 指令&lt;/p&gt;

&lt;p&gt;TSL（测试并加锁）指令将一个内存字 lock 读到寄存器 RX 中，然后在该内存地址上存一个非零值。读字和写字操作保证是不可分割的，即在该指令结束前其他处理器均不允许访问该内存字。执行 TSL 指令的 CPU 将锁住内存总线，以防止其他 CPU 在本指令结束前访问内存。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;enter region:
    TSL REGISTER, LOCK      | copy lock to register and set lock to 1
    CMP REGISTER, #0        | was lock zero?
    JNE enter_region        | if it was not zero, lock was set, so loop
    RET                     | return to caller; critical region entered

leave region:
    MOVE LOCK, #0           | store a 0 in lock
    RET                     | return to caller  
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;一个可替代 TSL 的指令是 XCHG，它原子性的交换了两个位置的内容，例如寄存器和内存字。代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;enter region:
    MOVE REGISTER, #1       | put a 1 in the register
    XCHG REGISTER, LOCK     | swap the contents of the register and lock variable
    CMP REGISTER, #0        | was lock zero?
    JNE enter_region        | if it was non zero, lock was set, so loop
    RET                     | return to caller; critical region entered

leave region:
    MOVE LOCK, #0           | store a 0 in lock
    RET                     | return to caller
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;忙等待存在优先级反转的问题。假设存在 H 和 L 两个进程，L 优先级较低，调度规则规定只要 H 处于就绪状态就可以允许。在某一时刻，L 处于临界区中，此时 H 变到就绪态，然后开始忙等待。但由于 H 就绪时 L 不会被调度，也就无法离开临界区，所以 H 将永远忙等待下去。&lt;/p&gt;

&lt;h2&gt;信号量&lt;/h2&gt;

&lt;p&gt;信号量使用整型变量来累计唤醒次数。信号量的取值可以为 0 或者为正值。信号量有 up 和 down 这两种操作。&lt;/p&gt;

&lt;p&gt;使用信号量解决生产者－消费者问题：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#define N 100                   /* number of slots in the buffer */
typedef int semaphore;          /* semaphores are a special kind of int */
semaphore mutex = 1;            /* controls access to critical region */
semaphore empty = N;            /* counts empty buffer slots */
semaphore full = 0;             /* counts full buffer slots */

void producer(void) {
  int item;
  while (TRUE) {                /* TRUE is the constant 1 */
    item = produce_item();      /* generate something to put in buffer */
    down(&amp;amp;empty);               /* decrement empty count */
    down(&amp;amp;mutex);               /* enter critical region */
    insert_item(item);          /* put new item in buffer */
    up(&amp;amp;mutex);                 /* leavecriticalregion */
    up(&amp;amp;full);                  /* increment count of full slots */
  } 
}

void consumer(void) {
  int item;
  while (TRUE) {                /* infinite loop */
    down(&amp;amp;full);                /* decrement full count */
    down(&amp;amp;mutex);               /* enter critical region */
    item = remove_item();       /* take item from buffer */
    up(&amp;amp;mutex);                 /* leavecriticalregion */
    up(&amp;amp;empty);                 /* increment count of empty slots */
    consume item(item);         /* do something with the item */
  } 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;中断可以用信号量来实现，最自然的方法是为每个 I/O 设备设置一个信号量，初始值为 0。在启动 I/O 设备后，管理进程就立即对相关信号量执行一个 down 操作，于是进程被阻塞。当中断到来时，中断处理程序随后对相关信号量执行一个 up 操作，从而使进程变成就绪态。&lt;/p&gt;

&lt;p&gt;信号量可以用以实现互斥，也可以用于事件同步。&lt;/p&gt;

&lt;h2&gt;互斥量&lt;/h2&gt;

&lt;p&gt;互斥量是信号量的简化版本，称为互斥量。常用于用户线程包。互斥量只有两个状态：解锁和加锁。&lt;/p&gt;

&lt;p&gt;TSL 或 XCHG 指令可以方便的在用户空间中实现互斥量：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;mutex_lock:
    TSL REGISTER, MUTEX                 | copy mutex to register and set mutex to 1
    CMP REGISTER, #0                    | was mutex zero?
    JZE ok                              | if it was zero, mutex was unlocked, so return
    CALL thread_yield                   | mutex is busy; schedule another thread
    JMP mutex_lock                      | try again 
ok: RET                                 | return to caller; critical region entered


mutex_unlock:
    MOVE MUTEX, #0                      | store a 0 in mutex
    RET                                 | return to caller
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;mutex_lock 和 enter_region 很类似，但有个关键的区别。当 enter_region 进入临界区失败时，进程始终在重复测试锁（忙等待），直到时钟超时，重新调度其他进程运行。&lt;/p&gt;

&lt;p&gt;在用户线程中，由于没有时钟来停止运行过长的线程，因此需要调用 thread_yield 来让出 CPU。&lt;/p&gt;

&lt;p&gt;Pthread 提供多种同步机制，包括互斥量和条件变量。&lt;strong&gt;条件变量总是结合互斥量一起使用。&lt;/strong&gt;另外条件变量不会存在内存中，需要避免丢失信号。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#define MAX 1000000000                                  /* how many numbers to produce */
pthread_mutex_t the mutex; 
pthread_cond_t condc, condp;                            /* used for signaling */
int buffer = 0;                                         /* buffer used between producer and consumer */

void *producer(void *ptr) {                             /* produce data */
    int i;

    for (i= 1; i &amp;lt;= MAX; i++) {
        pthread_mutex_lock(&amp;amp;the_mutex);                 /* get exclusive access to buffer */            
        while (buffer != 0) 
            pthread_cond_wait(&amp;amp;condp, &amp;amp;the_mutex);
        buffer = i;                                     /* put item in buffer */    
        pthread_cond_signal(&amp;amp;condc);                    /* wakeupconsumer */
        pthread_mutex_unlock(&amp;amp;the_mutex);               /* release access to buffer */
    }
    pthread exit(0); 
}


void *consumer(void *ptr) {                             /* consume data */
    int i;
    for (i = 1; i &amp;lt;= MAX; i++) {
        pthread_mutex_lock(&amp;amp;the_mutex);                 /* get exclusive access to buffer */ 
        while (buffer ==0 ) 
            pthread_cond_wait(&amp;amp;condc, &amp;amp;the_mutex);      /* wakeupproducer */
        buffer = 0;
        pthread_cond_signal(&amp;amp;condp);  
        pthread_mutex_unlock(&amp;amp;the_mutex);               /* release access to buffer */
    }
    pthread exit(0); 
}

int main(int argc, char **argv) {
    pthread_t pro, con;
    pthread_mutex_init(&amp;amp;the_mutex, 0); 
    pthread_cond_init(&amp;amp;condc, 0); 
    pthread_cond_init(&amp;amp;condp, 0); 
    pthread_create(&amp;amp;con, 0, consumer, 0); 
    pthread_create(&amp;amp;pro, 0, producer, 0); 
    pthread_join(pro, 0);
    pthread_join(con, 0);
    pthread_cond_destroy(&amp;amp;condc); 
    pthread_cond_destroy(&amp;amp;condp); 
    pthread_mutex_destroy(&amp;amp;the_mutex);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h1&gt;系统调用及库函数&lt;/h1&gt;

&lt;h2&gt;线程同步&lt;/h2&gt;

&lt;h3&gt;互斥量&lt;/h3&gt;

&lt;p&gt;可以使用 pthread 的互斥接口来保护数据。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;pthread.h&amp;gt;

int pthread_mutex_lock(pthread_mutex_t *mutex);

int pthread_mutex_trylock(pthread_mutex_t *mutex);

int pthread_mutex_unlock(pthread_mutex_t *mutex);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;读写锁&lt;/h3&gt;

&lt;p&gt;读写锁可以有三个状态：读模式下加锁状态，写模式下加锁状态，不加锁状态。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;pthread.h&amp;gt;

int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;条件变量&lt;/h3&gt;

&lt;p&gt;条件变量与互斥量一起使用时，允许线程以无竞争的方式等待特定的条件发生。&lt;strong&gt;条件本身是由互斥量保护的，线程在改变条件状态前必须先锁住互斥量&lt;/strong&gt;。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;
#include &amp;lt;pthread.h&amp;gt;

int pthread_cond_wait(pthread_cond_t *restrict cond,
                     pthread_mutex_t *restrict mutex);

int pthread_cond_signal(pthread_cond_t *cond);

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;传递给 pthread_cond_wait 的互斥量对条件进行保护。调用者把锁住的互斥量传给函数，函数自动把调用线程放到等待条件的线程列表上，再对互斥量解锁。这就&lt;strong&gt;关闭了条件检查和线程进入休眠状态等待条件改变这两个操作之间的时间通道，因此线程不会错过条件的任何变化&lt;/strong&gt;。pthread_cond_wait 返回时，互斥量再次被锁住。&lt;/p&gt;

&lt;h3&gt;自旋锁&lt;/h3&gt;

&lt;p&gt;自旋锁与互斥量类似，但其不是通过休眠使进程阻塞，而是获得锁之前一直处于忙等待。自锁锁可以用于以下情况：锁被持有时间短，而且线程不希望在重新调度上花费太多成本。&lt;/p&gt;

&lt;p&gt;自旋锁通常用于底层原语用于实现其它类型的锁。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;pthread.h&amp;gt;

int pthread_spin_lock(pthread_spinlock_t *lock);

int pthread_spin_trylock(pthread_spinlock_t *lock);

int pthread_spin_unlock(pthread_spinlock_t *lock);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;屏障&lt;/h3&gt;

&lt;p&gt;屏障是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都到达某一个点，然后从该点继续执行。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;pthread.h&amp;gt;

int pthread_barrier_init(pthread_barrier_t *restrict barrier,
                        const pthread_barrierattr_t *restrict attr,
                        unsigned int count);

int pthread_barrier_wait(pthread_barrier_t *barrier);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;进程同步与通信&lt;/h2&gt;

&lt;h3&gt;管道&lt;/h3&gt;

&lt;p&gt;管道是 UNIX 系统 IPC 的最古老方式。管道是半双工的，只能在具有公共祖先的两个进程之间使用。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;unistd.h&amp;gt;

int pipe(int fd[2]);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;常量 PIPE_BUF 规定了内核的管道缓冲区大小，如果写管道的字节数小于等于 PIPE_BUF，则此操作不会与其它进程对同一管道的写操作交叉进行。&lt;/p&gt;

&lt;h3&gt;FIFO&lt;/h3&gt;

&lt;p&gt;通过 FIFO 不相关的进程也能交换数据。创建 FIFO 类似创建文件：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;sys/stat.h&amp;gt;

int mkfifo(const char *path, mode_t mode);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;XSI IPC&lt;/h3&gt;

&lt;p&gt;消息队列，信号量以及共享存储器称为 XSI IPC。&lt;/p&gt;

&lt;h4&gt;标识符和键&lt;/h4&gt;

&lt;p&gt;每个内核中的 IPC 结构都用一个非负整数的标识符加以引用。标识符是 IPC 对象的内部名，每个 IPC 对象都与一个键关联，将这个键作为该对象的外部名。&lt;/p&gt;

&lt;h4&gt;权限结构&lt;/h4&gt;

&lt;p&gt;每个 IPC 结构关联了一个 ipc_perm 结构，该结构规定了权限和所有者，其至少包括了以下成员：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct ipc_perm {
    uid_t   uid;   /* owner&amp;#39;s effective user id */
    gid_t   gid;   /* owner&amp;#39;s effective group id */
    uid_t   cuid;  /* creator&amp;#39;s effective user id */
    gid_t   cgid;  /* creator&amp;#39;s effective group id */
    mode_t  mode;  /* access modes */
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h4&gt;优缺点&lt;/h4&gt;

&lt;p&gt;XSI IPC 是在系统范围内起作用的，没有引用计数。例如，消息队列在引用进程终止后其内容不会被删除。与管道相比，当最后一个引用管道的进程终止时，管道就被完全的删除了。另一个问题是，XSI IPC 结构在文件系统中没有名字，无法使用文件系统的函数来访问或修改它们的属性，因此内核增加了十几个全新的系统调用（msgget、semop、shmat等）来支持这些 IPC 对象。&lt;/p&gt;

&lt;p&gt;消息队列的优点是：可靠、流控制的。&lt;/p&gt;

&lt;h4&gt;信号量、记录锁和互斥量的比较&lt;/h4&gt;

&lt;p&gt;如果在多个进程间共享一个资源，则可使用信号量、记录锁或互斥量来协调访问。&lt;/p&gt;

&lt;p&gt;若使用信号量，则先创建包含一个成员的信号量集合，分配资源调用 sem_op 为 -1 的 semop。释放资源调用 sem_op 为 +1 的 semop。对每个操作都指定 SEM_UNDO，以处理未释放资源条件下进程终止的情况。&lt;/p&gt;

&lt;p&gt;若使用记录锁，则先创建一个空文件，并使用该文件的第一个字节（无需存在）为锁字节。记录锁的性质确保当锁的持有者终止时，内核会自动释放锁。&lt;/p&gt;

&lt;p&gt;若使用互斥量，需要所有进程将相同文件映射到各自的地址空间，并使用 PTHREAD_PROCESS_SHARED 互斥量属性在文件的相同偏移处初始化互斥量。如果一个进程没有释放互斥量而终止，要恢复将是非常困难的。&lt;/p&gt;

&lt;p&gt;下图显示在 Linux 上，使用这三种不同技术进行锁操作所需要的时间。在每一种情况下，资源都被分配、释放 1 000 000 次：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;操作&lt;/th&gt;
&lt;th&gt;用户时间&lt;/th&gt;
&lt;th&gt;系统时间&lt;/th&gt;
&lt;th&gt;时钟&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;带undo的信号量&lt;/td&gt;
&lt;td&gt;0.50&lt;/td&gt;
&lt;td&gt;6.08&lt;/td&gt;
&lt;td&gt;7.55&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;建议性记录锁&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;td&gt;9.06&lt;/td&gt;
&lt;td&gt;4.38&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;共享存储中的互斥量&lt;/td&gt;
&lt;td&gt;0.21&lt;/td&gt;
&lt;td&gt;0.40&lt;/td&gt;
&lt;td&gt;0.25&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;如果我们仅需要对单一资源加锁，不需要 XSI 信号量的所有花哨功能，记录锁将比信号量更好，使用起来更简单、速度更快，当进程终止时系统会管理遗留下来的锁。除非特别考虑性能，否则不会使用共享存储中的互斥量。首先，在多个进程间共享内存中使用互斥量来恢复一个终止的进程更困难，其次，进程共享的互斥量属性还没得到普遍的支持。&lt;/p&gt;

&lt;h3&gt;POSIX 信号量&lt;/h3&gt;

&lt;p&gt;POSIX 信号量接口意在解决 XSI 信号量接口的几个缺陷：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更高性能的实现&lt;/li&gt;
&lt;li&gt;接口使用更简单，没有信号量集&lt;/li&gt;
&lt;li&gt;删除时表现更完美&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;尽可能避免使用消息队列和信号量，应当考虑全双工管道和记录锁，它们使用起来更简单。&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Linux 中的实现&lt;/h1&gt;

&lt;p&gt;内核提供了一系列实现同步的方法，包括原子操作、自旋锁、信号量、序列锁等。&lt;/p&gt;

&lt;h2&gt;自旋锁&lt;/h2&gt;

&lt;p&gt;自旋锁可以在中断上下文中使用，而信号量不能，因为信号量可能会休眠。在中断处理中使用了锁的话，需要禁止本地中断，否则可能会因为重复申请锁而导致死锁。&lt;/p&gt;

&lt;p&gt;内核提供了一个方便的方法以禁止中断并申请锁：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;spin_lock_irqsave(&amp;amp;mr_lock, flags);
/* critical region ... */ 
spin_unlock_irqrestore(&amp;amp;mr_lock, flags);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;spin_lock_irqsave 保存当前的中断状态，禁止本地中断并获取自旋锁。&lt;/p&gt;

&lt;p&gt;在单处理器系统，自旋锁的实现仅仅是禁止本地中断，并禁止抢占。&lt;/p&gt;

&lt;h2&gt;完成变量（Completion Variables）&lt;/h2&gt;

&lt;p&gt;Completion Variables 类似信号量，可以认为是信号量的简化版本。在内核中 Completion Variables 用于 vfork 系统调用：当子进程终止时通过 Completion Variables 通知父进程。&lt;/p&gt;

&lt;h2&gt;顺序锁（Sequential Locks）&lt;/h2&gt;

&lt;p&gt;顺序锁提供了一个简单的机制用以读写共享的数据，其基于一个顺序计数器。当数据被写入的时候，就会获得一把锁，并且序列值会增加。在读取数据之前和之后，读取序列值。如果序列值相同的话，那么在读数据的时候，并没有写操作发生。更进一步将，如果序列值是偶数的话，说明当前没有写操作正在进行（由于初始值为0，写操作获得和释放锁时均会让序列值加1）。&lt;/p&gt;

&lt;p&gt;顺序锁非常轻量级，适用于以下场景：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据拥有非常多的读取者。&lt;/li&gt;
&lt;li&gt;数据有很少的写入者。&lt;/li&gt;
&lt;li&gt;数据更倾向于写，并且不允许读造成写饥饿。&lt;/li&gt;
&lt;li&gt;数据非常的简单，但是因为某些原因，不能使用atomic变量。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;内核中存储 uptime 的变量 jiffies 的读写就使用了顺序锁。在某些不能原子读取 64 位 jiffies_64 变量的系统上，使用顺序锁来读取：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;u64 get_jiffies_64(void) {
    unsigned long seq; 
    u64 ret;

    do {
        seq = read_seqbegin(&amp;amp;xtime_lock);
        ret = jiffies_64;
    } while (read_seqretry(&amp;amp;xtime_lock, seq)); 
    return ret;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;更新 jiffies_64 的代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;write_seqlock(&amp;amp;xtime_lock); 
jiffies_64 += 1; 
write_sequnlock(&amp;amp;xtime_lock);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Sun, 27 Nov 2016 13:49:16 +0800</pubDate>
        <link>http://masutangu.com/2016/11/linux-kernel-serial-2/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/11/linux-kernel-serial-2/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
  </channel>
</rss>
