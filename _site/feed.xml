<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Masutangu</title>
    <description>也許我這一生　始終在追逐那顆九號球</description>
    <link>http://masutangu.com/</link>
    <atom:link href="http://masutangu.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 28 Dec 2016 22:20:35 +0800</pubDate>
    <lastBuildDate>Wed, 28 Dec 2016 22:20:35 +0800</lastBuildDate>
    <generator>Jekyll v3.1.1</generator>
    
      <item>
        <title>我的 2016</title>
        <description>&lt;p&gt;时间飞逝，又到了写年终总结的时候了。翻回看去年的总结和展望，回想起去年的雄心壮志，今年则是坎坷、困惑与焦虑的一年。&lt;/p&gt;

&lt;h1&gt;回顾过去&lt;/h1&gt;

&lt;p&gt;在这整整一年中，我所思考的和困扰的，可以由三个词来概括：&lt;strong&gt;成绩&lt;/strong&gt;、&lt;strong&gt;成长&lt;/strong&gt;和&lt;strong&gt;价值&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;工作已经两年半，对自己目前取得的成绩，对自己技术成长的预期，对自己为团队创造的价值，实话实说，都不满意。&lt;/p&gt;

&lt;p&gt;从今年年初开始，我就有点焦虑，觉得自己没有太多的成长，一直在原地踏步，已经没有刚入职时那种回顾过去会觉得自己突飞猛进的感觉（工作后做的每个比较大的需求，我都会整理保存下来 ppt，回看时就会清楚自己相比起过去进步了多少）。困于瓶颈期时，我尝试更加主动的去做事情。在那段时间，我开始关注些不仅仅是技术上的知识，例如关注了&lt;a href=&quot;https://wanqu.co/&quot;&gt;《湾区日报》&lt;/a&gt;，做了些读书笔记&lt;a href=&quot;http://masutangu.com/2015/12/dewdrop-note-1/&quot;&gt;《水滴石穿》&lt;/a&gt;。那段时间有些收获，但当我尝试把我阅读中收获的这些想法，运用到工作中时，却发现有层层阻碍。其中细节就不展开了，这让我非常沮丧。一方面，我理解在大公司工作，最重要是“稳”。有新的方案，新的想法，首要考虑的不是这个新的方案、新的想法的收益，而是运维成本。另一方面，这也让我觉得在大公司工作非常乏味，每个人的贡献都是固定的，尤其是工程师，你的定位就是执行者。公司也已经有很多很成熟的组件，即使不太适应于业务场景，也能勉强用用，你的工作就是做做接入，其它不需要操心。&lt;/p&gt;

&lt;p&gt;这种状况让我觉得非常的不适应。在学生时代，每一阶段、每个学期你都会学习到新的知识。而在工作中，更多的时候你是在重复做些体力活，例如，复制粘贴的完成一些需求。又例如，一遍遍的用已经成熟的方案去解决一些问题。而我其实不太喜欢这样的工作方式。我蛮希望自己是一个比较有创造力的工程师，我倾向于用不同的方案去完成类似的需求，通过真正的实践来对比不同的方案的优劣性。但在大公司来说，&lt;strong&gt;进度&lt;/strong&gt;和&lt;strong&gt;稳定性&lt;/strong&gt;是首要目标。只有在发展迅猛的前沿/明星项目中，你才有可能遇到各种新的问题，才有得到锻炼的机会。&lt;/p&gt;

&lt;p&gt;互联网不是按照工龄来排资论辈，同样工作三五年，差距可能非常大。有一句话说得好，&lt;strong&gt;“Good judgment comes from experience, experience comes from bad judgment.”&lt;/strong&gt;（正确的判断来自于丰富的经验,而丰富的经验来自错误的判断）。如果工作中没有太多挑战，不能促使你学习进步以应对工作的要求，一味追求保守无法得到犯错踩坑进步的机会，那你就应该停下来思考自己的未来了。我非常不希望把工作当做是一个任务，我希望工作是融于生活的，能带给我挑战和战胜难题的动力，能带给我解决问题后的成就感。如果说做为工程师，工作于己如同体力劳动般每日重复，那和流水线工人又有什么区别呢？&lt;/p&gt;

&lt;p&gt;再一个让我不适应的，是大公司的考核机制。并不像在学生时代，你的排名和你考出来的成绩相关，和你上课积不积极听讲，有没经常举手回答问题，一点关系都没有。所以你的成绩很差，抱歉，是你不够努力，你知道是自己的原因，所以你会努力去学习让自己进步。工作则不是如此简单纯粹。由于工作中有挑战的难点并不多，每个人做的事情都差不多，那只好看谁做事比较积极主动（并非吐槽，我也非常理解）。而我不太喜欢“伪加班”，也希望工作完成后能有更多自己的时间去学习充电。因此，工作后自己取得的绩效非常平庸。我意识到再这样下去，职业生涯也许就这样了。做为一个已经不算新人的员工来说，我渴望做出成绩，希望能为团队贡献更多的价值。我觉得自己还有很多的能量，我能做的不仅仅是完成我手上的工作。我也意识需要到达一定的职位，才能去推动些什么，去改变些什么。但以我这平庸的考核，我对自己未来的发展不抱有太多的信心，所以我开始寻求改变。&lt;/p&gt;

&lt;p&gt;既然不想再在大公司做了，我开始寻找一些有意思的创业公司。在 v2ex 上逛的时候，&lt;a href=&quot;https://www.xiaohongshu.com/&quot;&gt;小红书&lt;/a&gt; 吸引了我的注意。CTO 来自前谷歌中国工程院副院长，团队很多海归名校的背景，非常有吸引力。在经过电面，飞到上海去面试后，我拿到了offer。然而犹豫再三，我还是放弃了。放弃的原因主要是因为我资历尚浅，5月份拿到 offer，那时我才工作了一年多，当时小红书的开发团队已经有几十人，已经算是个大团队了。但不得不说，面试官给我的感觉非常的好，如果是在更早期，团队还是小规模的时候，我一定愿意加入这样的团队。&lt;/p&gt;

&lt;p&gt;之后就在公司内部寻找些机会，7月份到了现在的游戏工作室。小团队，后台只有几个人，听起来很有成就感。转岗之前我也有点小担心，担心难以融入，担心过来后也是打打杂，幸好过来后发现多虑了。工作室给我的感觉，很明显，大家共同的目标就是把游戏做好。当然从做社交，到做游戏，一开始还是有些不适应。做社交，本质上是各类存储的设计。游戏则不太一样，复杂的都是在业务逻辑。&lt;/p&gt;

&lt;p&gt;下半年的工作，新的环境，新的方向。学习了新的后台框架，对比之前用的框架，自己造了个轮子，写了篇文章&lt;a href=&quot;http://masutangu.com/2016/08/simple-async-framework/&quot;&gt;《简单异步应用框架的实现》&lt;/a&gt;，对后台异步框架的设计有一些了解，不再局限于只会用框架了。浅读了 libuv 和 libco 的源码，同样写了两篇文章&lt;a href=&quot;http://masutangu.com/2016/10/libuv-source-code/&quot;&gt;《Libuv 源码阅读》&lt;/a&gt; 和 &lt;a href=&quot;http://masutangu.com/2016/10/learn-libco/&quot;&gt;《浅读 Libco》&lt;/a&gt;，对异步和协程两种模式都有了进一步的认识。之后，在日常查问题的时候，我意识到自己定位问题的能力有所缺失，主要是对 linux 的各种监控系统状态的命令还不熟悉，操作系统和网络的知识也忘掉差不多了，所以决定重新翻读下 《UNIX 环境高级编程》、《现代操作系统》，并结合 《Linux 内核设计与实现》，了解些操作系统的理论和实现，这个系列的文章&lt;a href=&quot;http://masutangu.com/2016/11/linux-kernel-serial-1/&quot;&gt;《Linux 内核系列－进程》&lt;/a&gt; 还没写完。&lt;/p&gt;

&lt;p&gt;经过这阵子的摸索，我明确了之后的突破点，找到了进步的方向。虽然说，这一年，我有很多困惑、迷茫和焦虑，心情经常非常差，情绪起伏也很大。我明白这些都是成长的必经之路，这么看来，这些起起伏伏，也是蛮值得的。&lt;/p&gt;

&lt;h1&gt;展望未来&lt;/h1&gt;

&lt;p&gt;新的一年，工作上认真努力，不必多说。这里来聊聊新的一年，个人方面，我想做些什么。&lt;/p&gt;

&lt;p&gt;今年我意识到，对于大多数项目来说，技术并不是最重要的，只要不出问题就好（虽然我热爱技术，但我也不得不承认这点）。那技术人员应该如何发挥更大的价值呢？&lt;/p&gt;

&lt;p&gt;我给自己定的目标是：&lt;strong&gt;提高核心竞争力&lt;/strong&gt;和&lt;strong&gt;变得更全面&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;提升技术能力，这是首要目标。我希望新的一年可以把基础打扎实了，作为后台开发，操作系统和网络知识要打牢。另外了解业界流行的中间件（消息队列、数据库等）的实现，比较深入的选择一个方向（游戏引擎、数据分析、图形学、编程语言等）去研究。&lt;/p&gt;

&lt;p&gt;另外在公司工作，技能点很容易变得非常窄。我希望自己可以变得更加全面，不希望把自己局限于后台开发，也不仅局限于技术。新的一年，我希望自己能够做一个上线的 side project 并用心运营。目前看来我应该会选择做一款独立游戏，技术上独立完成前台－接入层－后台的实现，也借此学习下游戏策划的一些思想，让自己更加了解游戏这个行业。&lt;/p&gt;

&lt;h1&gt;总结心得&lt;/h1&gt;

&lt;p&gt;今天读了陈皓的&lt;a href=&quot;http://coolshell.cn/articles/17583.html&quot;&gt;《技术人员的发展之路》&lt;/a&gt;，写的很好，推荐大家都读一读。这一年，有两句话，我经常对自己说的，一是：&lt;strong&gt;不忘初心&lt;/strong&gt;，二是：&lt;strong&gt;Pursue excellence, and success will follow&lt;/strong&gt; (追求卓越，成功就会如期而至)。&lt;/p&gt;

&lt;p&gt;不忘初心，是提醒自己，选择了计算机的道路，是因为我喜欢编程，喜欢创造。不要因为眼前的失意去妥协自己。希望自己工作三年，五年，十年，都能保持学生的心态。&lt;strong&gt;stay hungry, stay foolish&lt;/strong&gt;。 &lt;/p&gt;

&lt;p&gt;追求卓越，是因为我相信，让自己成为一个优秀的工程师，比拿到好的绩效更加重要。自己要为自己的职业生涯负责，更勇敢的去追求梦想。&lt;/p&gt;

&lt;p&gt;大公司工作，可以带给你光环，但自己要想清楚，去掉光环后，自己还剩下些什么。也许我们都是平凡人，但平凡人也希望做出稍微那么不平凡的成绩。2017 年，希望自己不留遗憾！&lt;/p&gt;
</description>
        <pubDate>Wed, 28 Dec 2016 22:19:43 +0800</pubDate>
        <link>http://masutangu.com/2016/12/review/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/12/review/</guid>
        
        
        <category>随笔</category>
        
      </item>
    
      <item>
        <title>Linux 内核系列－进程通信和同步</title>
        <description>&lt;p&gt;本系列文章为阅读《现代操作系统》《UNIX 环境高级编程》和《Linux 内核设计与实现》所整理的读书笔记，源代码取自 Linux-kernel 2.6.34 版本并有做简化。&lt;/p&gt;

&lt;h1&gt;概念&lt;/h1&gt;

&lt;h2&gt;竞争条件&lt;/h2&gt;

&lt;p&gt;多个进程读写某些共享数据，而最后的结果取决于进程运行的精确时许，称为竞争条件。&lt;/p&gt;

&lt;h2&gt;忙等待的互斥&lt;/h2&gt;

&lt;p&gt;几种实现互斥的方案：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;屏蔽中断&lt;/p&gt;

&lt;p&gt;在单处理器系统中，最简单的方法是使每个进程在刚刚进入临界区后立即屏蔽所有中断，包括时钟中断。CPU 只有在发生中断的时候才会进行进程切换，这样在中断被屏蔽后 CPU 将不会被切换到其他进程。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;锁变量&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;严格轮换法&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;while (TRUE) {
    while (turn != 0) 
    critical_region(); 
    turn = 1;
    noncritical_region();
}

while (TRUE) {
    while (turn != 1) 
    critical_region(); 
    turn = 0;
    noncritical_region();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;忙等待检查变量。使用忙等待的锁称为自旋锁。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Peterson 解法&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#define FALSE 0 
#define TRUE  1
#define N     2                    /* number of processes */

int turn;                          /* whose turn is it? */
int interested[N];                 /* all values initially 0 (FALSE) */

void enter_region(int process);    /* process is 0 or 1 */
{
    int other;

    other = 1 - process;
    interested[process] = TRUE;
    turn = process;
    while (turn == process &amp;amp;&amp;amp; interested[other] == TRUE); 
}

void leave_region(int process)     /* process: who is leaving */ 
{
    interested[process] = FALSE;   /* indicate departure from critical region */ 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;TSL 指令&lt;/p&gt;

&lt;p&gt;TSL（测试并加锁）指令将一个内存字 lock 读到寄存器 RX 中，然后在该内存地址上存一个非零值。读字和写字操作保证是不可分割的，即在该指令结束前其他处理器均不允许访问该内存字。执行 TSL 指令的 CPU 将锁住内存总线，以防止其他 CPU 在本指令结束前访问内存。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;enter region:
    TSL REGISTER, LOCK      | copy lock to register and set lock to 1
    CMP REGISTER, #0        | was lock zero?
    JNE enter_region        | if it was not zero, lock was set, so loop
    RET                     | return to caller; critical region entered

leave region:
    MOVE LOCK, #0           | store a 0 in lock
    RET                     | return to caller  
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;一个可替代 TSL 的指令是 XCHG，它原子性的交换了两个位置的内容，例如寄存器和内存字。代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;enter region:
    MOVE REGISTER, #1       | put a 1 in the register
    XCHG REGISTER, LOCK     | swap the contents of the register and lock variable
    CMP REGISTER, #0        | was lock zero?
    JNE enter_region        | if it was non zero, lock was set, so loop
    RET                     | return to caller; critical region entered

leave region:
    MOVE LOCK, #0           | store a 0 in lock
    RET                     | return to caller
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;忙等待存在优先级反转的问题。假设存在 H 和 L 两个进程，L 优先级较低，调度规则规定只要 H 处于就绪状态就可以允许。在某一时刻，L 处于临界区中，此时 H 变到就绪态，然后开始忙等待。但由于 H 就绪时 L 不会被调度，也就无法离开临界区，所以 H 将永远忙等待下去。&lt;/p&gt;

&lt;h2&gt;信号量&lt;/h2&gt;

&lt;p&gt;信号量使用整型变量来累计唤醒次数。信号量的取值可以为 0 或者为正值。信号量有 up 和 down 这两种操作。&lt;/p&gt;

&lt;p&gt;使用信号量解决生产者－消费者问题：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#define N 100                   /* number of slots in the buffer */
typedef int semaphore;          /* semaphores are a special kind of int */
semaphore mutex = 1;            /* controls access to critical region */
semaphore empty = N;            /* counts empty buffer slots */
semaphore full = 0;             /* counts full buffer slots */

void producer(void) {
  int item;
  while (TRUE) {                /* TRUE is the constant 1 */
    item = produce_item();      /* generate something to put in buffer */
    down(&amp;amp;empty);               /* decrement empty count */
    down(&amp;amp;mutex);               /* enter critical region */
    insert_item(item);          /* put new item in buffer */
    up(&amp;amp;mutex);                 /* leavecriticalregion */
    up(&amp;amp;full);                  /* increment count of full slots */
  } 
}

void consumer(void) {
  int item;
  while (TRUE) {                /* infinite loop */
    down(&amp;amp;full);                /* decrement full count */
    down(&amp;amp;mutex);               /* enter critical region */
    item = remove_item();       /* take item from buffer */
    up(&amp;amp;mutex);                 /* leavecriticalregion */
    up(&amp;amp;empty);                 /* increment count of empty slots */
    consume item(item);         /* do something with the item */
  } 
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;中断可以用信号量来实现，最自然的方法是为每个 I/O 设备设置一个信号量，初始值为 0。在启动 I/O 设备后，管理进程就立即对相关信号量执行一个 down 操作，于是进程被阻塞。当中断到来时，中断处理程序随后对相关信号量执行一个 up 操作，从而使进程变成就绪态。&lt;/p&gt;

&lt;p&gt;信号量可以用以实现互斥，也可以用于事件同步。&lt;/p&gt;

&lt;h2&gt;互斥量&lt;/h2&gt;

&lt;p&gt;互斥量是信号量的简化版本，称为互斥量。常用于用户线程包。互斥量只有两个状态：解锁和加锁。&lt;/p&gt;

&lt;p&gt;TSL 或 XCHG 指令可以方便的在用户空间中实现互斥量：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;mutex_lock:
    TSL REGISTER, MUTEX                 | copy mutex to register and set mutex to 1
    CMP REGISTER, #0                    | was mutex zero?
    JZE ok                              | if it was zero, mutex was unlocked, so return
    CALL thread_yield                   | mutex is busy; schedule another thread
    JMP mutex_lock                      | try again 
ok: RET                                 | return to caller; critical region entered


mutex_unlock:
    MOVE MUTEX, #0                      | store a 0 in mutex
    RET                                 | return to caller
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;mutex_lock 和 enter_region 很类似，但有个关键的区别。当 enter_region 进入临界区失败时，进程始终在重复测试锁（忙等待），直到时钟超时，重新调度其他进程运行。&lt;/p&gt;

&lt;p&gt;在用户线程中，由于没有时钟来停止运行过长的线程，因此需要调用 thread_yield 来让出 CPU。&lt;/p&gt;

&lt;p&gt;Pthread 提供多种同步机制，包括互斥量和条件变量。&lt;strong&gt;条件变量总是结合互斥量一起使用。&lt;/strong&gt;另外条件变量不会存在内存中，需要避免丢失信号。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;pthread.h&amp;gt;
#define MAX 1000000000                                  /* how many numbers to produce */
pthread_mutex_t the mutex; 
pthread_cond_t condc, condp;                            /* used for signaling */
int buffer = 0;                                         /* buffer used between producer and consumer */

void *producer(void *ptr) {                             /* produce data */
    int i;

    for (i= 1; i &amp;lt;= MAX; i++) {
        pthread_mutex_lock(&amp;amp;the_mutex);                 /* get exclusive access to buffer */            
        while (buffer != 0) 
            pthread_cond_wait(&amp;amp;condp, &amp;amp;the_mutex);
        buffer = i;                                     /* put item in buffer */    
        pthread_cond_signal(&amp;amp;condc);                    /* wakeupconsumer */
        pthread_mutex_unlock(&amp;amp;the_mutex);               /* release access to buffer */
    }
    pthread exit(0); 
}


void *consumer(void *ptr) {                             /* consume data */
    int i;
    for (i = 1; i &amp;lt;= MAX; i++) {
        pthread_mutex_lock(&amp;amp;the_mutex);                 /* get exclusive access to buffer */ 
        while (buffer ==0 ) 
            pthread_cond_wait(&amp;amp;condc, &amp;amp;the_mutex);      /* wakeupproducer */
        buffer = 0;
        pthread_cond_signal(&amp;amp;condp);  
        pthread_mutex_unlock(&amp;amp;the_mutex);               /* release access to buffer */
    }
    pthread exit(0); 
}

int main(int argc, char **argv) {
    pthread_t pro, con;
    pthread_mutex_init(&amp;amp;the_mutex, 0); 
    pthread_cond_init(&amp;amp;condc, 0); 
    pthread_cond_init(&amp;amp;condp, 0); 
    pthread_create(&amp;amp;con, 0, consumer, 0); 
    pthread_create(&amp;amp;pro, 0, producer, 0); 
    pthread_join(pro, 0);
    pthread_join(con, 0);
    pthread_cond_destroy(&amp;amp;condc); 
    pthread_cond_destroy(&amp;amp;condp); 
    pthread_mutex_destroy(&amp;amp;the_mutex);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h1&gt;系统调用及库函数&lt;/h1&gt;

&lt;h2&gt;线程同步&lt;/h2&gt;

&lt;h3&gt;互斥量&lt;/h3&gt;

&lt;p&gt;可以使用 pthread 的互斥接口来保护数据。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;pthread.h&amp;gt;

int pthread_mutex_lock(pthread_mutex_t *mutex);

int pthread_mutex_trylock(pthread_mutex_t *mutex);

int pthread_mutex_unlock(pthread_mutex_t *mutex);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;读写锁&lt;/h3&gt;

&lt;p&gt;读写锁可以有三个状态：读模式下加锁状态，写模式下加锁状态，不加锁状态。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;pthread.h&amp;gt;

int pthread_rwlock_rdlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_wrlock(pthread_rwlock_t *rwlock);

int pthread_rwlock_unlock(pthread_rwlock_t *rwlock);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;条件变量&lt;/h3&gt;

&lt;p&gt;条件变量与互斥量一起使用时，允许线程以无竞争的方式等待特定的条件发生。&lt;strong&gt;条件本身是由互斥量保护的，线程在改变条件状态前必须先锁住互斥量&lt;/strong&gt;。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;
#include &amp;lt;pthread.h&amp;gt;

int pthread_cond_wait(pthread_cond_t *restrict cond,
                     pthread_mutex_t *restrict mutex);

int pthread_cond_signal(pthread_cond_t *cond);

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;传递给 pthread_cond_wait 的互斥量对条件进行保护。调用者把锁住的互斥量传给函数，函数自动把调用线程放到等待条件的线程列表上，再对互斥量解锁。这就&lt;strong&gt;关闭了条件检查和线程进入休眠状态等待条件改变这两个操作之间的时间通道，因此线程不会错过条件的任何变化&lt;/strong&gt;。pthread_cond_wait 返回时，互斥量再次被锁住。&lt;/p&gt;

&lt;h3&gt;自旋锁&lt;/h3&gt;

&lt;p&gt;自旋锁与互斥量类似，但其不是通过休眠使进程阻塞，而是获得锁之前一直处于忙等待。自锁锁可以用于以下情况：锁被持有时间短，而且线程不希望在重新调度上花费太多成本。&lt;/p&gt;

&lt;p&gt;自旋锁通常用于底层原语用于实现其它类型的锁。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;pthread.h&amp;gt;

int pthread_spin_lock(pthread_spinlock_t *lock);

int pthread_spin_trylock(pthread_spinlock_t *lock);

int pthread_spin_unlock(pthread_spinlock_t *lock);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;屏障&lt;/h3&gt;

&lt;p&gt;屏障是用户协调多个线程并行工作的同步机制。屏障允许每个线程等待，直到所有的合作线程都到达某一个点，然后从该点继续执行。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;pthread.h&amp;gt;

int pthread_barrier_init(pthread_barrier_t *restrict barrier,
                        const pthread_barrierattr_t *restrict attr,
                        unsigned int count);

int pthread_barrier_wait(pthread_barrier_t *barrier);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;进程同步与通信&lt;/h2&gt;

&lt;h3&gt;管道&lt;/h3&gt;

&lt;p&gt;管道是 UNIX 系统 IPC 的最古老方式。管道是半双工的，只能在具有公共祖先的两个进程之间使用。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;unistd.h&amp;gt;

int pipe(int fd[2]);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;常量 PIPE_BUF 规定了内核的管道缓冲区大小，如果写管道的字节数小于等于 PIPE_BUF，则此操作不会与其它进程对同一管道的写操作交叉进行。&lt;/p&gt;

&lt;h3&gt;FIFO&lt;/h3&gt;

&lt;p&gt;通过 FIFO 不相关的进程也能交换数据。创建 FIFO 类似创建文件：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;sys/stat.h&amp;gt;

int mkfifo(const char *path, mode_t mode);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;XSI IPC&lt;/h3&gt;

&lt;p&gt;消息队列，信号量以及共享存储器称为 XSI IPC。&lt;/p&gt;

&lt;h4&gt;标识符和键&lt;/h4&gt;

&lt;p&gt;每个内核中的 IPC 结构都用一个非负整数的标识符加以引用。标识符是 IPC 对象的内部名，每个 IPC 对象都与一个键关联，将这个键作为该对象的外部名。&lt;/p&gt;

&lt;h4&gt;权限结构&lt;/h4&gt;

&lt;p&gt;每个 IPC 结构关联了一个 ipc_perm 结构，该结构规定了权限和所有者，其至少包括了以下成员：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct ipc_perm {
    uid_t   uid;   /* owner&amp;#39;s effective user id */
    gid_t   gid;   /* owner&amp;#39;s effective group id */
    uid_t   cuid;  /* creator&amp;#39;s effective user id */
    gid_t   cgid;  /* creator&amp;#39;s effective group id */
    mode_t  mode;  /* access modes */
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h4&gt;优缺点&lt;/h4&gt;

&lt;p&gt;XSI IPC 是在系统范围内起作用的，没有引用计数。例如，消息队列在引用进程终止后其内容不会被删除。与管道相比，当最后一个引用管道的进程终止时，管道就被完全的删除了。另一个问题是，XSI IPC 结构在文件系统中没有名字，无法使用文件系统的函数来访问或修改它们的属性，因此内核增加了十几个全新的系统调用（msgget、semop、shmat等）来支持这些 IPC 对象。&lt;/p&gt;

&lt;p&gt;消息队列的优点是：可靠、流控制的。&lt;/p&gt;

&lt;h4&gt;信号量、记录锁和互斥量的比较&lt;/h4&gt;

&lt;p&gt;如果在多个进程间共享一个资源，则可使用信号量、记录锁或互斥量来协调访问。&lt;/p&gt;

&lt;p&gt;若使用信号量，则先创建包含一个成员的信号量集合，分配资源调用 sem_op 为 -1 的 semop。释放资源调用 sem_op 为 +1 的 semop。对每个操作都指定 SEM_UNDO，以处理未释放资源条件下进程终止的情况。&lt;/p&gt;

&lt;p&gt;若使用记录锁，则先创建一个空文件，并使用该文件的第一个字节（无需存在）为锁字节。记录锁的性质确保当锁的持有者终止时，内核会自动释放锁。&lt;/p&gt;

&lt;p&gt;若使用互斥量，需要所有进程将相同文件映射到各自的地址空间，并使用 PTHREAD_PROCESS_SHARED 互斥量属性在文件的相同偏移处初始化互斥量。如果一个进程没有释放互斥量而终止，要恢复将是非常困难的。&lt;/p&gt;

&lt;p&gt;下图显示在 Linux 上，使用这三种不同技术进行锁操作所需要的时间。在每一种情况下，资源都被分配、释放 1 000 000 次：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;操作&lt;/th&gt;
&lt;th&gt;用户时间&lt;/th&gt;
&lt;th&gt;系统时间&lt;/th&gt;
&lt;th&gt;时钟&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;带undo的信号量&lt;/td&gt;
&lt;td&gt;0.50&lt;/td&gt;
&lt;td&gt;6.08&lt;/td&gt;
&lt;td&gt;7.55&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;建议性记录锁&lt;/td&gt;
&lt;td&gt;0.51&lt;/td&gt;
&lt;td&gt;9.06&lt;/td&gt;
&lt;td&gt;4.38&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;共享存储中的互斥量&lt;/td&gt;
&lt;td&gt;0.21&lt;/td&gt;
&lt;td&gt;0.40&lt;/td&gt;
&lt;td&gt;0.25&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;如果我们仅需要对单一资源加锁，不需要 XSI 信号量的所有花哨功能，记录锁将比信号量更好，使用起来更简单、速度更快，当进程终止时系统会管理遗留下来的锁。除非特别考虑性能，否则不会使用共享存储中的互斥量。首先，在多个进程间共享内存中使用互斥量来恢复一个终止的进程更困难，其次，进程共享的互斥量属性还没得到普遍的支持。&lt;/p&gt;

&lt;h3&gt;POSIX 信号量&lt;/h3&gt;

&lt;p&gt;POSIX 信号量接口意在解决 XSI 信号量接口的几个缺陷：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;更高性能的实现&lt;/li&gt;
&lt;li&gt;接口使用更简单，没有信号量集&lt;/li&gt;
&lt;li&gt;删除时表现更完美&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;尽可能避免使用消息队列和信号量，应当考虑全双工管道和记录锁，它们使用起来更简单。&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Linux 中的实现&lt;/h1&gt;

&lt;p&gt;内核提供了一系列实现同步的方法，包括原子操作、自旋锁、信号量、序列锁等。&lt;/p&gt;

&lt;h2&gt;自旋锁&lt;/h2&gt;

&lt;p&gt;自旋锁可以在中断上下文中使用，而信号量不能，因为信号量可能会休眠。在中断处理中使用了锁的话，需要禁止本地中断，否则可能会因为重复申请锁而导致死锁。&lt;/p&gt;

&lt;p&gt;内核提供了一个方便的方法以禁止中断并申请锁：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;spin_lock_irqsave(&amp;amp;mr_lock, flags);
/* critical region ... */ 
spin_unlock_irqrestore(&amp;amp;mr_lock, flags);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;spin_lock_irqsave 保存当前的中断状态，禁止本地中断并获取自旋锁。&lt;/p&gt;

&lt;p&gt;在单处理器系统，自旋锁的实现仅仅是禁止本地中断，并禁止抢占。&lt;/p&gt;

&lt;h2&gt;完成变量（Completion Variables）&lt;/h2&gt;

&lt;p&gt;Completion Variables 类似信号量，可以认为是信号量的简化版本。在内核中 Completion Variables 用于 vfork 系统调用：当子进程终止时通过 Completion Variables 通知父进程。&lt;/p&gt;

&lt;h2&gt;顺序锁（Sequential Locks）&lt;/h2&gt;

&lt;p&gt;顺序锁提供了一个简单的机制用以读写共享的数据，其基于一个顺序计数器。当数据被写入的时候，就会获得一把锁，并且序列值会增加。在读取数据之前和之后，读取序列值。如果序列值相同的话，那么在读数据的时候，并没有写操作发生。更进一步将，如果序列值是偶数的话，说明当前没有写操作正在进行（由于初始值为0，写操作获得和释放锁时均会让序列值加1）。&lt;/p&gt;

&lt;p&gt;顺序锁非常轻量级，适用于以下场景：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;数据拥有非常多的读取者。&lt;/li&gt;
&lt;li&gt;数据有很少的写入者。&lt;/li&gt;
&lt;li&gt;数据更倾向于写，并且不允许读造成写饥饿。&lt;/li&gt;
&lt;li&gt;数据非常的简单，但是因为某些原因，不能使用atomic变量。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;内核中存储 uptime 的变量 jiffies 的读写就使用了顺序锁。在某些不能原子读取 64 位 jiffies_64 变量的系统上，使用顺序锁来读取：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;u64 get_jiffies_64(void) {
    unsigned long seq; 
    u64 ret;

    do {
        seq = read_seqbegin(&amp;amp;xtime_lock);
        ret = jiffies_64;
    } while (read_seqretry(&amp;amp;xtime_lock, seq)); 
    return ret;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;更新 jiffies_64 的代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;write_seqlock(&amp;amp;xtime_lock); 
jiffies_64 += 1; 
write_sequnlock(&amp;amp;xtime_lock);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Sun, 27 Nov 2016 13:49:16 +0800</pubDate>
        <link>http://masutangu.com/2016/11/linux-kernel-serial-2/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/11/linux-kernel-serial-2/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>Linux 内核系列－进程</title>
        <description>&lt;p&gt;本系列文章为阅读《现代操作系统》《UNIX 环境高级编程》和《Linux 内核设计与实现》所整理的读书笔记，源代码取自 Linux-kernel 2.6.34 版本并有做简化。&lt;/p&gt;

&lt;h1&gt;概念&lt;/h1&gt;

&lt;p&gt;进程即处于运行中的程序，除了程序的代码外，还包括打开的文件、挂起的信号、进程状态、内存地址空间以及用以存储全局变量的数据段等。&lt;/p&gt;

&lt;p&gt;执行线程，简称线程，是在进程中活动的对象。每个线程都拥有独立的程序计数器、进程栈和一组进程寄存器。内核的调度对象是线程，而不是进程。&lt;/p&gt;

&lt;p&gt;在现代操作系统中，进程提供两种虚拟机制：虚拟处理器和虚拟内存。虚拟处理器提供给进程独享处理器的假象，虚拟内存则提供进程独占内存资源的假象。线程之间可以共享虚拟内存，但拥有各自的虚拟处理器。&lt;/p&gt;

&lt;h2&gt;创建&lt;/h2&gt;

&lt;p&gt;在 UNIX 系统中，只有系统调用 fork 可以创建新进程。&lt;/p&gt;

&lt;p&gt;使用 fork 创建新进程，子进程从父进程继承了如下属性：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;实际用户 ID、实际组 ID、有效用户 ID、有效组 ID&lt;/li&gt;
&lt;li&gt;附属组 ID&lt;/li&gt;
&lt;li&gt;进程组 ID&lt;/li&gt;
&lt;li&gt;会话 ID&lt;/li&gt;
&lt;li&gt;控制终端&lt;/li&gt;
&lt;li&gt;设置用户 ID 标志和设置组 ID 标志&lt;/li&gt;
&lt;li&gt;打开的文件描述符（相当于调用了 dup 函数）&lt;/li&gt;
&lt;li&gt;当前工作目录&lt;/li&gt;
&lt;li&gt;根目录&lt;/li&gt;
&lt;li&gt;文件模式创建屏蔽字&lt;/li&gt;
&lt;li&gt;信号屏蔽和处理函数&lt;/li&gt;
&lt;li&gt;close-on-exec 标志&lt;/li&gt;
&lt;li&gt;环境&lt;/li&gt;
&lt;li&gt;共享存储段&lt;/li&gt;
&lt;li&gt;存储映射&lt;/li&gt;
&lt;li&gt;资源限制&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;父子进程区别如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;fork 返回值&lt;/li&gt;
&lt;li&gt;进程 ID 和父进程 ID&lt;/li&gt;
&lt;li&gt;子进程的 tms_utime、tms_stime、tms_cutime、tms_ustime 的值设置为 0&lt;/li&gt;
&lt;li&gt;子进程不继承父进程设置的文件锁&lt;/li&gt;
&lt;li&gt;子进程未处理的 alarm 被清除&lt;/li&gt;
&lt;li&gt;子进程未处理的信号集被置空&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;终止&lt;/h2&gt;

&lt;p&gt;进程终止通常由以下条件引起：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;正常退出&lt;/li&gt;
&lt;li&gt;出错退出&lt;/li&gt;
&lt;li&gt;严重错误&lt;/li&gt;
&lt;li&gt;被其他进程杀死&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当进程终止时，内核会向其父进程发送 SIGCHLD 信号。&lt;/p&gt;

&lt;h2&gt;层次结构&lt;/h2&gt;

&lt;p&gt;在 UNIX 中，进程和其子进程共同组成一个进程组。整个系统中，所有进程都属于以 init 为根的一棵树。&lt;/p&gt;

&lt;p&gt;进程组是一个或多个进程的集合，通常是在同一个作业中结合起来的。同一个进程组中的各进程接收来自同一终端的各种信号。每个进程组有一个唯一的进程组 ID。每个进程组有一个组长进程，组长进程的进程组 ID 等于其进程 ID。只要进程组中还有进程存在，该进程组就存在。一个进程只能为自己或其子进程设置进程组 ID，在子进程调用了 exec 后，它就无法再更改子进程的进程组 ID。&lt;/p&gt;

&lt;p&gt;会话是一个或多个进程组的集合。一个会话可以有一个控制终端，建立与控制终端连接的会话首进程（session leader）被称为控制进程（controlling process）。会话可以有一个前台进程组和多个后台进程组。终端产生的信号都将发送给前台进程组，调制解调器断开连接时，挂断信号将发给控制进程。&lt;/p&gt;

&lt;p&gt;孤儿进程组定义为：该组中每个成员的父进程要么是该组的一个成员，要么不是该组所属会话的成员。换句话说，如果该组有一个进程的父进程属于同一会话的另一个组，则该组不是孤儿进程组。POSIX.1 要求向孤儿进程组中处于停止状态的进程发送 SIGHUP 信号，系统对于这种信号的默认处理是终止进程。&lt;/p&gt;

&lt;p&gt;为什么需要孤儿进程组的概念：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;When a controlling process terminates, its terminal becomes free and a new session can be established on it. (In fact, another user could log in on the terminal.) This could cause a problem if any processes from the old session are still trying to use that terminal.&lt;/p&gt;

&lt;p&gt;To prevent problems, process groups that continue running even after the session leader has terminated are marked as orphaned process groups. When a process group becomes an orphan, its processes are sent a SIGHUP signal. Ordinarily, this causes the processes to terminate. However, if a program ignores this signal or establishes a handler for it, it can continue running as in the orphan process group even after its controlling process terminates; but it still cannot access the terminal any more.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;状态&lt;/h2&gt;

&lt;p&gt;进程有以下三种状态：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;运行态：占用 CPU&lt;/li&gt;
&lt;li&gt;就绪态：可以执行，等待其他进程执行完&lt;/li&gt;
&lt;li&gt;阻塞态：需要外部事件触发&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;进程表&lt;/h2&gt;

&lt;p&gt;操作系统维护一张进程表，每个进程占用一个表项。该表项包含了进程状态的重要信息。包括程序计数器、堆栈指针、内存分配状况、所打开的文件指针、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时必须保存的信息，以保证进程随后能再次启动。&lt;/p&gt;

&lt;p&gt;下图为一个典型系统中进程表项的关键字段：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;进程管理&lt;/th&gt;
&lt;th&gt;存储管理&lt;/th&gt;
&lt;th&gt;文件管理&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;寄存器&lt;/td&gt;
&lt;td&gt;正文段指针&lt;/td&gt;
&lt;td&gt;根目录&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;程序计数器&lt;/td&gt;
&lt;td&gt;数据段指针&lt;/td&gt;
&lt;td&gt;工作目录&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;程序状态字&lt;/td&gt;
&lt;td&gt;堆栈段指针&lt;/td&gt;
&lt;td&gt;文件描述符&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;进程状态&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;优先级&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;调度参数&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;进程id&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;父进程&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;进程组&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;信号&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;进程开始的时间&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;使用cpu的时间&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;子进程的cpu时间&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;下次alarm的时间&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;h2&gt;中断&lt;/h2&gt;

&lt;p&gt;中断的处理和调度过程如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;硬件将程序计数器等压入堆栈&lt;/li&gt;
&lt;li&gt;硬件从中断向量中加载新的程序计数器&lt;/li&gt;
&lt;li&gt;汇编语言写的 procedure 保存堆栈中的寄存器等信息，并移除该信息&lt;/li&gt;
&lt;li&gt;汇编语言写的 procedure 设置新的堆栈&lt;/li&gt;
&lt;li&gt;c 中断服务例程开始执行&lt;/li&gt;
&lt;li&gt;处理完后，调度程序决定下一个执行的进程&lt;/li&gt;
&lt;li&gt;返回至汇编代码，恢复即将执行的进程的寄存器等信息，并启动该进程&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;线程&lt;/h2&gt;

&lt;p&gt;线程提供共享同一地址空间和数据的能力，并且比进程更加轻量级。&lt;/p&gt;

&lt;p&gt;如果多个线程都是 CPU 密集型的，那么并不能得到性能上的增强。但如果存在大量的计算和 IO 处理，那么多线程运行这些活动彼此重叠进行，从而加快应用程序的执行速度。&lt;/p&gt;

&lt;p&gt;进程模型基于两种独立的概念：&lt;strong&gt;资源分组处理&lt;/strong&gt;和&lt;strong&gt;执行&lt;/strong&gt;。而线程的引入即是对这两种概念的区分。理解进程的一个角度是，用某种方法把相关资源集中在一起，将资源放在进程中可以更容易的管理。另一个概念是，进程有一个执行线程，通常简写为线程。线程拥有程序计数器用以记录执行的下一条指令，寄存器用以保存当前的工作变量，堆栈用以记录执行历史，其中每一帧保存了一个已调用但还没返回的函数。&lt;strong&gt;进程用于把资源集中到一起，而线程则是在 CPU 上被调度执行的实体。&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;线程有两种主要的实现方法：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linux-kernel-serial-1/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;用户空间：&lt;/p&gt;

&lt;p&gt;把整个线程包放在用户空间中，内核对线程一无所知。从内核的角度即单线程进程。这类实现有同样的通用结构，线程在一个运行时系统之上运行，运行时系统是管理线程的函数集合（pthread_create, pthread_exit, pthread_join 和 pthread_yield 等），如上图左图。&lt;/p&gt;

&lt;p&gt;在用户空间管理线程时，每个进程需要有专用的线程表，用以跟踪该进程中的线程。线程表记录了线程的属性，如程序计数器、堆栈、寄存器和状态等。该线程表由运行时系统管理。&lt;/p&gt;

&lt;p&gt;用户级线程的优点在于保存线程状态和调度都是本地过程，比内核调用更有效率，另外不需要陷阱，不需要上下文切换，也不需要对内存高速缓存进行刷新。&lt;/p&gt;

&lt;p&gt;用户级线程还允许每个进程定制自己的调度算法。&lt;/p&gt;

&lt;p&gt;用户级线程的问题在于难以实现阻塞系统调用，page faults 引发阻塞，以及没有时钟中断，需要依赖线程自动放弃 CPU。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;内核空间：&lt;/p&gt;

&lt;p&gt;内核实现线程的管理，此时便不再需要运行时系统了，如上图右图。在内核中有专门的线程表记录所有线程。与用户级线程类似，内核的线程表保存线程的信息。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;系统调用及库函数&lt;/h1&gt;

&lt;h2&gt;进程终止&lt;/h2&gt;

&lt;p&gt;正常终止包括以下方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;从 main 函数返回&lt;/li&gt;
&lt;li&gt;调用 exit&lt;/li&gt;
&lt;li&gt;调用 _exit 或 _Exit&lt;/li&gt;
&lt;li&gt;最后一个线程从其启动例程中返回&lt;/li&gt;
&lt;li&gt;从最后一个线程调用 pthread_exit&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;异常退出有以下方式：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用 abort&lt;/li&gt;
&lt;li&gt;接收到一个信号&lt;/li&gt;
&lt;li&gt;最后一个线程对取消请求做出回应&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;退出函数&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#include &amp;lt;stdlib.h&amp;gt;
void exit(int status);
void _Exit(int status);

#include &amp;lt;unistd.h&amp;gt;
void _exit(int status);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;_exit 和 _Exit 立即进入内核，而 exit 会先执行些清理工作（exit 函数总执行一个标准 I/O 库的清理关闭操作：对所有打开流调用 fclose 函数，造成输出缓冲区中数据被冲洗）。&lt;/p&gt;

&lt;p&gt;三个退出函数都带有一个整型参数，称为终止状态。&lt;/p&gt;

&lt;h1&gt;Linux 中的实现&lt;/h1&gt;

&lt;h2&gt;进程描述符及任务结构&lt;/h2&gt;

&lt;p&gt;内核把进程的列表存放在名为任务队列（task list）的双向循环链表中。链表中的每一项类型都为 task_struct ，称为进程描述符（process descriptor）。task_struct 在 32 位机器上大概占用 1.7 KB。&lt;/p&gt;

&lt;p&gt;进程描述符包含了进程的所有信息，包括打开的文件，进程地址空间，挂起的信号，进程的状态等等。&lt;/p&gt;

&lt;p&gt;task_struct 结构体如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct task_struct {
    volatile long state;    /* -1 unrunnable, 0 runnable, &amp;gt;0 stopped */
    void *stack;
    atomic_t usage;
    unsigned int flags; /* per process flags, defined below */

    int prio, static_prio, normal_prio;
    unsigned int rt_priority;
    const struct sched_class *sched_class;
    struct sched_entity se;
    struct sched_rt_entity rt;

    unsigned int policy;
    int nr_cpus_allowed;
    cpumask_t cpus_allowed;

    struct list_head tasks;  // 进程链表
    struct mm_struct *mm, *active_mm;

    /* task state */
    int exit_state;
    int exit_code, exit_signal;
    int pdeath_signal;  /*  The signal sent when the parent dies  */

    pid_t pid;
    pid_t tgid;

    /* 
     * pointers to (original) parent process, youngest child, younger sibling,
     * older sibling, respectively.  (p-&amp;gt;father can be replaced with 
     * p-&amp;gt;real_parent-&amp;gt;pid)
     */
    struct task_struct *real_parent; /* real parent process */
    struct task_struct *parent; /* recipient of SIGCHLD, wait4() reports */
    /*
     * children/sibling forms the list of my natural children
     */
    struct list_head children;  /* list of my children */
    struct list_head sibling;   /* linkage in my parent&amp;#39;s children list */
    struct task_struct *group_leader;   /* threadgroup leader */

    /* PID/PID hash table linkage. */
    struct pid_link pids[PIDTYPE_MAX];

    /* file system info */
    struct nameidata *nameidata;
    /* filesystem information */
    struct fs_struct *fs;
    /* open file information */
    struct files_struct *files;

    /* signal handlers */
    struct signal_struct *signal;
    struct sighand_struct *sighand;

    sigset_t saved_sigmask; /* restored if set_restore_sigmask() was used */
    struct sigpending pending;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;在内核 2.6 之前，task_struct 结构被存储于每个进程的内核栈的底部。2.6 之后，thread_info 结构体存储于内核栈的底部，而 task_struct 为该结构体的成员:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct thread_info {
    struct task_struct      *task;          /* main task structure */
    struct exec_domain      *exec_domain;   /* execution domain */
    __u32                   flags;          /* low level flags */
    __u32                   status;         /* thread synchronous flags */
    __u32                   cpu;            /* current CPU */
    int                     preempt_count;  /* 0 =&amp;gt; preemptable,  &amp;lt;0 =&amp;gt; BUG */
    mm_segment_t            addr_limit;
    struct restart_block    restart_block;
    void __user             *sysenter_return;
#ifdef CONFIG_X86_32
    unsigned long           previous_esp;   /* ESP of the previous stack in case of nested (IRQ) stacks */
    __u8                    supervisor_stack[0];
#endif
    int                     uaccess_err;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;PID 是进程的唯一标志，其类型为 pid_t。内核将进程的 PID 存放在各自的 task_struct 结构体中。&lt;/p&gt;

&lt;p&gt;注：PID 在内核态和用户态是不同的概念。Linux 中的线程都有各自的 PID，而 getpid() 返回的其实不是 PID，而是 TGID。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://stackoverflow.com/questions/9154671/distinction-between-processes-and-threads-in-linux&quot;&gt;stackoverflow&lt;/a&gt; 上的解释：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The first and most important thing to realize is that &amp;quot;PID&amp;quot; means different things in kernel space and user space. What the kernel calls PIDs are actually kernel-level thread ids (often called TIDs), not to be confused with pthread_t which is a separate identifier. Each thread on the system, whether in the same process or a different one, has a unique TID (or &amp;quot;PID&amp;quot; in the kernel&amp;#39;s terminology). What&amp;#39;s considered a PID in the POSIX sense of &amp;quot;process&amp;quot;, on the other hand, is called a &amp;quot;thread group ID&amp;quot; or &amp;quot;TGID&amp;quot; in the kernel. Each process consists of one or more threads (kernel processes) each with their own TID (kernel PID), but all sharing the same TGID, which is equal to the TID (kernel PID) of the initial thread in which main runs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;current 宏用于快速定位当前执行的进程的进程描述符，current_thread_info() 的 C 语言实现如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;static inline struct thread_info *current_thread_info(void) __attribute_const__;

static inline struct thread_info *current_thread_info(void)
{
    return (struct thread_info *)
        (current_stack_pointer &amp;amp; ~(THREAD_SIZE - 1));   // 按照 THREAD\_SIZE 对齐
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;调用 current_thread_info()-&amp;gt;task 返回 task_struct。&lt;/p&gt;

&lt;p&gt;进程的当前状态由 task_struct 的 state 字段来表示，分别有以下几种情况：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/linux-kernel-serial-1/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;TASK_RUNNING：进程正在执行或处于可运行的就绪状态。&lt;/li&gt;
&lt;li&gt;TASK_INTERRUPTIBLE：进程正在休眠，等待某个条件发生。当收到信号时进程也会被唤醒。&lt;/li&gt;
&lt;li&gt;TASK_UNINTERRUPTIBLE：和 TASK_INTERRUPTIBLE 类似，但收到信号时进程不会被唤醒。&lt;/li&gt;
&lt;li&gt;__TASK_STOPPED：进程终止，通常发生于进程收到 SIGSTOP, SIGTSTP, SIGTTIN 或 SIGTTOU 信号。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;当进程执行了系统调用或触发了异常，它就陷入了内核空间，此时内核“代表进程执行”并处于进程的上下文中。在此上下文中 current 宏是有效的（处于中断上下文的情况下，系统不代表进程执行，此时不存在进程上下文，current 宏也是无效的）。&lt;/p&gt;

&lt;p&gt;task_struct 的 parent 字段指向其父进程 task_struct，children 字段为其子进程的链表。因此可以通过下面代码得到父进程的进程描述符：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct task_struct *my_parent = current-&amp;gt;parent;
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;同样，以下代码可以依次访问子进程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;struct task_struct *task; 
struct list_head *list;

list_for_each(list, &amp;amp;current-&amp;gt;children) {
    task = list_entry(list, struct task_struct, sibling); 
    /* task now points to one of current’s children */
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;任务队列是双向循环链表，下面代码可以获取链表中的下一个进程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;list_entry(task-&amp;gt;tasks.next, struct task_struct, tasks)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;获取前一个进程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;list_entry(task-&amp;gt;tasks.prev, struct task_struct, tasks)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;进程创建&lt;/h2&gt;

&lt;p&gt;fork() 通过拷贝当前进程来创建一个子进程。子进程和父进程的区别仅仅在于 PID、PPID 和某些资源和统计量（例如挂起的信号）。exec() 函数负责读取可执行文件并将其载入地址空间开始运行。&lt;/p&gt;

&lt;p&gt;Linux 通过 clone() 系统调用实现 fork()。这个调用通过一系列参数标志来指明父子进程需要共享的资源。fork()、vfork() 和 __clone() 库函数都根据各自需要的参数标志去调用 clone()，然后由 clone() 去调用 do_fork()。&lt;/p&gt;

&lt;p&gt;do_fork() 完成创建进程中的大部分工作，该函数调用 copy_process() 函数，然后让进程开始运行。copy_process() 的步骤如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用 dup_task_struct() 为新进程创建一个内核栈、thread_info 结构和 task_struct。这些值与当前进程相同，此时父子进程的描述符完全相同。&lt;/li&gt;
&lt;li&gt;检查当前用户所拥有的进程数没有超出资源限制。&lt;/li&gt;
&lt;li&gt;子进程开始与父进程区别开来，将进程描述符里的大多数成员重新初始化。&lt;/li&gt;
&lt;li&gt;将子进程的状态置为 TASK_UNINTERRUPTIBLE。（没有找到对应的代码）&lt;/li&gt;
&lt;li&gt;copy_process() 调用 copy_flags() 以更新 task_struct 的 flags 成员，重置 PF_SUPERPRIV 标志位，并设置 PF_FORKNOEXEC 标志位。&lt;/li&gt;
&lt;li&gt;根据不同的 clone_flags 参数，拷贝或共享打开的文件、文件系统信息、信号处理函数、进程地址空间和命名空间等。一般情况下，同一个进程内的线程共享这些信息。&lt;/li&gt;
&lt;li&gt;调用 alloc_pid() 为新进程分配一个有效的 PID。&lt;/li&gt;
&lt;li&gt;最后，copy_process() 做扫尾工作并返回指向子进程的指针。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;回到 do_fork() 函数，如果 copy_process() 返回成功，唤醒新创建的子进程并让其投入运行。内核有意选择子进程先执行，如果子进程马上调用 exec() 函数可以避免写时拷贝的额外开销。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;long do_fork(unsigned long clone_flags,
          unsigned long stack_start,
          struct pt_regs *regs,
          unsigned long stack_size,
          int __user *parent_tidptr,
          int __user *child_tidptr)
{
    struct task_struct *p;

    p = copy_process(clone_flags, stack_start, regs, stack_size,
             child_tidptr, NULL, trace);

    /*
     * Do this prior waking up the new thread - the thread pointer
     * might get invalid after that point, if the thread exits quickly.
     */
    if (!IS_ERR(p)) {
        struct completion vfork;

        trace_sched_process_fork(current, p);

        if (clone_flags &amp;amp; CLONE_VFORK) {
            p-&amp;gt;vfork_done = &amp;amp;vfork;
            init_completion(&amp;amp;vfork);
        }

        /*
         * We set PF_STARTING at creation in case tracing wants to
         * use this to distinguish a fully live task from one that
         * hasn&amp;#39;t gotten to tracehook_report_clone() yet.  Now we
         * clear it and set the child going.
         */
        p-&amp;gt;flags &amp;amp;= ~PF_STARTING;

        if (unlikely(clone_flags &amp;amp; CLONE_STOPPED)) {
            /*
             * We&amp;#39;ll start up with an immediate SIGSTOP.
             */
            sigaddset(&amp;amp;p-&amp;gt;pending.signal, SIGSTOP);
            set_tsk_thread_flag(p, TIF_SIGPENDING);
            __set_task_state(p, TASK_STOPPED);
        } else {
            wake_up_new_task(p, clone_flags);
        }

        if (clone_flags &amp;amp; CLONE_VFORK) {
            wait_for_completion(&amp;amp;vfork);
        }
    } else {
        nr = PTR_ERR(p);
    }
    return nr;
}

static struct task_struct *copy_process(unsigned long clone_flags,
                    unsigned long stack_start,
                    struct pt_regs *regs,
                    unsigned long stack_size,
                    int __user *child_tidptr,
                    struct pid *pid,
                    int trace)
{
    int retval;
    struct task_struct *p;

    p = dup_task_struct(current);

    if (atomic_read(&amp;amp;p-&amp;gt;real_cred-&amp;gt;user-&amp;gt;processes) &amp;gt;=
            task_rlimit(p, RLIMIT_NPROC)) {
        if (!capable(CAP_SYS_ADMIN) &amp;amp;&amp;amp; !capable(CAP_SYS_RESOURCE) &amp;amp;&amp;amp;
            p-&amp;gt;real_cred-&amp;gt;user != INIT_USER)
            goto bad_fork_free;
    }

    p-&amp;gt;did_exec = 0;
    delayacct_tsk_init(p);  /* Must remain after dup_task_struct() */
    copy_flags(clone_flags, p);
    INIT_LIST_HEAD(&amp;amp;p-&amp;gt;children);
    INIT_LIST_HEAD(&amp;amp;p-&amp;gt;sibling);
    rcu_copy_process(p);
    p-&amp;gt;vfork_done = NULL;
    spin_lock_init(&amp;amp;p-&amp;gt;alloc_lock);

    init_sigpending(&amp;amp;p-&amp;gt;pending);

    p-&amp;gt;utime = cputime_zero;
    p-&amp;gt;stime = cputime_zero;
    p-&amp;gt;gtime = cputime_zero;
    p-&amp;gt;utimescaled = cputime_zero;
    p-&amp;gt;stimescaled = cputime_zero;
#ifndef CONFIG_VIRT_CPU_ACCOUNTING
    p-&amp;gt;prev_utime = cputime_zero;
    p-&amp;gt;prev_stime = cputime_zero;
#endif

    /* copy all the process information */
    if ((retval = copy_semundo(clone_flags, p)))
        goto bad_fork_cleanup_audit;
    if ((retval = copy_files(clone_flags, p)))
        goto bad_fork_cleanup_semundo;
    if ((retval = copy_fs(clone_flags, p)))
        goto bad_fork_cleanup_files;
    if ((retval = copy_sighand(clone_flags, p)))
        goto bad_fork_cleanup_fs;
    if ((retval = copy_signal(clone_flags, p)))
        goto bad_fork_cleanup_sighand;
    if ((retval = copy_mm(clone_flags, p)))
        goto bad_fork_cleanup_signal;
    if ((retval = copy_namespaces(clone_flags, p)))
        goto bad_fork_cleanup_mm;
    if ((retval = copy_io(clone_flags, p)))
        goto bad_fork_cleanup_namespaces;
    retval = copy_thread(clone_flags, stack_start, stack_size, p, regs);
    if (retval)
        goto bad_fork_cleanup_io;

    if (pid != &amp;amp;init_struct_pid) {
        retval = -ENOMEM;
        pid = alloc_pid(p-&amp;gt;nsproxy-&amp;gt;pid_ns);
        if (!pid)
            goto bad_fork_cleanup_io;

        if (clone_flags &amp;amp; CLONE_NEWPID) {
            retval = pid_ns_prepare_proc(p-&amp;gt;nsproxy-&amp;gt;pid_ns);
            if (retval &amp;lt; 0)
                goto bad_fork_free_pid;
        }
    }

    p-&amp;gt;pid = pid_nr(pid);
    p-&amp;gt;tgid = p-&amp;gt;pid;
    if (clone_flags &amp;amp; CLONE_THREAD)
        p-&amp;gt;tgid = current-&amp;gt;tgid;  // 同一进程内的所有线程的 tgid 相同


    /* ok, now we should be set up.. */
    p-&amp;gt;exit_signal = (clone_flags &amp;amp; CLONE_THREAD) ? -1 : (clone_flags &amp;amp; CSIGNAL);
    p-&amp;gt;pdeath_signal = 0;
    p-&amp;gt;exit_state = 0;

    /*
     * Ok, make it visible to the rest of the system.
     * We dont wake it up yet.
     */
    p-&amp;gt;group_leader = p;
    INIT_LIST_HEAD(&amp;amp;p-&amp;gt;thread_group);

    /* CLONE_PARENT re-uses the old parent */
    if (clone_flags &amp;amp; (CLONE_PARENT|CLONE_THREAD)) {
        p-&amp;gt;real_parent = current-&amp;gt;real_parent;
        p-&amp;gt;parent_exec_id = current-&amp;gt;parent_exec_id;
    } else {
        p-&amp;gt;real_parent = current;
        p-&amp;gt;parent_exec_id = current-&amp;gt;self_exec_id;
    }

    return p;
}

static struct task_struct *dup_task_struct(struct task_struct *orig)
{
    struct task_struct *tsk;
    struct thread_info *ti;
    unsigned long *stackend;

    int err;

    prepare_to_copy(orig);

    tsk = alloc_task_struct();
    if (!tsk)
        return NULL;

    ti = alloc_thread_info(tsk);
    if (!ti) {
        free_task_struct(tsk);
        return NULL;
    }

    err = arch_dup_task_struct(tsk, orig);
    if (err)
        goto out;

    tsk-&amp;gt;stack = ti;

    setup_thread_stack(tsk, orig);
    stackend = end_of_stack(tsk);
    *stackend = STACK_END_MAGIC;    /* for overflow detection */

    /* One for us, one for whoever does the &amp;quot;release_task()&amp;quot; (usually parent) */
    atomic_set(&amp;amp;tsk-&amp;gt;usage,2);
    atomic_set(&amp;amp;tsk-&amp;gt;fs_excl, 0);

    return tsk;
}

// x86 下的实现
int arch_dup_task_struct(struct task_struct *dst, struct task_struct *src)
{
    *dst = *src;
    if (src-&amp;gt;thread.xstate) {
        dst-&amp;gt;thread.xstate = kmem_cache_alloc(task_xstate_cachep,
                              GFP_KERNEL);
        if (!dst-&amp;gt;thread.xstate)
            return -ENOMEM;
        WARN_ON((unsigned long)dst-&amp;gt;thread.xstate &amp;amp; 15);
        memcpy(dst-&amp;gt;thread.xstate, src-&amp;gt;thread.xstate, xstate_size);
    }
    return 0;
}

#define task_thread_info(task)  ((struct thread_info *)(task)-&amp;gt;stack)

#define setup_thread_stack(p, org) \
    *task_thread_info(p) = *task_thread_info(org); \
    task_thread_info(p)-&amp;gt;task = (p);

static void copy_flags(unsigned long clone_flags, struct task_struct *p)
{
    unsigned long new_flags = p-&amp;gt;flags;

    new_flags &amp;amp;= ~PF_SUPERPRIV;
    new_flags |= PF_FORKNOEXEC;
    new_flags |= PF_STARTING;
    p-&amp;gt;flags = new_flags;
    clear_freeze_flag(p);
}

void wake_up_new_task(struct task_struct *p, unsigned long clone_flags)
{
    unsigned long flags;
    struct rq *rq;
    int cpu __maybe_unused = get_cpu();

#ifdef CONFIG_SMP
    /*
     * Fork balancing, do it here and not earlier because:
     *  - cpus_allowed can change in the fork path
     *  - any previously selected cpu might disappear through hotplug
     *
     * We still have TASK_WAKING but PF_STARTING is gone now, meaning
     * -&amp;gt;cpus_allowed is stable, we have preemption disabled, meaning
     * cpu_online_mask is stable.
     */
    cpu = select_task_rq(p, SD_BALANCE_FORK, 0);
    set_task_cpu(p, cpu);
#endif

    /*
     * Since the task is not on the rq and we still have TASK_WAKING set
     * nobody else will migrate this task.
     */
    rq = cpu_rq(cpu);
    raw_spin_lock_irqsave(&amp;amp;rq-&amp;gt;lock, flags);

    BUG_ON(p-&amp;gt;state != TASK_WAKING);
    p-&amp;gt;state = TASK_RUNNING;  // 设置成TASK_RUNNING状态  
    update_rq_clock(rq);
    activate_task(rq, p, 0);  // activate_task 会把该 task 放入 cpu 的 runqueue
    trace_sched_wakeup_new(rq, p, 1);
    check_preempt_curr(rq, p, WF_FORK);
#ifdef CONFIG_SMP
    if (p-&amp;gt;sched_class-&amp;gt;task_woken)
        p-&amp;gt;sched_class-&amp;gt;task_woken(rq, p);
#endif
    task_rq_unlock(rq, &amp;amp;flags);
    put_cpu();
}


/*
 * activate_task - move a task to the runqueue.
 */
static void activate_task(struct rq *rq, struct task_struct *p, int wakeup)
{
    if (task_contributes_to_load(p))
        rq-&amp;gt;nr_uninterruptible--;

    enqueue_task(rq, p, wakeup, false);  // 放入 runqueue
    inc_nr_running(rq);
}

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;vfork() 的实现是通过向 clone() 传递一个特殊标志 CLONE_VFORK 来进行的：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;在调用 copy_process() 时，task_struct 的 vfork_done 成员被设置为 NULL。&lt;/li&gt;
&lt;li&gt;在执行 do_fork() 时，如果指定了 CLONE_VFORK 标志位，则 vfork_done 会被设置为指向一个特定地址。&lt;/li&gt;
&lt;li&gt;子进程先开始执行后，父进程会一直等待，直到子进程通过 vfork_done 指针向他发送信号。&lt;/li&gt;
&lt;li&gt;进程退出内存地址空间时会调用 mm_release() 函数，该函数会检查 vfork_done 是非为空，如果非空，则向父进程发送信号。&lt;/li&gt;
&lt;li&gt;返回到 do_fork()，父进程被唤醒并继续执行&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;void mm_release(struct task_struct *tsk, struct mm_struct *mm)
{
    struct completion *vfork_done = tsk-&amp;gt;vfork_done;

    /* notify parent sleeping on vfork() */
    if (vfork_done) {
        tsk-&amp;gt;vfork_done = NULL;
        complete(vfork_done);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;线程&lt;/h2&gt;

&lt;p&gt;Linux 把所有线程都当做进程来实现，每个线程都有唯一隶属于自己的 task_struct，所以在内核中，它看起来就像是一个普通的进程。&lt;/p&gt;

&lt;p&gt;线程的创建和普通进程类似，只不过调用 clone() 的时候需要传递参数来指明需要共享的资源：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;clone(CLONE_VM | CLONE_FS | CLONE_FILES | CLONE_SIGHAND, 0);
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;下表列举了参数标志及其作用：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Flag&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_FILES&lt;/td&gt;
&lt;td&gt;Parent and child share open files&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_FS&lt;/td&gt;
&lt;td&gt;Parent and child share filesystem information&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_IDLETASK&lt;/td&gt;
&lt;td&gt;Set PID to zero (used only by the idle tasks)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_NEWNS&lt;/td&gt;
&lt;td&gt;Create a new namespace for the child&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_PARENT&lt;/td&gt;
&lt;td&gt;Child is to have same parent as its parent&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_PTRACE&lt;/td&gt;
&lt;td&gt;Continue tracing child&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_SETTID&lt;/td&gt;
&lt;td&gt;Write the TID back to user-space&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_SETTLS&lt;/td&gt;
&lt;td&gt;Create a new TLS for the child&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_SIGHAND&lt;/td&gt;
&lt;td&gt;Parent and child share signal handlers and blocked signals&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_SYSVSEM&lt;/td&gt;
&lt;td&gt;Parent and child share System V SEM_UNDO semantics&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_THREAD&lt;/td&gt;
&lt;td&gt;Parent and child are in the same thread group&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_VFORK&lt;/td&gt;
&lt;td&gt;vfork() was used and the parent will sleep until the child wakes it&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_UNTRACED&lt;/td&gt;
&lt;td&gt;Do not let the tracing process force CLONE_PTRACE on the child&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_STOP&lt;/td&gt;
&lt;td&gt;Start process in the TASK_STOPPED state&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_SETTLS&lt;/td&gt;
&lt;td&gt;Create a new TLS (thread-local storage) for the child&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_CHILD_CLEARTID&lt;/td&gt;
&lt;td&gt;Clear the TID in the child&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_CHILD_SETTID&lt;/td&gt;
&lt;td&gt;Set the TID in the child&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_PARENT_SETTID&lt;/td&gt;
&lt;td&gt;Set the TID in the parent&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;CLONE_VM&lt;/td&gt;
&lt;td&gt;Parent and child share address space&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;内核经常需要在后台执行一些操作，这通过内核线程来完成。内核线程和普通进程间的区别在于内核线程没有独立的地址空间（指向地址空间的 mm 指针被设置为 NULL）。内核线程只在内核空间运行，从来不切换到用户空间。内核线程和普通进程一样可以被调度和抢占。&lt;/p&gt;

&lt;h2&gt;进程终止&lt;/h2&gt;

&lt;p&gt;进程终止可以由自身调用 exit() 系统调用引起，或接收到不能处理或不能忽略的信号或异常时。进程终止由 do_exit() 完成大部分工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;将 task_struct 中的标志成员设置为 PF_EXITING。&lt;/li&gt;
&lt;li&gt;调用 del_timer_sync() 删除内核定时器，确保没有定时器在排队也没有定时器处理程序在运行。&lt;/li&gt;
&lt;li&gt;调用 acct_update_intergrals() 来输出记账信息。&lt;/li&gt;
&lt;li&gt;调用 exit_mm() 函数释放进程占用的 mm_struct。如果该地址空间没有被共享，则彻底释放它们。&lt;/li&gt;
&lt;li&gt;设置 exit_code 成员为由 exit() 提供的退出代码。&lt;/li&gt;
&lt;li&gt;接下来调用 exit_sem() 函数，如果该进程正在排队等候 IPC 信号，则 dequeue。&lt;/li&gt;
&lt;li&gt;调用 exit_files() 和 exit_fs()，分别递减文件描述符、文件系统数据的引用计数。如果引用计数降为零，则释放资源。&lt;/li&gt;
&lt;li&gt;调用 exit_notify() 向父进程发送信号，给其子进程重新找养父，并把进程状态设置为 EXIT_ZOMBIE。&lt;/li&gt;
&lt;li&gt;do_exit() 调用 schedule() 函数切换到新的进程。由于处于 EXIT_ZOMBIE 状态的进程不会再被调度，所以 do_exit() 永不返回。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;至此，与进程相关的所有资源都被释放，进程不可运行并处于 EXIT_ZOMBIE 状态。它占用的内存就是内核栈、thread_info 结构和 task_struct 结构。此时进程存在的唯一目的就是向父进程提供信息。父进程检索到信息或通知内核那是无关信息后，进程所持有的剩余内存将被释放。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;NORET_TYPE void do_exit(long code)
{
    struct task_struct *tsk = current;
    int group_dead;

    /*
     * We&amp;#39;re taking recursive faults here in do_exit. Safest is to just
     * leave this task alone and wait for reboot.
     */
    if (unlikely(tsk-&amp;gt;flags &amp;amp; PF_EXITING)) {
        printk(KERN_ALERT
            &amp;quot;Fixing recursive fault but reboot is needed!\n&amp;quot;);
        /*
         * We can do this unlocked here. The futex code uses
         * this flag just to verify whether the pi state
         * cleanup has been done or not. In the worst case it
         * loops once more. We pretend that the cleanup was
         * done as there is no way to return. Either the
         * OWNER_DIED bit is set by now or we push the blocked
         * task into the wait for ever nirwana as well.
         */
        tsk-&amp;gt;flags |= PF_EXITPIDONE;
        set_current_state(TASK_UNINTERRUPTIBLE);
        schedule();
    }

    exit_signals(tsk);  /* sets PF_EXITING */

    acct_update_integrals(tsk);

    group_dead = atomic_dec_and_test(&amp;amp;tsk-&amp;gt;signal-&amp;gt;live);

    tsk-&amp;gt;exit_code = code;

    exit_mm(tsk);

    exit_sem(tsk);
    exit_files(tsk);
    exit_fs(tsk);
    check_stack_usage();
    exit_thread();
    cgroup_exit(tsk, 1);

    exit_notify(tsk, group_dead);

    /*
     * We can do this unlocked here. The futex code uses this flag
     * just to verify whether the pi state cleanup has been done
     * or not. In the worst case it loops once more.
     */
    tsk-&amp;gt;flags |= PF_EXITPIDONE;
    preempt_disable();
    exit_rcu();
    /* causes final put_task_struct in finish_task_switch(). */
    tsk-&amp;gt;state = TASK_DEAD;
    schedule();
}

static void exit_mm(struct task_struct * tsk)
{
    struct mm_struct *mm = tsk-&amp;gt;mm;
    struct core_state *core_state;

    mm_release(tsk, mm);
    if (!mm)
        return;

    down_read(&amp;amp;mm-&amp;gt;mmap_sem);
    atomic_inc(&amp;amp;mm-&amp;gt;mm_count);
    BUG_ON(mm != tsk-&amp;gt;active_mm);
    /* more a memory barrier than a real lock */
    task_lock(tsk);
    tsk-&amp;gt;mm = NULL;
    up_read(&amp;amp;mm-&amp;gt;mmap_sem);
    enter_lazy_tlb(mm, current);
    /* We don&amp;#39;t want this task to be frozen prematurely */
    clear_freeze_flag(tsk);
    task_unlock(tsk);
    mm_update_next_owner(mm);
    mmput(mm);
}

/*
 * Send signals to all our closest relatives so that they know
 * to properly mourn us..
 */
static void exit_notify(struct task_struct *tsk, int group_dead)
{
    int signal;
    void *cookie;

    /*
     * This does two things:
     *
     * A.  Make init inherit all the child processes
     * B.  Check to see if any process groups have become orphaned
     *  as a result of our exiting, and if they have any stopped
     *  jobs, send them a SIGHUP and then a SIGCONT.  (POSIX 3.2.2.2)
     */
    forget_original_parent(tsk);
    exit_task_namespaces(tsk);

    write_lock_irq(&amp;amp;tasklist_lock);
    if (group_dead)
        kill_orphaned_pgrp(tsk-&amp;gt;group_leader, NULL);

    /* Let father know we died
     *
     * Thread signals are configurable, but you aren&amp;#39;t going to use
     * that to send signals to arbitary processes.
     * That stops right now.
     *
     * If the parent exec id doesn&amp;#39;t match the exec id we saved
     * when we started then we know the parent has changed security
     * domain.
     *
     * If our self_exec id doesn&amp;#39;t match our parent_exec_id then
     * we have changed execution domain as these two values started
     * the same after a fork.
     */
    if (tsk-&amp;gt;exit_signal != SIGCHLD &amp;amp;&amp;amp; !task_detached(tsk) &amp;amp;&amp;amp;
        (tsk-&amp;gt;parent_exec_id != tsk-&amp;gt;real_parent-&amp;gt;self_exec_id ||
         tsk-&amp;gt;self_exec_id != tsk-&amp;gt;parent_exec_id))
        tsk-&amp;gt;exit_signal = SIGCHLD;

    signal = tracehook_notify_death(tsk, &amp;amp;cookie, group_dead);
    if (signal &amp;gt;= 0)
        signal = do_notify_parent(tsk, signal);  // 给父进程发信号。如果父进程处理 SIGCHLD 信号，返回 DEATH_REAP

    tsk-&amp;gt;exit_state = signal == DEATH_REAP ? EXIT_DEAD : EXIT_ZOMBIE;  

    /* mt-exec, de_thread() is waiting for us */
    if (thread_group_leader(tsk) &amp;amp;&amp;amp;
        tsk-&amp;gt;signal-&amp;gt;group_exit_task &amp;amp;&amp;amp;
        tsk-&amp;gt;signal-&amp;gt;notify_count &amp;lt; 0)
        wake_up_process(tsk-&amp;gt;signal-&amp;gt;group_exit_task);

    write_unlock_irq(&amp;amp;tasklist_lock);

    tracehook_report_death(tsk, signal, cookie, group_dead);

    /* If the process is dead, release it - nobody will wait for it */
    if (signal == DEATH_REAP)
        release_task(tsk);
}

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;调用 do_exit() 之后，其进程描述符依然被保留。在其父进程获得退出信息或通知内核它并不关注后，子进程的 task_struct 才被释放。&lt;/p&gt;

&lt;p&gt;wait() 这一组函数都是通过唯一的系统调用 wait4() 来实现。它的标准动作是挂起调用它的进程，直到其中一个子进程退出。此时函数会返回该子进程的 PID。此外，调用该函数时提供的指针会包含子进程退出时的退出码。&lt;/p&gt;

&lt;p&gt;wait 系统调用会调用 do_wait() 函数，其将调用 do_wait_thread() -&amp;gt; wait_consider_task() -&amp;gt; wait_task_zombie() -&amp;gt; release_task()。release_task() 会释放进程描述符，完成以下工作：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;调用 __exit_signal()，进行最终统计，并调用 _unhash_process()，后者又会调用 detach_pid() 从 pidhash 上删除该进程，同时也从任务列表中删除该进程。&lt;/li&gt;
&lt;li&gt;__exit_signal() 释放僵死进程所占用的剩余资源。&lt;/li&gt;
&lt;li&gt;如果该进程是线程组的最后一个进程，并且领头进程已经死掉，那么release_task() 就得通知僵死的领头进程的父进程。&lt;/li&gt;
&lt;li&gt;release_task() 调用 put_task_struct() 释放进程内核栈和 thread_info 结构所占的页，并释放 task_struct 所占的 slab 高速缓存。&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;
void release_task(struct task_struct * p)
{
    struct task_struct *leader;
    int zap_leader;

repeat:
    __exit_signal(p);
    zap_leader = 0;
    leader = p-&amp;gt;group_leader;
    if (leader != p &amp;amp;&amp;amp; thread_group_empty(leader) &amp;amp;&amp;amp; leader-&amp;gt;exit_state == EXIT_ZOMBIE) {
        BUG_ON(task_detached(leader));
        do_notify_parent(leader, leader-&amp;gt;exit_signal);
        /*
         * If we were the last child thread and the leader has
         * exited already, and the leader&amp;#39;s parent ignores SIGCHLD,
         * then we are the one who should release the leader.
         *
         * do_notify_parent() will have marked it self-reaping in
         * that case.
         */
        zap_leader = task_detached(leader);

        /*
         * This maintains the invariant that release_task()
         * only runs on a task in EXIT_DEAD, just for sanity.
         */
        if (zap_leader)
            leader-&amp;gt;exit_state = EXIT_DEAD;
    }

    write_unlock_irq(&amp;amp;tasklist_lock);
    release_thread(p);
    call_rcu(&amp;amp;p-&amp;gt;rcu, delayed_put_task_struct);

    p = leader;
    if (unlikely(zap_leader))
        goto repeat;
}


/*
 * This function expects the tasklist_lock write-locked.
 */
static void __exit_signal(struct task_struct *tsk)
{
    struct signal_struct *sig = tsk-&amp;gt;signal;
    struct sighand_struct *sighand;

    BUG_ON(!sig);
    BUG_ON(!atomic_read(&amp;amp;sig-&amp;gt;count));


    posix_cpu_timers_exit(tsk);
    if (atomic_dec_and_test(&amp;amp;sig-&amp;gt;count))
        posix_cpu_timers_exit_group(tsk);
    else {
        /*
         * If there is any task waiting for the group exit
         * then notify it:
         */
        if (sig-&amp;gt;group_exit_task &amp;amp;&amp;amp; atomic_read(&amp;amp;sig-&amp;gt;count) == sig-&amp;gt;notify_count)
            wake_up_process(sig-&amp;gt;group_exit_task);

        if (tsk == sig-&amp;gt;curr_target)
            sig-&amp;gt;curr_target = next_thread(tsk);
        /*
         * Accumulate here the counters for all threads but the
         * group leader as they die, so they can be added into
         * the process-wide totals when those are taken.
         * The group leader stays around as a zombie as long
         * as there are other threads.  When it gets reaped,
         * the exit.c code will add its counts into these totals.
         * We won&amp;#39;t ever get here for the group leader, since it
         * will have been the last reference on the signal_struct.
         */
        sig-&amp;gt;utime = cputime_add(sig-&amp;gt;utime, tsk-&amp;gt;utime);
        sig-&amp;gt;stime = cputime_add(sig-&amp;gt;stime, tsk-&amp;gt;stime);
        sig-&amp;gt;gtime = cputime_add(sig-&amp;gt;gtime, tsk-&amp;gt;gtime);
        sig-&amp;gt;min_flt += tsk-&amp;gt;min_flt;
        sig-&amp;gt;maj_flt += tsk-&amp;gt;maj_flt;
        sig-&amp;gt;nvcsw += tsk-&amp;gt;nvcsw;
        sig-&amp;gt;nivcsw += tsk-&amp;gt;nivcsw;
        sig-&amp;gt;inblock += task_io_get_inblock(tsk);
        sig-&amp;gt;oublock += task_io_get_oublock(tsk);
        task_io_accounting_add(&amp;amp;sig-&amp;gt;ioac, &amp;amp;tsk-&amp;gt;ioac);
        sig-&amp;gt;sum_sched_runtime += tsk-&amp;gt;se.sum_exec_runtime;
        sig = NULL; /* Marker for below. */
    }

    __unhash_process(tsk);

    /*
     * Do this under -&amp;gt;siglock, we can race with another thread
     * doing sigqueue_free() if we have SIGQUEUE_PREALLOC signals.
     */
    flush_sigqueue(&amp;amp;tsk-&amp;gt;pending);

    tsk-&amp;gt;signal = NULL;
    tsk-&amp;gt;sighand = NULL;
    spin_unlock(&amp;amp;sighand-&amp;gt;siglock);

    __cleanup_sighand(sighand);
    clear_tsk_thread_flag(tsk,TIF_SIGPENDING);
    if (sig) {
        flush_sigqueue(&amp;amp;sig-&amp;gt;shared_pending);
        taskstats_tgid_free(sig);
        /*
         * Make sure -&amp;gt;signal can&amp;#39;t go away under rq-&amp;gt;lock,
         * see account_group_exec_runtime().
         */
        task_rq_unlock_wait(tsk);
        __cleanup_signal(sig);
    }
}

static void __unhash_process(struct task_struct *p)
{
    nr_threads--;
    detach_pid(p, PIDTYPE_PID);
    if (thread_group_leader(p)) {
        detach_pid(p, PIDTYPE_PGID);
        detach_pid(p, PIDTYPE_SID);

        list_del_rcu(&amp;amp;p-&amp;gt;tasks);  // 没理解 为什么需要是 group_header 才从 tasks_list 上删掉？
        list_del_init(&amp;amp;p-&amp;gt;sibling);
        __get_cpu_var(process_counts)--;
    }
    list_del_rcu(&amp;amp;p-&amp;gt;thread_group);
}


void release_task(struct task_struct *p)
{
    struct task_struct *leader;

    __exit_signal(p);

    zap_leader = 0;
    leader = p-&amp;gt;group_leader;
    if (leader != p &amp;amp;&amp;amp; thread_group_empty(leader)
            &amp;amp;&amp;amp; leader-&amp;gt;exit_state == EXIT_ZOMBIE) {
        /*
         * If we were the last child thread and the leader has
         * exited already, and the leader&amp;#39;s parent ignores SIGCHLD,
         * then we are the one who should release the leader.
         */
        zap_leader = do_notify_parent(leader, leader-&amp;gt;exit_signal);
        if (zap_leader)
            leader-&amp;gt;exit_state = EXIT_DEAD;
    }

    release_thread(p);
}

void detach_pid(struct task_struct *task, enum pid_type type)
{
    __change_pid(task, type, NULL);
}

static void __change_pid(struct task_struct *task, enum pid_type type,
            struct pid *new)
{
    struct pid_link *link;
    struct pid *pid;
    int tmp;

    link = &amp;amp;task-&amp;gt;pids[type];
    pid = link-&amp;gt;pid;

    hlist_del_rcu(&amp;amp;link-&amp;gt;node);
    link-&amp;gt;pid = new;

    for (tmp = PIDTYPE_MAX; --tmp &amp;gt;= 0; )
        if (!hlist_empty(&amp;amp;pid-&amp;gt;tasks[tmp]))
            return;

    free_pid(pid);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;如果父进程在子进程之前退出，需要给子进程在当前的线程组内找一个进程作为父亲，如果失败，则让 init 做子进程的父进程。forget_original_parent() 调用 find_new_reaper() 来执行寻父过程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;
static void forget_original_parent(struct task_struct *father)
{
    struct task_struct *p, *n, *reaper;
    LIST_HEAD(dead_children);

    exit_ptrace(father);

    write_lock_irq(&amp;amp;tasklist_lock);
    reaper = find_new_reaper(father);

    list_for_each_entry_safe(p, n, &amp;amp;father-&amp;gt;children, sibling) {
        struct task_struct *t = p;
        do {
            t-&amp;gt;real_parent = reaper;
            if (t-&amp;gt;parent == father) {
                BUG_ON(task_ptrace(t));
                t-&amp;gt;parent = t-&amp;gt;real_parent;
            }
        } while_each_thread(p, t);
        reparent_leader(father, p, &amp;amp;dead_children);
    }
    write_unlock_irq(&amp;amp;tasklist_lock);

    BUG_ON(!list_empty(&amp;amp;father-&amp;gt;children));

    list_for_each_entry_safe(p, n, &amp;amp;dead_children, sibling) {
        list_del_init(&amp;amp;p-&amp;gt;sibling);
        release_task(p);
    }
}

static struct task_struct *find_new_reaper(struct task_struct *father)
{
    struct pid_namespace *pid_ns = task_active_pid_ns(father);
    struct task_struct *thread;

    thread = father;
    while_each_thread(father, thread) {
        if (thread-&amp;gt;flags &amp;amp; PF_EXITING)
            continue;
        if (unlikely(pid_ns-&amp;gt;child_reaper == father))
            pid_ns-&amp;gt;child_reaper = thread;
        return thread;
    }

    if (unlikely(pid_ns-&amp;gt;child_reaper == father)) {
        write_unlock_irq(&amp;amp;tasklist_lock);
        if (unlikely(pid_ns == &amp;amp;init_pid_ns))
            panic(&amp;quot;Attempted to kill init!&amp;quot;);

        zap_pid_ns_processes(pid_ns);
        write_lock_irq(&amp;amp;tasklist_lock);
        /*
         * We can not clear -&amp;gt;child_reaper or leave it alone.
         * There may by stealth EXIT_DEAD tasks on -&amp;gt;children,
         * forget_original_parent() must move them somewhere.
         */
        pid_ns-&amp;gt;child_reaper = init_pid_ns.child_reaper;
    }

    return pid_ns-&amp;gt;child_reaper;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Sun, 27 Nov 2016 13:49:16 +0800</pubDate>
        <link>http://masutangu.com/2016/11/linux-kernel-serial-1/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/11/linux-kernel-serial-1/</guid>
        
        
        <category>读书笔记</category>
        
      </item>
    
      <item>
        <title>Libuv 源码阅读</title>
        <description>&lt;p&gt;花了几天时间读了下 libuv 的源码，整理成这篇文章。&lt;a href = #section_1&gt;第一节&lt;/a&gt;是读官方教程做的笔记，主要是供自己备忘用，读者可以跳过。&lt;a href = #section_2&gt;第二节&lt;/a&gt;解读 libuv 的源码，重点在 libuv 队列的实现和如何用线程池实现异步文件 IO。&lt;/p&gt;

&lt;h1&gt;&lt;span id=&quot;section_1&quot;&gt;概念&lt;/span&gt;&lt;/h1&gt;

&lt;h2&gt;handles 和 requests&lt;/h2&gt;

&lt;p&gt;libuv 提供了两个抽象：handles 和 requests。handles 是 long－lived 的，会在其 active 的时候做特定的操作。requests 则为 short-lived 操作，request 可以独自执行或被 handle 调用执行。&lt;/p&gt;

&lt;h2&gt;I/O loop&lt;/h2&gt;

&lt;p&gt;I/O loop（或 event loop）是 libuv 的核心。每个 I/O loop 绑定单一的线程。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The libuv event loop (or any other API involving the loop or handles, for that matter) is not thread-safe except where stated otherwise.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;event loop 采用单线程异步 IO 的形式：所有网络操作都使用 non-blocking 套接字，并使用各个平台上性能最好的 poll 机制例如 linux 上的 epoll，OSX 的 kqueue 等等。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/libuv-source-code/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I/O loop 的流程：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;event loop 在每次循环周期开始前都会缓存当前时间，以减少时间相关的系统调用&lt;/li&gt;
&lt;li&gt;执行到期定时器的 callback &lt;/li&gt;
&lt;li&gt;执行上一轮循环推迟的 I/O callback &lt;/li&gt;
&lt;li&gt;执行 Idle handle 的 callback &lt;/li&gt;
&lt;li&gt;执行 Prepare handle 的 callback&lt;/li&gt;
&lt;li&gt;计算 poll timeout&lt;/li&gt;
&lt;li&gt;阻塞处理 I/O，超时时间为上一步计算的 poll timeout &lt;/li&gt;
&lt;li&gt;执行 Check handle 的 callback&lt;/li&gt;
&lt;li&gt;执行 Close callback&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;libuv uses a thread pool to make asynchronous file I/O operations possible, but network I/O is always performed in a single thread, each loop’s thread.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2&gt;File I/O&lt;/h2&gt;

&lt;p&gt;libuv 的异步文件 I/O 是通过线程池实现的。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;libuv provides a threadpool which can be used to run user code and get notified in the loop thread. &lt;strong&gt;This thread pool is internally used to run all filesystem operations&lt;/strong&gt;, as well as getaddrinfo and getnameinfo requests.&lt;/p&gt;

&lt;p&gt;The threadpool is global and shared across all event loops. When a particular function makes use of the threadpool (i.e. when using &lt;code&gt;uv_queue_work()&lt;/code&gt;) libuv preallocates and initializes the maximum number of threads allowed by UV_THREADPOOL_SIZE.&lt;/p&gt;

&lt;p&gt;libuv currently uses a global thread pool on which all loops can queue work on. 3 types of operations are currently run on this pool:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Filesystem operations&lt;/li&gt;
&lt;li&gt;DNS functions (getaddrinfo and getnameinfo)&lt;/li&gt;
&lt;li&gt;User specified code via uv_queue_work()&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h2&gt;主要结构体&lt;/h2&gt;

&lt;h3&gt;uv_loop_t&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;The event loop is the central part of libuv’s functionality. It takes care of polling for i/o and scheduling callbacks to be run based on different sources of events.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;uv_loop_t 执行的三种模式&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;UV_RUN_DEFAULT&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Runs the event loop until there are no more active and referenced handles or requests. Returns non-zero if uv_stop() was called and there are still active handles or requests. Returns zero in all other cases.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;UV_RUN_ONCE&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Poll for i/o once. Note that this function blocks if there are no pending callbacks. Returns zero when done (no active handles or requests left), or non-zero if more callbacks are expected (meaning you should run the event loop again sometime in the future).&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;UV_RUN_NOWAIT&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Poll for i/o once but don’t block if there are no pending callbacks. Returns zero if done (no active handles or requests left), or non-zero if more callbacks are expected (meaning you should run the event loop again sometime in the future).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;uv_handle_t&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;uv_handle_t is the base type for all libuv handle types.&lt;/p&gt;

&lt;p&gt;Structures are aligned so that any libuv handle can be cast to uv_handle_t. All API functions defined here work with any handle type.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;void uv_ref(uv_handle_t* handle)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Reference the given handle. References are idempotent, that is, if a handle is already referenced calling this function again will have no effect.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;void uv_unref(uv_handle_t* handle)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Un-reference the given handle. References are idempotent, that is, if a handle is not referenced calling this function again will have no effect.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;uv_unref 主要用于计时器。&lt;a href=&quot;https://nikhilm.github.io/uvbook/utilities.html#reference-count&quot;&gt;例子在此&lt;/a&gt;，摘抄如下：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;These functions can be used to allow a loop to exit even when a watcher is active or to use custom objects to keep the loop alive.&lt;/p&gt;

&lt;p&gt;The latter can be used with interval timers. You might have a garbage collector which runs every X seconds, or your network service might send a heartbeat to others periodically, but you don’t want to have to stop them along all clean exit paths or error scenarios. Or you want the program to exit when all your other watchers are done. In that case just unref the timer immediately after creation so that if it is the only watcher running then uv_run will still exit.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;uv_loop_t *loop;
uv_timer_t gc_req;
uv_timer_t fake_job_req;

int main() {
    loop = uv_default_loop();

    uv_timer_init(loop, &amp;amp;gc_req);
    uv_unref((uv_handle_t*) &amp;amp;gc_req);

    uv_timer_start(&amp;amp;gc_req, gc, 0, 2000);

    // could actually be a TCP download or something
    uv_timer_init(loop, &amp;amp;fake_job_req);
    uv_timer_start(&amp;amp;fake_job_req, fake_job, 9000, 0);
    return uv_run(loop, UV_RUN_DEFAULT);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;blockquote&gt;
&lt;p&gt;We initialize the garbage collector timer, then immediately unref it. Observe how after 9 seconds, when the fake job is done, the program automatically exits, even though the garbage collector is still running.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;uv_req_t&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;uv_req_t is the base type for all libuv request types.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1&gt;&lt;span id=&quot;section_2&quot;&gt;代码解读&lt;/span&gt;&lt;/h1&gt;

&lt;h2&gt;队列&lt;/h2&gt;

&lt;p&gt;libuv 的队列是循环双向链表，队列在 libuv 中用到的地方很多，例如 event loop 用队列来存储 handle（handle_queue)，待监听的io事件（watcher_queue）等等。&lt;/p&gt;

&lt;h3&gt;定义&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;typedef void *QUEUE[2];
#define QUEUE_NEXT(q)       (*(QUEUE **) &amp;amp;((*(q))[0]))
#define QUEUE_PREV(q)       (*(QUEUE **) &amp;amp;((*(q))[1]))
#define QUEUE_PREV_NEXT(q)  (QUEUE_NEXT(QUEUE_PREV(q)))
#define QUEUE_NEXT_PREV(q)  (QUEUE_PREV(QUEUE_NEXT(q)))

#define QUEUE_INIT(q)                                                         \
  do {                                                                        \
    QUEUE_NEXT(q) = (q);                                                      \
    QUEUE_PREV(q) = (q);                                                      \
  }                                                                           \
  while (0)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这段定义了 QUEUE 是元素类型为 void* 的数组，数组长度为 2。
如果按下面这样定义：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#define QUEUE_NEXT(q)       ((QUEUE *) ((*(q))[0]))
#define QUEUE_PREV(q)       ((QUEUE *) ((*(q))[1]))
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;返回值不是左值，在 QUEUE_INIT 函数中对 QUEUE_NEXT 和 QUEUE_PREV 的赋值会编译失败。
C/C++ 中类型转换有可能会返回左值（可以看 &lt;a href=&quot;http://stackoverflow.com/questions/26508609/is-the-result-of-a-cast-an-rvalue&quot;&gt;stackoverflow&lt;/a&gt; 的讲解)：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The result of the expression (T) cast-expression is of type T. The result is an lvalue if T is an lvalue reference type or an rvalue reference to function type and an xvalue if T is an rvalue reference to object type; &lt;strong&gt;otherwise the result is a prvalue.&lt;/strong&gt;[ Note: if T is a non-class type that is cv-qualified, the cv-qualifiers are ignored when determining the type of the resulting prvalue; see 3.10. —end note ]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;因此需要先将 ((*(q))[0])) 取址再解引用（解引用返回左值）。&lt;/p&gt;

&lt;h3&gt;接口&lt;/h3&gt;

&lt;p&gt;下面是 QUEUE 几个重要的接口：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;
// 取出数据，具体例子可参考：https://gist.github.com/bodokaiser/5657156
#define QUEUE_DATA(ptr, type, field)                                          \
  ((type *) ((char *) (ptr) - offsetof(type, field)))

// 将 n 队列的元素添加到 h 队列，保留 h 队列原先的元素。注意操作后 n 队列的结构被破坏，不能在遍历 n 队列
#define QUEUE_ADD(h, n)                                                       \
  do {                                                                        \
    QUEUE_PREV_NEXT(h) = QUEUE_NEXT(n);                                       \
    QUEUE_NEXT_PREV(n) = QUEUE_PREV(h);                                       \
    QUEUE_PREV(h) = QUEUE_PREV(n);                                            \
    QUEUE_PREV_NEXT(h) = (h);                                                 \
  }                                                                           \
  while (0)

// QUEUE_MOVE 的 helper 函数
#define QUEUE_SPLIT(h, q, n)                                                  \
  do {                                                                        \
    QUEUE_PREV(n) = QUEUE_PREV(h);                                            \
    QUEUE_PREV_NEXT(n) = (n);                                                 \
    QUEUE_NEXT(n) = (q);                                                      \
    QUEUE_PREV(h) = QUEUE_PREV(q);                                            \
    QUEUE_PREV_NEXT(h) = (h);                                                 \
    QUEUE_PREV(q) = (n);                                                      \
  }                                                                           \
  while (0)

// 将 h 队列的元素添加到 n 队列， h 队列被清空，n 队列原先的元素也被清空
#define QUEUE_MOVE(h, n)                                                      \
  do {                                                                        \
    if (QUEUE_EMPTY(h))                                                       \
      QUEUE_INIT(n);                                                          \
    else {                                                                    \
      QUEUE* q = QUEUE_HEAD(h);                                               \
      QUEUE_SPLIT(h, q, n);                                                   \
    }                                                                         \
  }                                                                           \
  while (0)

// 添加元素 q 到 h 队列的尾部，QUEUE_PREV(h) 为原先队列的 tail 节点
#define QUEUE_INSERT_TAIL(h, q)                                               \
  do {                                                                        \
    QUEUE_NEXT(q) = (h);                                                      \
    QUEUE_PREV(q) = QUEUE_PREV(h);                                            \
    QUEUE_PREV_NEXT(q) = (q);                                                 \
    QUEUE_PREV(h) = (q);                                                      \
  }                                                                           \
  while (0)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上面提到了 QUEUE 是一个循环链表。定义 h 为队列的哨兵节点，则 QUEUE_NEXT(h) 指向队列的 head 节点，QUEUE_PREV(h) 指向队列的 tail 节点。&lt;/p&gt;

&lt;p&gt;结合图例来看看 QUEUE_INSERT_TAIL 的实现。&lt;/p&gt;

&lt;p&gt;原队列，因为只有一个元素（h节点为哨兵节点，不算在内），因此其即是 head 也是 tail：
&lt;img src=&quot;/assets/images/libuv-source-code/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;新增一个新元素后如下所示：
&lt;img src=&quot;/assets/images/libuv-source-code/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;下面是 QUEUE_MOVE 的图例。
h 队列 和 n 队列 QUEUE_MOVE 操作前如下图：
&lt;img src=&quot;/assets/images/libuv-source-code/illustration-4.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;QUEUE_MOVE 后，h 队列被清空，n 队列的哨兵节点连接到原 h 队列的 head 和 tail：
&lt;img src=&quot;/assets/images/libuv-source-code/illustration-5.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;最后是 QUEUE_ADD 的图例，原理就是将 n 队列的 head 和 h 队列的 tail 相连，并把 h 队列的 tail 重置指向 n 队列的 tail：
&lt;img src=&quot;/assets/images/libuv-source-code/illustration-6.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;epoll 事件管理&lt;/h2&gt;

&lt;p&gt;IO 事件都会调用 &lt;code&gt;uv__io_start&lt;/code&gt; 函数，该函数将需要监听的事件保存到 event loop 的 watcher_queue 队列中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;void uv__io_start(uv_loop_t* loop, uv__io_t* w, unsigned int events) {
  ...

  if (QUEUE_EMPTY(&amp;amp;w-&amp;gt;watcher_queue))
    QUEUE_INSERT_TAIL(&amp;amp;loop-&amp;gt;watcher_queue, &amp;amp;w-&amp;gt;watcher_queue);  // 添加到 loop-&amp;gt;watcher_queue 队列

  ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;然后在 event loop 的循环中，会调用 &lt;code&gt;uv__io_poll&lt;/code&gt;。该函数将 loop-&amp;gt;watcher_queue 队列中的事件取出，添加到 epoll 进行监听：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;void uv__io_poll(uv_loop_t* loop, int timeout) {
  ...
  uv__io_t* w;

  while (!QUEUE_EMPTY(&amp;amp;loop-&amp;gt;watcher_queue)) {  // 遍历取出 loop-&amp;gt;watcher_queue 队列中待监听的事件，直至队列为空
    q = QUEUE_HEAD(&amp;amp;loop-&amp;gt;watcher_queue);
    QUEUE_REMOVE(q);
    QUEUE_INIT(q);

    w = QUEUE_DATA(q, uv__io_t, watcher_queue);  // 取出 uv__io_t 结构，该结构保存了用户注册的回调函数

    e.events = w-&amp;gt;pevents;
    e.data = w-&amp;gt;fd;

    if (w-&amp;gt;events == 0)
      op = UV__EPOLL_CTL_ADD;
    else
      op = UV__EPOLL_CTL_MOD;

    /* XXX Future optimization: do EPOLL_CTL_MOD lazily if we stop watching
     * events, skip the syscall and squelch the events after epoll_wait().
     */
    if (uv__epoll_ctl(loop-&amp;gt;backend_fd, op, w-&amp;gt;fd, &amp;amp;e)) {  // 添加到 epoll
      if (errno != EEXIST)
        abort();

      assert(op == UV__EPOLL_CTL_ADD);

      /* We&amp;#39;ve reactivated a file descriptor that&amp;#39;s been watched before. */
      if (uv__epoll_ctl(loop-&amp;gt;backend_fd, UV__EPOLL_CTL_MOD, w-&amp;gt;fd, &amp;amp;e))
        abort();
    }

    w-&amp;gt;events = w-&amp;gt;pevents;
  }

  ... 


  // 阻塞等待 epoll 返回直到超时
  for (;;) {
    if (no_epoll_wait != 0 || (sigmask != 0 &amp;amp;&amp;amp; no_epoll_pwait == 0)) {
      nfds = uv__epoll_pwait(loop-&amp;gt;backend_fd,
                             events,
                             ARRAY_SIZE(events),
                             timeout,
                             sigmask);
      if (nfds == -1 &amp;amp;&amp;amp; errno == ENOSYS)
        no_epoll_pwait = 1;
    } else {
      nfds = uv__epoll_wait(loop-&amp;gt;backend_fd,
                            events,
                            ARRAY_SIZE(events),
                            timeout);
      if (nfds == -1 &amp;amp;&amp;amp; errno == ENOSYS)
        no_epoll_wait = 1;
    }
    ...

    loop-&amp;gt;watchers[loop-&amp;gt;nwatchers] = (void*) events;  // 将 events 保存在 loop-&amp;gt;watchers，为了在 uv__io_close 中可以将对应 fd 的 event 删掉
    loop-&amp;gt;watchers[loop-&amp;gt;nwatchers + 1] = (void*) (uintptr_t) nfds;
    for (i = 0; i &amp;lt; nfds; i++) {
      pe = events + i;
      fd = pe-&amp;gt;data;

      /* Skip invalidated events, see uv__platform_invalidate_fd */
      if (fd == -1)
        continue;

      assert(fd &amp;gt;= 0);
      assert((unsigned) fd &amp;lt; loop-&amp;gt;nwatchers);

      w = loop-&amp;gt;watchers[fd];

      if (w == NULL) {
        /* File descriptor that we&amp;#39;ve stopped watching, disarm it.
         *
         * Ignore all errors because we may be racing with another thread
         * when the file descriptor is closed.
         */
        uv__epoll_ctl(loop-&amp;gt;backend_fd, UV__EPOLL_CTL_DEL, fd, pe);
        continue;
      }

      /* Give users only events they&amp;#39;re interested in. Prevents spurious
       * callbacks when previous callback invocation in this loop has stopped
       * the current watcher. Also, filters out events that users has not
       * requested us to watch.
       */
      pe-&amp;gt;events &amp;amp;= w-&amp;gt;pevents | POLLERR | POLLHUP;

      /* Work around an epoll quirk where it sometimes reports just the
       * EPOLLERR or EPOLLHUP event.  In order to force the event loop to
       * move forward, we merge in the read/write events that the watcher
       * is interested in; uv__read() and uv__write() will then deal with
       * the error or hangup in the usual fashion.
       *
       * Note to self: happens when epoll reports EPOLLIN|EPOLLHUP, the user
       * reads the available data, calls uv_read_stop(), then sometime later
       * calls uv_read_start() again.  By then, libuv has forgotten about the
       * hangup and the kernel won&amp;#39;t report EPOLLIN again because there&amp;#39;s
       * nothing left to read.  If anything, libuv is to blame here.  The
       * current hack is just a quick bandaid; to properly fix it, libuv
       * needs to remember the error/hangup event.  We should get that for
       * free when we switch over to edge-triggered I/O.
       */
      if (pe-&amp;gt;events == POLLERR || pe-&amp;gt;events == POLLHUP)
        pe-&amp;gt;events |= w-&amp;gt;pevents &amp;amp; (POLLIN | POLLOUT);

      if (pe-&amp;gt;events != 0) {
        /* Run signal watchers last.  This also affects child process watchers
         * because those are implemented in terms of signal watchers.
         */
        if (w == &amp;amp;loop-&amp;gt;signal_io_watcher)
          have_signals = 1;
        else
          w-&amp;gt;cb(loop, w, pe-&amp;gt;events);  // 调用用户注册的回调

        nevents++;
      }
    }

    loop-&amp;gt;watchers[loop-&amp;gt;nwatchers] = NULL;
    loop-&amp;gt;watchers[loop-&amp;gt;nwatchers + 1] = NULL;

    ...
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;线程池实现异步文件 IO&lt;/h2&gt;

&lt;p&gt;libuv 中文件操作的异步 IO 是通过线程池实现的。原理是将文件操作由工作线程来完成，当操作完成后工作线程通过 fd 通知主线程（该 fd 同样由 epoll 管理），主线程监听该 fd，当有 epoll 事件时根据层层回调，最终会调用到用户注册的回调函数。&lt;/p&gt;

&lt;p&gt;下面看看这块逻辑，所有文件操作都调用了 POST 定义的宏。POST 判断是否注册了回调，如果有则表示该操作为异步调用，此时调用 &lt;code&gt;uv__work_submit&lt;/code&gt; 向线程池提交任务。                                            &lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;#define POST                                                                  \
  do {                                                                        \
    if (cb != NULL) {                                                         \
      uv__work_submit(loop, &amp;amp;req-&amp;gt;work_req, uv__fs_work, uv__fs_done);        \
      return 0;                                                               \
    }                                                                         \
    else {                                                                    \
      // 回调为 null 是同步调用                                                  \
      uv__fs_work(&amp;amp;req-&amp;gt;work_req);                                            \
      return req-&amp;gt;result;                                                     \
    }                                                                         \
  }                                                                           \
  while (0)

// 操作完成后的回调函数
static void uv__fs_done(struct uv__work* w, int status) {
  uv_fs_t* req;

  req = container_of(w, uv_fs_t, work_req);
  uv__req_unregister(req-&amp;gt;loop, req);

  if (status == -ECANCELED) {
    assert(req-&amp;gt;result == 0);
    req-&amp;gt;result = -ECANCELED;
  }

  req-&amp;gt;cb(req);  // 调用用户注册的回调
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;uv__work_submit&lt;/code&gt; 先调用 &lt;code&gt;init_once&lt;/code&gt; 初始化工作线程池，再调用 &lt;code&gt;post&lt;/code&gt; 提交任务给工作线程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;void uv__work_submit(uv_loop_t* loop,
                     struct uv__work* w,
                     void (*work)(struct uv__work* w),
                     void (*done)(struct uv__work* w, int status)) {
  uv_once(&amp;amp;once, init_once);
  w-&amp;gt;loop = loop;
  w-&amp;gt;work = work;
  w-&amp;gt;done = done;
  post(&amp;amp;w-&amp;gt;wq);
}


static void init_once(void) {
  unsigned int i;
  const char* val;

  nthreads = ARRAY_SIZE(default_threads);
  val = getenv(&amp;quot;UV_THREADPOOL_SIZE&amp;quot;);
  if (val != NULL)
    nthreads = atoi(val);
  if (nthreads == 0)
    nthreads = 1;
  if (nthreads &amp;gt; MAX_THREADPOOL_SIZE)
    nthreads = MAX_THREADPOOL_SIZE;

  threads = default_threads;
  if (nthreads &amp;gt; ARRAY_SIZE(default_threads)) {
    threads = uv__malloc(nthreads * sizeof(threads[0]));
    if (threads == NULL) {
      nthreads = ARRAY_SIZE(default_threads);
      threads = default_threads;
    }
  }

  if (uv_cond_init(&amp;amp;cond))  // 初始化条件变量
    abort();

  if (uv_mutex_init(&amp;amp;mutex))  // 初始化互斥锁
    abort();

  QUEUE_INIT(&amp;amp;wq);

  for (i = 0; i &amp;lt; nthreads; i++)
    if (uv_thread_create(threads + i, worker, NULL))  // 创建工作线程
      abort();

  initialized = 1;
}

// 工作线程
static void worker(void* arg) {
  struct uv__work* w;
  QUEUE* q;

  (void) arg;

  for (;;) {
    uv_mutex_lock(&amp;amp;mutex);

    while (QUEUE_EMPTY(&amp;amp;wq)) {
      idle_threads += 1;
      uv_cond_wait(&amp;amp;cond, &amp;amp;mutex);   // wq 保存任务队列，当 wq 为空时阻塞等待任务，有新任务提交就会唤醒该 worker
      idle_threads -= 1;
    }

    q = QUEUE_HEAD(&amp;amp;wq);

    if (q == &amp;amp;exit_message)
      uv_cond_signal(&amp;amp;cond);  
    else {
      QUEUE_REMOVE(q);
      QUEUE_INIT(q);  /* Signal uv_cancel() that the work req is
                             executing. */
    }

    uv_mutex_unlock(&amp;amp;mutex);

    if (q == &amp;amp;exit_message)
      break;

    w = QUEUE_DATA(q, struct uv__work, wq);
    w-&amp;gt;work(w);   // work 执行文件操作

    uv_mutex_lock(&amp;amp;w-&amp;gt;loop-&amp;gt;wq_mutex);
    w-&amp;gt;work = NULL;  /* Signal uv_cancel() that the work req is done
                        executing. */
    QUEUE_INSERT_TAIL(&amp;amp;w-&amp;gt;loop-&amp;gt;wq, &amp;amp;w-&amp;gt;wq);  // 将已完成的 uv__work 添加到 loop-&amp;gt;wq 队列
    uv_async_send(&amp;amp;w-&amp;gt;loop-&amp;gt;wq_async);  // 通知主线程该任务已经执行完成
    uv_mutex_unlock(&amp;amp;w-&amp;gt;loop-&amp;gt;wq_mutex);
  }
}

// 提交任务 
static void post(QUEUE* q) {
  uv_mutex_lock(&amp;amp;mutex);
  QUEUE_INSERT_TAIL(&amp;amp;wq, q);  // 将任务提交到 wq 队列
  if (idle_threads &amp;gt; 0)
    uv_cond_signal(&amp;amp;cond);  // 有空闲工作线程时就唤醒 worker
  uv_mutex_unlock(&amp;amp;mutex);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;最后看看工作线程和主线程的通信，在文件操作完成后，工作线程调用 &lt;code&gt;uv__async_send&lt;/code&gt; ，该函数会往 wa-&amp;gt;wfd 或 wa-&amp;gt;io_watcher.fd 写一个空子节：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;int uv_async_send(uv_async_t* handle) {
  /* Do a cheap read first. */
  if (ACCESS_ONCE(int, handle-&amp;gt;pending) != 0)
    return 0;

  if (cmpxchgi(&amp;amp;handle-&amp;gt;pending, 0, 1) == 0)
    uv__async_send(&amp;amp;handle-&amp;gt;loop-&amp;gt;async_watcher);

  return 0;
}

void uv__async_send(struct uv__async* wa) {
  const void* buf;
  ssize_t len;
  int fd;
  int r;

  buf = &amp;quot;&amp;quot;;
  len = 1;
  fd = wa-&amp;gt;wfd;

#if defined(__linux__)
  if (fd == -1) {
    static const uint64_t val = 1;
    buf = &amp;amp;val;
    len = sizeof(val);
    fd = wa-&amp;gt;io_watcher.fd;  /* eventfd */
  }
#endif

  do
    r = write(fd, buf, len);
  while (r == -1 &amp;amp;&amp;amp; errno == EINTR);

  if (r == len)
    return;

  if (r == -1)
    if (errno == EAGAIN || errno == EWOULDBLOCK)
      return;

  abort();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;主线程监听 io_watcher.fd，当有 epoll 事件时回调的顺序如下：&lt;/p&gt;

&lt;p&gt;调用 uv__io_t 的 cb 即 &lt;code&gt;uv__async_io&lt;/code&gt; --&amp;gt; 调用 uv__async 的 cb 即 &lt;code&gt;uv__async_event&lt;/code&gt;  --&amp;gt; 调用 uv_async_t 的 cb 即 &lt;code&gt;uv__work_done&lt;/code&gt; --&amp;gt; 调用 uv__work 的 done 即用户提交的回调函数。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;int uv_loop_init(uv_loop_t* loop) {
  ...
  err = uv_async_init(loop, &amp;amp;loop-&amp;gt;wq_async, uv__work_done);  // 初始化 async 
  ...
}

void uv__work_done(uv_async_t* handle) {
  struct uv__work* w;
  uv_loop_t* loop;
  QUEUE* q;
  QUEUE wq;
  int err;

  loop = container_of(handle, uv_loop_t, wq_async);
  uv_mutex_lock(&amp;amp;loop-&amp;gt;wq_mutex);
  QUEUE_MOVE(&amp;amp;loop-&amp;gt;wq, &amp;amp;wq);  // 因为访问 loop-&amp;gt;wq 需要锁，为了避免长时间锁，所以拷贝一份副本出来，下面的遍历直接操作该副本
  uv_mutex_unlock(&amp;amp;loop-&amp;gt;wq_mutex);

  while (!QUEUE_EMPTY(&amp;amp;wq)) {  // 遍历 loop-&amp;gt;wq 的副本
    q = QUEUE_HEAD(&amp;amp;wq);
    QUEUE_REMOVE(q);

    w = container_of(q, struct uv__work, wq);
    err = (w-&amp;gt;work == uv__cancelled) ? UV_ECANCELED : 0;
    w-&amp;gt;done(w, err);  // 调用 done，即 uv__fs_done 函数，最终会调用用户注册的回调
  }
}

//  uv__async_start 函数会调用 uv__io_start，监听 wa-&amp;gt;io_watcher.fd
int uv_async_init(uv_loop_t* loop, uv_async_t* handle, uv_async_cb async_cb) {
  int err;

  err = uv__async_start(loop, &amp;amp;loop-&amp;gt;async_watcher, uv__async_event);
  if (err)
    return err;

  uv__handle_init(loop, (uv_handle_t*)handle, UV_ASYNC);
  handle-&amp;gt;async_cb = async_cb;
  handle-&amp;gt;pending = 0;

  QUEUE_INSERT_TAIL(&amp;amp;loop-&amp;gt;async_handles, &amp;amp;handle-&amp;gt;queue);
  uv__handle_start(handle);

  return 0;
}

// 创建 wa-&amp;gt;io_watcher.fd 
int uv__async_start(uv_loop_t* loop, struct uv__async* wa, uv__async_cb cb) {
  int pipefd[2];
  int err;

  if (wa-&amp;gt;io_watcher.fd != -1)
    return 0;

  // 下面一大段是创建 io_watcher.fd 的逻辑
  err = uv__async_eventfd();
  if (err &amp;gt;= 0) {
    pipefd[0] = err;
    pipefd[1] = -1;
  }
  else if (err == -ENOSYS) {
    err = uv__make_pipe(pipefd, UV__F_NONBLOCK);
#if defined(__linux__)
    /* Save a file descriptor by opening one of the pipe descriptors as
     * read/write through the procfs.  That file descriptor can then
     * function as both ends of the pipe.
     */
    if (err == 0) {
      char buf[32];
      int fd;

      snprintf(buf, sizeof(buf), &amp;quot;/proc/self/fd/%d&amp;quot;, pipefd[0]);
      fd = uv__open_cloexec(buf, O_RDWR);
      if (fd &amp;gt;= 0) {
        uv__close(pipefd[0]);
        uv__close(pipefd[1]);
        pipefd[0] = fd;
        pipefd[1] = fd;
      }
    }
#endif
  }

  if (err &amp;lt; 0)
    return err;

  uv__io_init(&amp;amp;wa-&amp;gt;io_watcher, uv__async_io, pipefd[0]);  // 注册 async io 事件的 callback 为 uv__async_io
  uv__io_start(loop, &amp;amp;wa-&amp;gt;io_watcher, POLLIN);  // 将该 io_watcher 添加到 loop-&amp;gt;watcher_queue，参考上文的 uv__io_start 
  wa-&amp;gt;wfd = pipefd[1];
  wa-&amp;gt;cb = cb;  // 注册 uv__async 的 cb 为 uv__async_event

  return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Thu, 13 Oct 2016 15:56:27 +0800</pubDate>
        <link>http://masutangu.com/2016/10/libuv-source-code/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/10/libuv-source-code/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>浅读 Libco</title>
        <description>&lt;p&gt;今天花了一天时间，学习了下微信的开源协程库 &lt;a href=&quot;https://github.com/tencent-wechat/libco&quot;&gt;libco&lt;/a&gt;的代码，写下来做个纪录，有部分细节代码（包括 coctx_swap.S 那段汇编）我还没读懂，以后再补充进来。&lt;/p&gt;

&lt;h2&gt;协程的原理&lt;/h2&gt;

&lt;p&gt;协程的概念和优点这里不再赘述。我们先介绍下实现协程的原理，再来看看相应的代码。&lt;/p&gt;

&lt;p&gt;协程的切换，其实就是由我们手动来管理指令执行的上下文。一般每一个协程有自己的 context_buff 来保存自己的运行上下文（寄存器和栈）。当需要挂起当前协程时，将当前的上下文保存到该协程的 context_buff，并把当前上下文重置为新的协程的 context_buff 即可。&lt;/p&gt;

&lt;h2&gt;hook 系统调用&lt;/h2&gt;

&lt;p&gt;一般会在有 IO 阻塞操作的时候做协程的切换。如何让协程的使用者无需关心这些切换的细节呢？libco 采用 hooking IO 函数的方法。将 IO 设置为非阻塞，提交给 epoll 来管理，并让出 cpu 资源，等到 epoll 事件返回后再 resume 对应的协程。下面的代码会给出相应的例子。&lt;/p&gt;

&lt;h2&gt;libco 源码&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;协程相关数据结构&lt;/p&gt;

&lt;p&gt;stCoRoutineEnv_t 管理协程的结构体，每起一个新的协程就压入 pCallStack 中，每挂起一个协程就将其踢出 pCallStack。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;struct stCoRoutineEnv_t
{
    stCoRoutine_t *pCallStack[ 128 ];
    int iCallStackSize;
    stCoEpoll_t *pEpoll;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;stCoRoutine_t 封装了协程对象，coctx_t 保存协程的 context。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;struct stCoRoutine_t
{
    stCoRoutineEnv_t *env;
    pfn_co_routine_t pfn;
    void *arg;
    coctx_t ctx;
    char cStart;
    char cEnd;
    stCoSpec_t aSpec[1024];
    char cIsMain;
    char cEnableSysHook;
    char sRunStack[ 1024 * 128 ];
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;epoll 相关数据结构&lt;/p&gt;

&lt;p&gt;管理 epoll 的结构体，pTimeout 管理 Timeout 事件。pstTimeoutList 为超时事件的列表。pstTimeoutList 和 pstActiveList 下面会看到其用法。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;struct stCoEpoll_t
{
    int iEpollFd;
    static const int _EPOLL_SIZE = 1024 * 10;
    struct stTimeout_t *pTimeout;
    struct stTimeoutItemLink_t *pstTimeoutList;  
    struct stTimeoutItemLink_t *pstActiveList;
    co_epoll_res *result; 

};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;stTimeout_t 封装了 Timeout 结构体。pItems 是一个链表数组，具体用法可以查看 &lt;code&gt;int AddTimeout( stTimeout_t *apTimeout,stTimeoutItem_t *apItem ,unsigned long long allNow )&lt;/code&gt; 函数。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;struct stTimeout_t
{
    stTimeoutItemLink_t *pItems;
    int iItemSize;
    unsigned long long ullStart;
    long long llStartIdx;
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;hooking IO&lt;/p&gt;

&lt;p&gt;下面以 read 函数为例子，看看 libco 是如何将 io 操作通过 epoll 来管理并与协程结合起来。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;ssize_t read( int fd, void *buf, size_t nbyte )
{
    HOOK_SYS_FUNC( read );
    if( !co_is_enable_sys_hook() )  // 如果没开启hook，则返回系统的 read 函数
    {
        return g_sys_read_func( fd,buf,nbyte );
    }
    rpchook_t *lp = get_by_fd( fd );

    if( !lp || ( O_NONBLOCK &amp;amp; lp-&amp;gt;user_flag ) ) 
    {
        ssize_t ret = g_sys_read_func( fd,buf,nbyte );
        return ret;
    }
    int timeout = ( lp-&amp;gt;read_timeout.tv_sec * 1000 ) 
                + ( lp-&amp;gt;read_timeout.tv_usec / 1000 );

    struct pollfd pf = { 0 };
    pf.fd = fd;
    pf.events = ( POLLIN | POLLERR | POLLHUP );

    int pollret = poll( &amp;amp;pf,1,timeout );  // 这里调用 poll 了，注意 poll 会挂起当前协程让出cpu，下面的指令需要等到该协程 resume 才会继续执行了。

    ssize_t readret = g_sys_read_func( fd,(char*)buf ,nbyte );

    return readret;

}

int poll(struct pollfd fds[], nfds_t nfds, int timeout)
{

    HOOK_SYS_FUNC( poll );

    if( !co_is_enable_sys_hook() )
    {
        return g_sys_poll_func( fds,nfds,timeout );
    }

    return co_poll( co_get_epoll_ct(),fds,nfds,timeout );  // 调用的是 co_poll
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;epoll 逻辑  &lt;/p&gt;

&lt;p&gt;最主要的代码都在 co_poll 函数和 co_eventloop 函数。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;int co_poll( stCoEpoll_t *ctx,struct pollfd fds[], nfds_t nfds, int timeout )
{
    int epfd = ctx-&amp;gt;iEpollFd;

    //1.struct change
    stPoll_t arg;
    memset( &amp;amp;arg,0,sizeof(arg) );

    arg.iEpollFd = epfd;
    arg.fds = fds;
    arg.nfds = nfds;

    stPollItem_t arr[2];
    if( nfds &amp;lt; sizeof(arr) / sizeof(arr[0]) )
    {
        arg.pPollItems = arr;
    }   
    else
    {
        arg.pPollItems = (stPollItem_t*)malloc( nfds * sizeof( stPollItem_t ) );
    }

    memset( arg.pPollItems, 0, nfds * sizeof(stPollItem_t) );

    arg.pfnProcess = OnPollProcessEvent;  // 当 epoll 事件被触发，就会调用该函数来 resume 相应的协程。
    arg.pArg = GetCurrCo( co_get_curr_thread_env() );  // pArg 保存当前的协程，pfnProcess 函数中用该字段来得到需要 resume 的协程对象。

    //2.add timeout

    unsigned long long now = GetTickMS();
    arg.ullExpireTime = now + timeout;
    int ret = AddTimeout( ctx-&amp;gt;pTimeout,&amp;amp;arg,now );  // 调用 AddTimeout，由 stCoEpoll_t 管理超时。

    //3. add epoll

    for(nfds_t i = 0; i &amp;lt; nfds; i++)
    {
        arg.pPollItems[i].pSelf = fds + i;
        arg.pPollItems[i].pPoll = &amp;amp;arg;

        arg.pPollItems[i].pfnPrepare = OnPollPreparePfn;
        struct epoll_event &amp;amp;ev = arg.pPollItems[i].stEvent;

        if( fds[i].fd &amp;gt; -1 )
        {
            ev.data.ptr = arg.pPollItems + i;
            ev.events = PollEvent2Epoll( fds[i].events );

            co_epoll_ctl( epfd,EPOLL_CTL_ADD, fds[i].fd, &amp;amp;ev );  // 添加到 epoll 中监听
        }
        //if fail,the timeout would work

    }

    co_yield_env( co_get_curr_thread_env() );  // 让出 cpu，挂起当前协程了。等到 stCoEpoll_t resume 该协程再继续执行下面的指令了

    // 下面都是清理工作 可以不用细看
    RemoveFromLink&amp;lt;stTimeoutItem_t,stTimeoutItemLink_t&amp;gt;( &amp;amp;arg );
    for(nfds_t i = 0;i &amp;lt; nfds;i++)
    {
        int fd = fds[i].fd;
        if( fd &amp;gt; -1 )
        {
            co_epoll_ctl( epfd,EPOLL_CTL_DEL,fd,&amp;amp;arg.pPollItems[i].stEvent );
        }
    }

    if( arg.pPollItems != arr )
    {
        free( arg.pPollItems );
        arg.pPollItems = NULL;
    }
    return arg.iRaiseCnt;
}

// 事件循环
void co_eventloop( stCoEpoll_t *ctx,pfn_co_eventloop_t pfn,void *arg )
{
    if( !ctx-&amp;gt;result )
    {
        ctx-&amp;gt;result =  co_epoll_res_alloc( stCoEpoll_t::_EPOLL_SIZE );
    }
    co_epoll_res *result = ctx-&amp;gt;result;

    for(;;)
    {
        int ret = co_epoll_wait( ctx-&amp;gt;iEpollFd, result, stCoEpoll_t::_EPOLL_SIZE, 1 );

        stTimeoutItemLink_t *active = (ctx-&amp;gt;pstActiveList);
        stTimeoutItemLink_t *timeout = (ctx-&amp;gt;pstTimeoutList);

        memset( timeout,0,sizeof(stTimeoutItemLink_t) );

        for(int i=0;i&amp;lt;ret;i++)
        {
            stTimeoutItem_t *item = (stTimeoutItem_t*)result-&amp;gt;events[i].data.ptr;
            if( item-&amp;gt;pfnPrepare )
            {
                item-&amp;gt;pfnPrepare( item,result-&amp;gt;events[i],active );
            }
            else
            {
                AddTail( active,item );  // 监听到的事件放到 active 链表里
            }
        }

        unsigned long long now = GetTickMS();
        TakeAllTimeout( ctx-&amp;gt;pTimeout,now,timeout );  // 超时的事件放到 timeout 链表里

        stTimeoutItem_t *lp = timeout-&amp;gt;head;
        while( lp )
        {
            lp-&amp;gt;bTimeout = true;
            lp = lp-&amp;gt;pNext;
        }

        Join&amp;lt;stTimeoutItem_t,stTimeoutItemLink_t&amp;gt;( active,timeout );  // 合并 active 和 timeout 链表

        lp = active-&amp;gt;head;
        while( lp )
        {
            PopHead&amp;lt;stTimeoutItem_t,stTimeoutItemLink_t&amp;gt;( active );
            if( lp-&amp;gt;pfnProcess )
            {
                lp-&amp;gt;pfnProcess( lp );  // 一个个拿出来处理，调用 pfnProcess 函数，即 OnPollProcessEvent 函数
            }
            lp = active-&amp;gt;head;
        }
        if( pfn )
        {
            if( -1 == pfn( arg ) )
            {
                break;
            }
        }
    }
}

void OnPollProcessEvent( stTimeoutItem_t * ap )
{
    stCoRoutine_t *co = (stCoRoutine_t*)ap-&amp;gt;pArg;  // 从上面知道，pArg 保存了该事件对应的协程
    co_resume( co );   // resume 相应的协程
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;协程的挂起和恢复&lt;/p&gt;

&lt;p&gt;协程的挂起和恢复由 stCoRoutineEnv_t 的 pCallStack 来管理。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;void co_yield_env( stCoRoutineEnv_t *env )  // 挂起当前协程，恢复其父协程
{
    stCoRoutine_t *last = env-&amp;gt;pCallStack[ env-&amp;gt;iCallStackSize - 2 ];  // last 可以认为是父协程
    stCoRoutine_t *curr = env-&amp;gt;pCallStack[ env-&amp;gt;iCallStackSize - 1 ];  // curr 为当前执行的协程
    env-&amp;gt;iCallStackSize--;
    coctx_swap( &amp;amp;curr-&amp;gt;ctx, &amp;amp;last-&amp;gt;ctx );  // 保持 curr 协程的上下文， 并恢复 last 协程的上下文
}

void co_resume( stCoRoutine_t *co )   // 恢复 co 协程
{
    stCoRoutineEnv_t *env = co-&amp;gt;env;
    stCoRoutine_t *lpCurrRoutine = env-&amp;gt;pCallStack[ env-&amp;gt;iCallStackSize - 1 ];
    if( !co-&amp;gt;cStart )
    {
        coctx_make( &amp;amp;co-&amp;gt;ctx,(coctx_pfn_t)CoRoutineFunc,co,0 );
        co-&amp;gt;cStart = 1;
    }
    env-&amp;gt;pCallStack[ env-&amp;gt;iCallStackSize++ ] = co;  // 执行协程的时候压入 pCallStack 栈中
    coctx_swap( &amp;amp;(lpCurrRoutine-&amp;gt;ctx),&amp;amp;(co-&amp;gt;ctx) );  // 恢复 co 协程的上下文
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;流程图&lt;/h2&gt;

&lt;p&gt;简化版的流程如下图所示：
&lt;img src=&quot;/assets/images/learn-libco/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 05 Oct 2016 15:59:32 +0800</pubDate>
        <link>http://masutangu.com/2016/10/learn-libco/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/10/learn-libco/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>Protobuf 编码原理</title>
        <description>&lt;p&gt;最近项目组有在用 protobuf，于是抽空读了些 protobuf 的相关资料。本文总结 protobuf 的编码原理，重点在于其如何实现版本兼容。文中样例及说明都参考了 protobuf 的&lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/encoding&quot;&gt;官方文档&lt;/a&gt;。&lt;/p&gt;

&lt;h2&gt;编码方法的介绍&lt;/h2&gt;

&lt;p&gt;要了解 protobuf 的编码方式，首先介绍下 Varint 和 ZigZag 这两种编码。&lt;/p&gt;

&lt;h3&gt;Varint&lt;/h3&gt;

&lt;p&gt;Varint 编码的优势在于值越小的数字，占用的字节更少。一般 int32 的数字都需要占用 4 个字节。使用 Varint 进行编码则有可能缩减到 1 个字节。反过来，如果是比较大的数字，则可能需要占用 5 个字节。
理解了 Varint 的目的（节省空间），来看看其原理：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Each byte in a varint, except the last byte, has the &lt;strong&gt;most significant bit (msb)&lt;/strong&gt; set – this indicates that there are further bytes to come. The lower 7 bits of each byte are used to store the two&amp;#39;s complement representation of the number in groups of 7 bits, &lt;strong&gt;least significant group first&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;即是说，Varint 中的每个字节的最高位 bit 有特殊的含义，该位为 1 表示后续的字节也是该数字的一部分，如果该位为 0 则是最后一个字节。其他的 7 个bit都用来表示数字，从最低有效字节开始。&lt;/p&gt;

&lt;p&gt;举个例子，1 的二进制表示为 0000 0001。通过 Varint 编码后的二进制表示为 0000 0001，过程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/talk-about-protobuf/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;再举个例子，300 的二进制表示为 100101100，通过 Varint 编码后的二进制表示为 10101100 00000010，详细过程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/talk-about-protobuf/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h3&gt;ZigZag&lt;/h3&gt;

&lt;p&gt;上节介绍了 Varints，我们知道 Varint 在处理小数值的数字很有效，而在处理值较大的数字则占用了多一个子节。对于负数来说，二进制最高有效位为 1，如果用 varint 来编码，无疑要占用比较多的子节。因此我们可以搭配 zigzag 来编码。&lt;/p&gt;

&lt;p&gt;ZigZag 编码将有符整型转化成无符的整型，其原理是将最高位的符号位放到最低位（－1 除外），这样大大减少了字节占用。&lt;/p&gt;

&lt;p&gt;举个例子，-2 的二进制表示为 1111 1110，用zigzag编码，－2 的绝对值为 2，二进制为 0000 0010，将符号位放到最低位，则变成 0000 0011。&lt;/p&gt;

&lt;p&gt;公式如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;32 位整型：(n &amp;lt;&amp;lt; 1) ^ (n &amp;gt;&amp;gt; 31)&lt;/li&gt;
&lt;li&gt;64 位整型：(n &amp;lt;&amp;lt; 1) ^ (n &amp;gt;&amp;gt; 63)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Note that the second shift – the (n &amp;gt;&amp;gt; 31) part – is an arithmetic shift. So, in other words, the result of the shift is either a number that is all zero bits (if n is positive) or all one bits (if n is negative).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;注意这里的位移操作符。如果在位移运算符左边的变量是有符号数，编译产生的汇编指令是&lt;strong&gt;算术位移指令&lt;/strong&gt;，如果该变量是无符号数，编译产生的汇编指令则是&lt;strong&gt;逻辑位移指令&lt;/strong&gt;。对于左移，它们都一样，整个二进制右移，低位补 0；右移则有所区分，&lt;strong&gt;算数右移左边补最高符号位，逻辑位移左边补 0&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;举个例子，-2 经过 ZigZag 编码后为 3，过程如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/talk-about-protobuf/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Protobuf 的编码原理&lt;/h2&gt;

&lt;h3&gt;版本兼容&lt;/h3&gt;

&lt;p&gt;Protobuf 支持向前向后兼容。向后兼容即升级的解码程序能够正确解析旧版本协议的数据，向前兼容则指旧版本的解码程序能够正确解析新版本协议的数据。如果新的协议新增了字段，旧版本的解析程序是如何自动跳过新字段的呢？&lt;/p&gt;

&lt;p&gt;协议，即通信双方约定好的规则。收到数据时，可以根据约定好的规则进行解包。假设我们使用简单粗暴的编解码方法，将结构体定义的成员按类型依此打解包。如下图，我们约定好的协议包括三个字段，类型都为 int32，那解码函数将从接收到的字节流中依次取出 4 个字节并按整型解析。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/talk-about-protobuf/illustration-4.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果发送方升级了协议，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/talk-about-protobuf/illustration-5.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;很明显，如果旧的解码程序还是按照依次取出 3 个 int32 去解析的话，毫无疑问是错误的（会把结构体 old_message 的成员 d 的值解析成 0x1a )。如果有办法能跳过新增字段，就可以做到兼容，即旧的解码程序能正确解析出旧协议定义的字段，新增字段一律忽略。&lt;/p&gt;

&lt;p&gt;Protobuf 采用的方法很简单也很实用，把 tag 和其类型一起打进去字节流，解码程序只要解析出不认识的 tag，就能知道该字段是新协议定义的，再通过其类型可以推断出该字段内容的长度，就能正确的跳过这部分 buffer，继续解析下一个字段。如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/talk-about-protobuf/illustration-6.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当旧的解码程序解析到 tag 为 3 时，发现在旧协议里找不到该 tag，又从其类型 int 64 知道该 tag 的值占了 8 个字节，于是他跳过这 8 个字节，继续解析剩下的字节流。&lt;/p&gt;

&lt;h3&gt;实现&lt;/h3&gt;

&lt;p&gt;Protobuf 的实现中，将每个字段的 key 设为 varint 编码后的 &lt;code&gt;(tag number &amp;lt;&amp;lt; 3) | wire_type&lt;/code&gt;。即 key 的最低三位表示字段类型，将 key 右移三位后的值表示 tag number。wire_type 如下表格所示：&lt;/p&gt;

&lt;table&gt;&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;th&gt;Used For&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Varint&lt;/td&gt;
&lt;td&gt;int32, int64, uint32, uint64, sint32, sint64, bool, enum&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;64-bit&lt;/td&gt;
&lt;td&gt;fixed64, sfixed64, double&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Length-delimited&lt;/td&gt;
&lt;td&gt;string, bytes, embedded messages, packed repeated fields&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Start group&lt;/td&gt;
&lt;td&gt;groups (deprecated)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;End group&lt;/td&gt;
&lt;td&gt;groups (deprecated)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;32-bit&lt;/td&gt;
&lt;td&gt;fixed32, sfixed32, float&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p&gt;如果是 Length-delimited Type，意味着长度不定，这时还需要在 key 后面多写入长度信息（用 varint 编码）。&lt;/p&gt;

&lt;p&gt;举个例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;message Test2 {
  required string b = 2;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;将 b 的值设为 &amp;quot;testing&amp;quot;，protobuf 编码后的字节流为&lt;code&gt;12 07 74 65 73 74 69 6e 67&lt;/code&gt; key 为 0x12，可以算出 tag 值为 2（0x12 &amp;gt;&amp;gt; 3), type 为 2 ( 0x12 取最低三位)。下个字节为 0x07 ，该字节表示长度，即长度为 7，因此后续的 7 个字节都为该 tag 的值。&lt;/p&gt;

&lt;p&gt;另外 protobuf 还定义了 sint32/sint64 类型。sint32/sin64 类型专门用于编码负数。如果使用 int32/int64 来编码负数， 通过 varint 编码后的 buffer 长达 5/10 个字节。（int32 时占用5个字节，int64时占用10个字节，因为负数的最高位为1，会被当作非常大的整数处理）。&lt;/p&gt;

&lt;p&gt;而 sint32/sint64 类型的值会先经过 zigzag 编码，转换成无符号整数，再采用 varint 编码，可以大大减少编码后占用的字节数。&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If you use int32 or int64 as the type for a negative number, the resulting varint is always ten bytes long – it is, effectively, treated like a very large unsigned integer. If you use one of the signed types, the resulting varint uses ZigZag encoding, which is much more efficient.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3&gt;使用建议&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;常用消息字段(尤其是 repeated 字段)的 tag number 尽量分配在 1 ~ 15 之间。tag number 超过 16，key 的编码将占用多一个字节&lt;/li&gt;
&lt;li&gt;尽可能多的（全部）使用 optional 字段&lt;/li&gt;
&lt;li&gt;不能修改字段的 tag number&lt;/li&gt;
&lt;li&gt;不能增删任何 required 字段&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 03 Sep 2016 00:44:24 +0800</pubDate>
        <link>http://masutangu.com/2016/09/talk-about-protobuf/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/09/talk-about-protobuf/</guid>
        
        
        <category>协议设计</category>
        
      </item>
    
      <item>
        <title>简单异步应用框架的实现</title>
        <description>&lt;p&gt;两年前刚进公司的时候，第一次接触了异步框架，那时还处于懵懵懂懂的状态。最近换了组，接触到另外一种实现的异步框架，这次有了一定的积累后，对异步框架的设计也有了更多的理解。刚好最近自己基于 libuv 造了个简单的轮子 &lt;a href=&quot;https://github.com/Masutangu/SAF&quot;&gt;saf (Simple Async Framework)&lt;/a&gt;，趁此机会和大家聊聊异步框架的设计思想和实现。&lt;/p&gt;

&lt;h1&gt;异步框架设计思想&lt;/h1&gt;

&lt;h2&gt;服务器模型&lt;/h2&gt;

&lt;p&gt;先来看看传统的服务器模型，如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/simple-async-framework/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;一般来说，服务器端可以分为三层：&lt;strong&gt;接入层&lt;/strong&gt;，&lt;strong&gt;逻辑层&lt;/strong&gt;，&lt;strong&gt;数据层&lt;/strong&gt;。接入层负责客户端的接入，逻辑层则实现业务逻辑，数据层就是数据的存储。&lt;/p&gt;

&lt;p&gt;简单来说，逻辑层做的事情无非就是解析客户端的请求包，写入数据到数据层或从数据层读取数据，再组装回包发送给客户端。&lt;/p&gt;

&lt;p&gt;我们拿微博做例子，用户登录微博，客户端发起拉取首页的请求，server 首先解析客户端请求，拿到用户 id，再根据用户 id 到数据层查询以下数据并拼装回包发回给客户端：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;关注数&lt;/li&gt;
&lt;li&gt;粉丝数&lt;/li&gt;
&lt;li&gt;微博数&lt;/li&gt;
&lt;li&gt;个人简介，包括头像&lt;/li&gt;
&lt;li&gt;微博时间轴，即关注的人最近发的微博&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;同步 vs 异步&lt;/h2&gt;

&lt;p&gt;继续上面微博的例子，我们假设微博时间轴采用拉的方式去获取。
同步的 server，实现的逻辑如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/simple-async-framework/illustration-2.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;如果同步的 server 是单线程，那每次发送请求到数据层查询数据时都会阻塞，在收到数据层的回包前 server 做不了其他事情，CPU 在等待期间空转，非常浪费资源。&lt;/p&gt;

&lt;p&gt;异步 server 则不会有这个烦恼，当 server 向数据层发送请求时会立即返回，此时 server 可以处理其它客户端请求，直到数据层返回所请求的数据，通知到 server，server 再继续之前的业务逻辑。流程图大致如下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/simple-async-framework/illustration-3.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们再仔细看上面的流程图，可以发现除了拉取微博时间轴需要依赖关注人列表之外，其它数据查询都互不依赖。因此可以把流程优化下：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/simple-async-framework/illustration-4.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;通过这样的优化，耗时从 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;关注数请求耗时 + 粉丝数请求耗时 + 微博数请求耗时 + 个人简介耗时 + 时间轴耗时&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;缩减到 &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;MAX(关注数请求耗时，粉丝数请求耗时，微博数请求耗时，个人简介耗时) + 时间轴耗时&lt;/strong&gt;。&lt;/p&gt;

&lt;h2&gt;模型抽象化&lt;/h2&gt;

&lt;p&gt;通过上面的例子，来讲讲如何将上述异步处理逻辑抽象化。
我们可以把业务逻辑以&lt;strong&gt;状态（state）&lt;/strong&gt;为单位来划分，如下图。&lt;strong&gt;状态与状态之间是串行的&lt;/strong&gt;，即你必须执行完一个状态，才会跳转到下一个状态。比如我们必须先拉取关注列表，才能根据关注列表去拉取时间轴。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/simple-async-framework/illustration-5.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;而一个状态内可以有很多&lt;strong&gt;动作（action）&lt;/strong&gt;，&lt;strong&gt;一个状态内的动作是互相不依赖的，即可以并行执行&lt;/strong&gt;，如下图。如我们可以同时发请求拉去关注数，粉丝数，微博数，因为他们之间是互相独立没有依赖的。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/simple-async-framework/illustration-6.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;h1&gt;异步框架的实现&lt;/h1&gt;

&lt;p&gt;讲完了概念，开始来实践。linux 下有 epoll 模型，另外还有大名鼎鼎的 libuv 提供了跨平台的异步 IO。那接下来结合我自己造的轮子，谈谈如何基于 epoll 或 libuv 来实现一个异步框架。&lt;/p&gt;

&lt;h2&gt;状态保存&lt;/h2&gt;

&lt;p&gt;无论是函数调用，或者线程切换，都会保存上下文，等到函数调用返回或线程切回来时，才能继续处理之前未完成的逻辑。而我们的异步模型（其实就是状态机），也是类似的道理，我们需要在请求发送时保存好上下文，才能在收到回包时继续之前的逻辑往下走。
saf 是基于 libuv 的，因此我使用 libuv 的 handle 结构体的 data 字段来保存上下文。如果是直接使用 epoll 来实现异步server，则可以用 fd 来绑定上下文（全局的 map，key 为 fd，value 为上下文信息）。&lt;/p&gt;

&lt;h2&gt;消息透传&lt;/h2&gt;

&lt;p&gt;既然各个状态是有依赖关系的，那就得有一个消息（message）实体贯穿整个处理流程。通过这个消息实体来传递各个状态所需要的信息。这也是为什么 saf 中 action 和 state 的接口都有一个 msg 参数的原因（见下节&lt;strong&gt;接口设计&lt;/strong&gt;）。&lt;/p&gt;

&lt;h2&gt;接口设计&lt;/h2&gt;

&lt;p&gt;封装一个异步框架，意味着对于框架使用者来说其无需关心网络收发包的细节，只需关心自身业务逻辑的实现。那我们在设计接口上就需要屏蔽这些细节。&lt;/p&gt;

&lt;p&gt;既然要对使用者屏蔽收发包细节，表明收包和发包的回调都由框架来控制。因此我们只需要暴露打包请求包和解包回包的接口给使用者去实现。框架调用使用者实现的打包接口后，将打好的 buffer 发送出去，在收到回包之后，再调用使用者实现的解包接口来处理回包。&lt;/p&gt;

&lt;p&gt;在 saf 的接口设计中，我尽量保持接口命名的统一，&lt;code&gt;prepareProcess&lt;/code&gt; 表示在执行前的预处理工作，&lt;code&gt;afterProcess&lt;/code&gt; 表示执行完后的后续处理工作。下面可以看到在不同的模块中，&lt;code&gt;prepareProcess&lt;/code&gt; 和 &lt;code&gt;afterProcess&lt;/code&gt; 的功能略有不同。&lt;/p&gt;

&lt;h3&gt;消息类&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;//msg.h

class Msg {
public:
    virtual ~Msg() {}
};
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;如上所述，消息用于状态之间传递依赖的信息，由业务自行继承添加所需成员。&lt;/p&gt;

&lt;h3&gt;Handler 类&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;    //handler.h

    /*
     * 解析客户端请求包
     * 返回 &amp;gt; 0 表示收包不完整
     * 返回 0 表示解析成功
     * 返回 &amp;lt; 0 表示解包失败, server将会杀掉客户端连接
     */
    virtual int prepareProcess(char* buf, unsigned int len, Msg* msg) = 0;

    /*
     * 打包客户端回包到输入 buf 中,len 为输入 buf 长度
     * 返回 &amp;gt; 0 表示 buf 不够, len 为实际需要的 buf 长度
     * 返回 0 表示打包成功, len 为 buf 的实际长度
     * 返回 &amp;lt; 0 表示打包失败, server将会杀掉客户端连接
     */
    virtual int afterProcess(char* buf, unsigned int&amp;amp; len, Msg* msg) = 0;

    /*
     * 创建该 handler 的 msg
     */
    virtual Msg* createMsg() = 0;
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;Handler 类对应客户端请求的处理流程。业务继承 Handler 基类，实现请求包和回包的打解包接口以及创建业务消息的接口。&lt;/p&gt;

&lt;p&gt;在 Handler 的构造函数添加该 Handler 包含的 State。在收到客户端请求后，框架调用相应的 Handler 的 &lt;code&gt;prepareProcess&lt;/code&gt; 接口对客户端请求进行解包。然后依次执行各个 State，全部 State 执行完成后，框架调用该 Handler 的 &lt;code&gt;afterProcess&lt;/code&gt; 将回包打包到传入的 buffer 参数，再由框架将该 buffer 发送回客户端。&lt;/p&gt;

&lt;h3&gt;State 类&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;    // state.h

    /*
     * 执行 state 包含的 action 前, 框架会调用该函数, 可以做预处理工作
     * 返回 0 表示成功
     * 返回 != 0 表示失败
     */
    virtual int prepareProcess(Msg* msg) { return 0; };
    /*
     * state 包含的 action 都执行完时, 框架会调用该函数,可以做一些后续处理工作
     * 返回 0 表示成功
     * 返回 != 0 表示失败
     */
    virtual int afterProcess(Msg* msg) { return 0; };
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;State 类对应上面&lt;strong&gt;模型抽象化&lt;/strong&gt;小节的&lt;strong&gt;状态&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;在 State 的构造函数添加该 State 包含的 Action。State 执行前，框架调用该 State 的 &lt;code&gt;prepareProcess&lt;/code&gt; 接口，使用者可以在该接口做些预处理工作。当 State 执行完成后，框架调用该 State 的 &lt;code&gt;afterProcess&lt;/code&gt; 接口。&lt;/p&gt;

&lt;h3&gt;Action 类&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;    //action.h 

    /*
     * 设置 action 的目的 ip，端口和通信协议（目前只支持tcp） 
     */
    void setActionInfo(const std::string&amp;amp; ip, int port, int protocol);

    /*
     * 设置 action 的超时时间，单位为毫秒。 &amp;lt;=0 为永不超时
     */
    void setTimeout(unsigned int timeout) { m_timeout = timeout; }  

    /*
     * 打包 Action 请求包到输入 buf 中, len 为输入 buf 的长度
     * 返回 0 表示打包成功, len 为实际需要的 buf 长度
     * 返回 &amp;gt; 表示 buf 不够, len 为实际需要的 buf 长度
     * 返回 &amp;lt; 0 表示失败
     */
    virtual int prepareProcess(char* buf, unsigned int&amp;amp; len, Msg* msg) = 0;

    /*
     * 解析 Action 回包
     * 返回 0 表示解析回包成功
     * 返回 &amp;lt; 0 表示出错
     * 返回 &amp;gt; 0 表示收包未完整
     */
    virtual int afterProcess(char* buf, unsigned int len, Msg* msg) = 0;
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;Action 类对应上面&lt;strong&gt;模型抽象化&lt;/strong&gt;小节的&lt;strong&gt;动作&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Action 执行前，框架调用该 Action 的 &lt;code&gt;prepareProcess&lt;/code&gt; 接口，将 Action 的请求包打包到传入的 buffer 参数，当收到 Action 的回包后，框架会调用 Action 的 &lt;code&gt;afterProcess&lt;/code&gt; 接口，将回包解包。&lt;/p&gt;

&lt;h3&gt;REGISTER_HEADER_PARSER&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;REGISTER_HEADER_PARSER&lt;/code&gt; 宏用于注册解析请求包头函数。&lt;/p&gt;

&lt;h3&gt;REGISTER_HANDLER&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;REGISTER_HANDLER&lt;/code&gt; 宏用于注册请求对应的 handler 类&lt;/p&gt;

&lt;h2&gt;状态机逻辑&lt;/h2&gt;

&lt;p&gt;接下来看看 saf 如何将 handler／state／action 串联起来（代码有所简化）&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;    //handler.cpp
    /* 
     * 主逻辑，ClientContext 保存了客户端会话的上下文
     * 其 m_state_idx 成员表示当前所属的状态 id
     * m_action_idx 成员表示处于当前所属状态的动作id
     * m_msg 即业务定义的消息类，被透传给 state 和 action 中
     */  
    void Handler::process(ClientContext* c_ctx) {
        if (c_ctx-&amp;gt;m_state_idx &amp;lt; m_state_list.size()) {
            State* state = m_state_list[c_ctx-&amp;gt;m_state_idx++];
            // 执行 state 前, 将 action_idx 置 0
            c_ctx-&amp;gt;m_action_idx = 0;
            // 调用 state 的 prepareProcess 接口
            state-&amp;gt;prepareProcess(c_ctx-&amp;gt;m_msg);
            // 开始执行该state
            state-&amp;gt;process(c_ctx);   
        } else {
            static char buf[DEFAULT_BUF_SIZE];
            char* actual_buf = buf;
            unsigned int actual_len = DEFAULT_BUF_SIZE;
            // 调用 handler 的 afterProcess 接口，打包回包到 actual_buf 中
            afterProcess(actual_buf, actual_len, c_ctx-&amp;gt;m_msg);
            // 发送回包给客户端
            c_ctx-&amp;gt;sendResponse(actual_buf, actual_len);
        }
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;    //state.cpp

    /* 
     * state 处理逻辑
     */
    void State::process(ClientContext* c_ctx) {
        // 如果没有action,直接finish
        if (m_action_list.size() == 0) {
            finish(c_ctx);
            return;
        }

        static char buf[DEFAULT_BUF_SIZE];
        char* actual_buf = NULL;
        unsigned int actual_len = 0; // buf 的实际长度
        int ret = 0;

        // 执行该 state 下所有 action 
        for(unsigned int i = 0; i &amp;lt; m_action_list.size(); i++) {
            Action* action = m_action_list[i];
            actual_len = DEFAULT_BUF_SIZE;
            actual_buf = buf;
            // 调用 action 的 prepareProcess 接口，打包 action 的请求包到 actual_buf 中
            action-&amp;gt;prepareProcess(actual_buf, actual_len, c_ctx-&amp;gt;m_msg);
            // 执行该 action
            c_ctx-&amp;gt;processAction(action, actual_buf, actual_len);
        }
    }

    // action 完成后回调该接口，如果所有action都完成，则调用下面的 finish 接口
    void State::finishAction(ClientContext* c_ctx) {
        printf(&amp;quot;finishAction\n&amp;quot;);
        c_ctx-&amp;gt;m_action_idx++;
        if (c_ctx-&amp;gt;m_action_idx &amp;gt;= m_action_list.size()) {
            finish(c_ctx);
        }
    }

    // 调用 state 所属的 handler 的 process 函数
    void State::finish(ClientContext* c_ctx) {
        afterProcess(c_ctx-&amp;gt;m_msg);
        m_handler-&amp;gt;process(c_ctx);
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;    //ClientContext.cpp

    /*
     * action 收到回包后的回调
     */
    static void recvActionRsp(uv_stream_t *server, ssize_t nread, const uv_buf_t *buf) {
        // data 字段保存了 action 的上下文
        ActionContext* a_ctx = (ActionContext*) server-&amp;gt;data;
        a_ctx-&amp;gt;recv_buf.append(buf-&amp;gt;base, nread);
        // action 的上下文中保存了客户端请求的上下文
        ClientContext* c_ctx = a_ctx-&amp;gt;c_ctx;
        // 调用 action 的 afterProcess 接口
        int ret = a_ctx-&amp;gt;action-&amp;gt;afterProcess(a_ctx-&amp;gt;recv_buf.data(), a_ctx-&amp;gt;recv_buf.len(), c_ctx-&amp;gt;m_msg);
        // 通知 action 所属的 state 该 action 完成了
        a_ctx-&amp;gt;action-&amp;gt;m_state-&amp;gt;finish(a_ctx-&amp;gt;c_ctx);
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;样例&lt;/h2&gt;

&lt;p&gt;以下是 saf 的一个简单的 &lt;a href=&quot;https://github.com/Masutangu/SAF/blob/master/sample.cpp&quot;&gt;demo&lt;/a&gt;。代码仅说明用，所以比较简单粗暴。该 server 的所有请求都由 myHandler 来处理，myHandler 包含一个状态 myState1。myState1 包含一个 Action, 该 Action 将客户端请求包拷贝并通过 tcp 发送给 127.0.0.1:7000 的服务，接收到回包后再把回包原样发回给客户端。  &lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;//
// Created by Masutangu on 16/8/9.
//

#include &amp;quot;saf/header.h&amp;quot;

#include &amp;lt;cstring&amp;gt;

using namespace saf;

const int BUF_SIZE = 1024;

class myMsg: public Msg {
public:
    char readbuf[BUF_SIZE];
    char writebuf[BUF_SIZE];
};

class myAction: public Action {
public:
    int prepareProcess(char* buf, unsigned int&amp;amp; len, Msg* msg);
    int afterProcess(char* buf, unsigned int len, Msg* msg);
};

int myAction::prepareProcess(char* buf, unsigned int&amp;amp; len, Msg* msg) {
    myMsg* my_msg = static_cast&amp;lt;myMsg*&amp;gt; (msg);
    printf(&amp;quot;myAction prepareProcess, data: %s\n&amp;quot;, my_msg-&amp;gt;readbuf);
    if (len &amp;gt;= BUF_SIZE) {
        memcpy(buf, my_msg-&amp;gt;readbuf, BUF_SIZE);
        return 0;
    } else {
        len = BUF_SIZE;
        return BUF_SIZE;
    }

}

int myAction::afterProcess(char* buf, unsigned int len, Msg* msg) {
    printf(&amp;quot;myAction afterProcess: %s\n&amp;quot;, buf);
    myMsg* my_msg = static_cast&amp;lt;myMsg*&amp;gt; (msg);
    memcpy(my_msg-&amp;gt;writebuf, buf, len &amp;lt; BUF_SIZE ? len:BUF_SIZE);
    return 0;
}

class myState1: public State {
public:
    myState1();
};

myState1::myState1() {
    myAction* action = new myAction;
    action-&amp;gt;setActionInfo(&amp;quot;127.0.0.1&amp;quot;, 7000, 0); //设置action的ip和端口
    addAction(action);
}

class myHandler: public Handler {
public:
    myHandler();
    Msg* createMsg();
    int prepareProcess(char* buf, unsigned int len, Msg* msg);
    int afterProcess(char* buf, unsigned int&amp;amp; len, Msg* msg);

};

Msg* myHandler::createMsg() {
    return new myMsg();
}

myHandler::myHandler() {
    myState1* state1 = new myState1();
    addState(state1);

}

int myHandler::prepareProcess(char* buf, unsigned int len, Msg* msg) {
    printf(&amp;quot;handler: prepareProcess len=%d\n&amp;quot;, len);
    myMsg* my_msg = static_cast&amp;lt;myMsg*&amp;gt; (msg);
    memcpy(my_msg-&amp;gt;readbuf, buf, len);
    return 0;
}

int myHandler::afterProcess(char* buf, unsigned int&amp;amp; len, Msg* msg) {
    myMsg* my_msg = static_cast&amp;lt;myMsg*&amp;gt; (msg);
    if (len &amp;gt;= 1024) {
        memcpy(buf, my_msg-&amp;gt;writebuf, 1024);
        return 0;
    } else {
        len = 1024;
        return 1;
    }
}

int parseReq(char* buf, unsigned int len) {
    return 1; // 该请求的类型为 1，由 myHandler 处理
}

int main() {
    REGISTER_HANDLER(1, myHandler);  // 请求类型为 1 的由 myHandler 类处理
    REGISTER_HEADER_PARSER(parseReq); // 请求包头由 parseReq 函数解析

    AsyncServer server = AsyncServer();
    server.setBindAddress(&amp;quot;0.0.0.0&amp;quot;, 8000); // 监听 8000 端口
    server.run();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h1&gt;总结&lt;/h1&gt;

&lt;p&gt;由于时间和能力有限，saf 目前来说非常简陋，也没有经过严格的测试。对于一个框架来说，要做的事情还有很多，比如日志模块的完善、性能分析和优化。不过，&lt;strong&gt;done is better than perfect&lt;/strong&gt;. 最后，如有问题或意见，欢迎留言或者 email 我，也欢迎转载分享～&lt;/p&gt;
</description>
        <pubDate>Tue, 30 Aug 2016 08:14:24 +0800</pubDate>
        <link>http://masutangu.com/2016/08/simple-async-framework/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/08/simple-async-framework/</guid>
        
        
        <category>个人项目</category>
        
      </item>
    
      <item>
        <title>工作两年记</title>
        <description>&lt;p&gt;转眼间，我也已经工作了快两年了。两年，在互联网行业，是一个尴尬的时间点。一方面，你不再是一个新人，意味着你的潜力已经渐渐被挖掘得差不多了。另一方面，你又还没完全成长，你会承担一些责任，但也许还没办法掌控全局，做到游刃有余。&lt;/p&gt;

&lt;p&gt;回想起刚入职，由于自己完全没有工程经验，心里相当忐忑。机缘巧合，leader 给我分配的第一个任务是爬虫。Python 对于新手来说相当的友好，我很快就上手并能够做出一些简单的成果。之后又熟悉了 Django，了解 MVC。之后再尝试空闲时间读一些库的源码，并最终自己用 Python 写了一个开源项目 &lt;a href=&quot;https://github.com/Masutangu/Elric&quot;&gt;Elric&lt;/a&gt;（基于 Apscheduler ）。这些经历极大得提升了我的自信心，也锻炼了我的代码能力和少部分的架构能力。&lt;/p&gt;

&lt;p&gt;第二年的时候，我给自己的计划是多学习新的知识点，重在求广。因此我学了 Golang，写了个小项目 &lt;a href=&quot;https://github.com/Masutangu/SuperScripter&quot;&gt;SuperScripter&lt;/a&gt; 练手（最终这个项目的进化版用在了工作中）；学习了 iOS，写了一个简单的 &lt;a href=&quot;https://github.com/Masutangu/ToDo&quot;&gt;ToDoList&lt;/a&gt;, 对客户端有了些了解；读了 NSQ 的源码，大致了解消息队列的实现；还读了一段时间的非技术类的文章（读书笔记：&lt;a href=&quot;http://masutangu.com/2015/12/dewdrop-note-1/&quot;&gt;水滴石穿&lt;/a&gt;），希望自己的思维可以更宽广，可惜后来没坚持下去。&lt;/p&gt;

&lt;p&gt;到了今年的年初，我感觉自己在技术上到了一个瓶颈，对于职业发展也有些迷茫。总会觉得自己在原地踏步，会的更熟练，不会的还是不会，让我有些急躁，心情也不是特别好。有一阵子我每天一闲下来就会想：“到底怎么做才能更进一步？”，始终绕不出这个困扰。后来我发现想要驱除内心的恐慌，取得让自己满意的进步，唯一的方法就是花时间做一些更深入的研究，而不是浮在表面。浮在表面让我非常没有安全感，如果你很快就能学会的，别人也可以。所以我不再把重心放在新知识上，打算打牢基础，并在自己感兴趣的领域做些探索。&lt;/p&gt;

&lt;p&gt;想清楚后，我规划了接下来这一年的学习路线：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;回归语言的本质&lt;/p&gt;

&lt;p&gt;学再多语言，不深入思考的话，也只是学到皮毛。不应该止步于会用，而是要深入到编程语言的设计哲学。我希望之后在这方面有一些理解。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;网络框架读源码，造轮子&lt;/p&gt;

&lt;p&gt;在公司工作，都有了现成的框架。就算自己做项目，也有很多开源框架可以使用。和编程语言类似，我希望自己能够再深入些，比如读读协程／异步／同步框架的代码，比较他们的适用场景，最好是能够自己造一些轻量级的轮子加深理解。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;巩固操作系统/编译原理/网络基础&lt;/p&gt;

&lt;p&gt;看书学习理论，造轮子加深理解。也许工作中 90% 的情况下不需要这些知识，但总会有 10% 的概率会出各种奇奇怪怪的问题，这时就是考验基本功的时候了。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我觉得第两年到第三年，是一个关键点。这一年，我希望兑现全部潜力，大幅度提升自己的能力，不仅是代码能力、架构能力，还有工程素养。我希望三年级的我，可以扛起重任。就像 NBA 的球员一样，经历了两年的磨砺，三年级，也该去争取进入全明星，争取一阵，争取属于自己的总冠军了！&lt;/p&gt;
</description>
        <pubDate>Wed, 13 Jul 2016 21:24:34 +0800</pubDate>
        <link>http://masutangu.com/2016/07/conclusion-of-two-years/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/07/conclusion-of-two-years/</guid>
        
        
        <category>工作</category>
        
      </item>
    
      <item>
        <title>Elric 使用手册</title>
        <description>&lt;p&gt;这篇文章正式介绍下我之前用 Python 实现的分布式任务框架 &lt;a href=&quot;https://github.com/Masutangu/Elric&quot;&gt;Elric&lt;/a&gt;，包括其API，架构，周边能力以及实现细节。&lt;/p&gt;

&lt;p&gt;读者可以先阅读之前的这篇文章《&lt;a href=&quot;http://masutangu.com/2015/08/elric-distributed-job-scheduler-by-python/&quot;&gt;Python实现的分布式任务调度系统&lt;/a&gt;》来了解Elric的起源和早期设计的思想。&lt;/p&gt;

&lt;h1&gt;一. 简介&lt;/h1&gt;

&lt;p&gt;Elric 是一个 Python 实现的简单的分布式任务框架。Master-Worker 架构，Worker 向 Master 提交任务和执行 Master 下发的任务。支持多种任务类型：即时任务，周期任务，crontab 任务和定时任务。
其实现参考了 &lt;a href=&quot;https://apscheduler.readthedocs.io/en/latest/&quot;&gt;Apscheduler&lt;/a&gt;，Elric 的部分逻辑参考了 Apscheduler， 部分代码（trigger）取自 Apscheduler。&lt;/p&gt;

&lt;h1&gt;二. API&lt;/h1&gt;

&lt;h2&gt;Master&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;初始化和启动 Master&lt;/p&gt;

&lt;p&gt;启动 Master 很简单，样例代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;import os
os.environ.setdefault(&amp;#39;ELRIC_SETTINGS_MODULE&amp;#39;, &amp;#39;settings&amp;#39;)  # 设置 settings.py

from elric.master.rqextend import RQMasterExtend

rq_Master = RQMasterExtend()
rq_Master.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Worker&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;初始化和启动 Worker&lt;/p&gt;

&lt;p&gt;Worker 的构造函数稍微复杂一些：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;def __init__(self, name, listen_keys=None, Worker_num=2, timezone=None, logger_name=&amp;#39;elric.Worker&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;name：Worker 的名字，不同用途的 Worker 应该取不同的名字。&lt;/li&gt;
&lt;li&gt;listen_keys：Worker 监听的任务队列名，类型为 list。&lt;/li&gt;
&lt;li&gt;Worker_num：Worker 的进程池数。&lt;/li&gt;
&lt;li&gt;timezone：时区，默认为 local。&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;启动 Worker 将会开始从监听的任务队列里取任务来执行，初始化和启动 Worker 的样例代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;import os
os.environ.setdefault(&amp;#39;ELRIC_SETTINGS_MODULE&amp;#39;, &amp;#39;settings&amp;#39;)  # 设置 settings.py

from elric.worker.rqueue import RQWorker

rq_Worker = RQWorker(name=&amp;#39;test&amp;#39;, listen_keys=[&amp;#39;job1&amp;#39;, &amp;#39;job2&amp;#39;])
rq_Worker.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上述代码初始化一个名字为 test 的 Worker，它将从 job1，job2 这两个任务队列中取下任务来执行。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;提交任务&lt;/p&gt;

&lt;p&gt;提交任务的接口如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;def submit_job(self, func, job_key, args=None, kwargs=None, trigger=None, job_id=None,
               replace_exist=False, need_filter=False, **trigger_args)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;ul&gt;
&lt;li&gt;func：提交该任务需要执行的函数。&lt;/li&gt;
&lt;li&gt;job_key：该任务将提交的任务队列名。&lt;/li&gt;
&lt;li&gt;args：提交的函数执行所需要的位置参数。&lt;/li&gt;
&lt;li&gt;kwargs：提交的函数执行所需要的命名参数。&lt;/li&gt;
&lt;li&gt;trigger：提交任务的执行时间信息，date 为定时任务，cron 为 crontab 任务、interval 为周期任务，为空则为即时任务。&lt;/li&gt;
&lt;li&gt;job_id：提交任务的id，用于调试和去重。如果没有提供将自动生成一个随机id。&lt;/li&gt;
&lt;li&gt;need_filter：是否去重。Master 使用 (job_key，job_id) 唯一标记一个任务。如果 need_filter 为 True，submit_job 时会 Master 会检查去重模块 dupefilter 是否有（job_key，job_id）任务成功执行的记录，如果已存在则被过滤。该特性主要用于爬虫。&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;去重&lt;/h2&gt;

&lt;p&gt;Elric 支持任务去重，通常这个特性用于爬虫，比如爬取过的页面无需再次爬取时，可以通过设置 need_filter 为 True 来实现：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;blog_url = &amp;#39;http://masutangu.com/&amp;#39;
rq_worker = RQWorker(name=&amp;#39;crawler&amp;#39;, listen_keys=[&amp;#39;crawl_blog&amp;#39;, ])
rq_worker.submit_job(crawl_blog, &amp;#39;crawl_blog&amp;#39;, args=[blog_url], job_id=blog_url)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;任务执行完成后，Master 的 dupefilter 模块会标记（&amp;#39;crawl_blog&amp;#39;，&amp;#39;&lt;a href=&quot;http://masutangu.com/&quot;&gt;http://masutangu.com/&lt;/a&gt;&amp;#39; ）任务已经执行成功。之后如果 Master 再次接收到任务，会到 dupefilter 模块查询是否有相应的记录，如果存在则直接过滤该任务，不再下发。&lt;/p&gt;

&lt;h2&gt;配置&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/Masutangu/Elric/blob/master/settings.py&quot;&gt;settings.py&lt;/a&gt; 文件的配置信息如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;DISTRIBUTED_LOCK_CONFIG：Master分布式锁的相关配置。&lt;/li&gt;
&lt;li&gt;JOB_QUEUE_CONFIG：任务队列的相关配置。&lt;/li&gt;
&lt;li&gt;FILTER_CONFIG：去重的相关配置。&lt;/li&gt;
&lt;li&gt;JOB_STORE_CONFIG：任务存储的相关配置。&lt;/li&gt;
&lt;li&gt;LOGGINGF_CONFIG：日志的相关配置。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;配置由环境变量设置，可以在代码中使用&lt;code&gt;os.environ.setdefault(&amp;#39;ELRIC_SETTINGS_MODULE&amp;#39;, &amp;#39;settings&amp;#39;)&lt;/code&gt;，或通过命令行设置环境变量&lt;code&gt;export ELRIC_SETTINGS_MODULE=settings&lt;/code&gt;来指定使用的settings.py，方便管理。&lt;/p&gt;

&lt;h2&gt;样例代码&lt;/h2&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;import os
os.environ.setdefault(&amp;#39;ELRIC_SETTINGS_MODULE&amp;#39;, &amp;#39;settings&amp;#39;)  # 设置 settings.py

from elric.worker.rqueue import RQWorker

def wapper_job():
    print &amp;#39;run first job&amp;#39;
    rq_Worker.submit_job(nest_job, &amp;#39;job1&amp;#39;, args=[&amp;#39;hi i am nested job&amp;#39;])

def nest_job(welcome):
    print welcome

def test_job(language=None):
    print &amp;#39;my favorite language is {language}&amp;#39;.format(language=language)

def test_date_job():
    print &amp;#39;hello i am date job&amp;#39;

def test_cron_job():
    print &amp;#39;hello i am crontab job&amp;#39;

if __name__ == &amp;#39;__main__&amp;#39;:
    # 初始化名字为 test 的 Worker ，监听 &amp;#39;job1&amp;#39; 和 &amp;#39;job2&amp;#39; 这两个任务队列
    rq_worker = RQWorker(name=&amp;#39;test&amp;#39;, listen_keys=[&amp;#39;job1&amp;#39;, &amp;#39;job2&amp;#39;])

    # 向 Master 提交任务，该任务将由 Master 在 2015-07-17 21:13:30 这个时间点通过 &amp;#39;job1&amp;#39; 任务队列下发给 Worker ，Worker 拿到后将执行 test_date_job 函数
    rq_worker.submit_job(test_date_job, &amp;#39;job1&amp;#39;, trigger=&amp;#39;date&amp;#39;, run_date=&amp;#39;2015-07-17 21:13:30&amp;#39;)

    # 向 Master 提交任务，该任务将每隔30秒由 Master 通过 &amp;#39;job1&amp;#39; 任务队列下发给 Worker ，Worker 拿到后将执行 wapper_job 函数
    rq_worker.submit_job(wapper_job, &amp;#39;job1&amp;#39;, trigger=&amp;#39;interval&amp;#39;, seconds=30)

    # 向 Master 提交任务，该任务为即时任务（没有提供trigger），将马上由Master 通过任务队列 &amp;#39;job2&amp;#39; 下发给 Worker ，Worker 拿到后将执行 test_job 函数
    rq_worker.submit_job(test_job, &amp;#39;job2&amp;#39;, kwargs={&amp;#39;language&amp;#39;: &amp;#39;python&amp;#39;})

    # 向 Master 提交任务，该任务将在每分钟的第7秒由 Master 通过 &amp;#39;job2&amp;#39; 任务队列下发给 Worker ，Worker 拿到后将执行 test_cron_job 函数
    rq_worker.submit_job(test_cron_job, &amp;#39;job2&amp;#39;, trigger=&amp;#39;cron&amp;#39;, second=7)

    # 启动 Worker，如果 &amp;#39;job1&amp;#39; 或 &amp;#39;job2&amp;#39; 有任务则拉取下来执行
    rq_worker.start()
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;完整的demo可见&lt;a href=&quot;https://github.com/Masutangu/Elric/tree/master/example&quot;&gt;https://github.com/Masutangu/Elric/tree/master/example&lt;/a&gt;&lt;/p&gt;

&lt;h1&gt;三. 架构&lt;/h1&gt;

&lt;p&gt;Elric 架构图如下：
&lt;img src=&quot;/assets/images/elric-documentation/illustration-1.png&quot; width=&quot;800&quot; /&gt;&lt;/p&gt;

&lt;p&gt;运转流程如下（包含部分实现细节）：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Worker 调用 submit_job 提交任务，该任务将存放在任务队列的 &amp;#39;&lt;strong&gt;elric_submit_channel&lt;/strong&gt;&amp;#39; 队列中，等待 Master 处理。同时启动 Worker，Worker 将监听其感兴趣的任务队列，比如 &amp;#39;job1&amp;#39; 队列。&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Master 从任务队列 &amp;#39;&lt;strong&gt;elric_submit_channel&lt;/strong&gt;&amp;#39; 中拉取 Worker 提交的任务，然后做如下处理：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;去重处理：&lt;/p&gt;

&lt;p&gt;首先判断任务的 need_filter 是否为 True，如果为 True，则由 dupefilter 模块去重，已经执行过的将被过滤掉。为 False 则跳过该步骤。  &lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;非即时处理：&lt;/p&gt;

&lt;p&gt;如果任务不是即时任务（ trigger 不为空），则将该任务存储到任务存储 jobstore 中，Master 有另一线程定时扫描 jobstore 取出到期任务来下发。如果为即时任务，则跳过该步骤。&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;任务下发：&lt;/p&gt;

&lt;p&gt;将即时任务或到期任务下发到相应的任务队列，例如放到名为 &amp;#39;job1&amp;#39; 的任务队列。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Worker 监听到 &amp;#39;job1&amp;#39; 任务队列有新任务，取出后交给 executor 来执行。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;四. 周边能力&lt;/h1&gt;

&lt;p&gt;任务的执行结果存放在 mongodb ，为了方便使用者查询和定位问题，我提供了一个简单粗糙的 web 服务：&lt;a href=&quot;https://github.com/Masutangu/ElricStats&quot;&gt;ElricStats&lt;/a&gt;，通过他可以方便的查询每个任务执行的时间和结果。&lt;/p&gt;

&lt;h1&gt;五. 实现细节&lt;/h1&gt;

&lt;h2&gt;Master的分布式锁&lt;/h2&gt;

&lt;p&gt;为了支持多机器部署Master，在某些操作需要有锁的机制来保证原子性，比如在查询 jobstore 并取出到期任务下发时，简化代码如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;for job_id, job_key, serialized_job in self.jobstore.get_due_jobs(now):
    # 将任务下发到任务队列
    self._enqueue_job(job_key, serialized_job)

    # 获取任务的下次执行时间，并更新到 jobstore 
    job = Job.deserialize(serialized_job)
    last_run_time = Job.get_serial_run_times(job, now)
    job.next_run_time = Job.get_next_trigger_time(job, last_run_time[-1])   
    self.update_job(job)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;如果在这个操作没有加锁保证原子性，将有可能下发重复的任务。这里我采用了redis实现的分布式锁来解决这个问题。其原理利用了 redis 的 setnx 命令，详细可以查看这篇文章《&lt;a href=&quot;http://redis.io/topics/distlock&quot;&gt;Distributed locks with Redis&lt;/a&gt;》。&lt;/p&gt;

&lt;p&gt;我把分布式锁封装成 Context Managers 的形式：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;class distributed_lock(object):
    def __init__(self, **config):
        self.config = config
        self.dlm = redlock.Redlock([config[&amp;#39;server&amp;#39;], ],
                                retry_count=config[&amp;#39;retry_count&amp;#39;],
                                retry_delay=config[&amp;#39;retry_delay&amp;#39;])
        self.dlm_lock = None

    def __enter__(self):
        while not self.dlm_lock:
            self.dlm_lock = self.dlm.lock(self.config[&amp;#39;resource&amp;#39;], 1000)
            if self.dlm_lock:
                break
            else:
                time.sleep(self.config[&amp;#39;retry_delay&amp;#39;])

    def __exit__(self, type, value, traceback):
        self.dlm.unlock(self.dlm_lock)
        self.dlm_lock = None
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这样就可以使用 with statement 来管理：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;with distributed_lock(**DISTRIBUTED_LOCK_CONFIG):
    for job_id, job_key, serialized_job in self.jobstore.get_due_jobs(now):
        # 将任务下发到任务队列
        self._enqueue_job(job_key, serialized_job)

        # 获取任务的下次执行时间，并更新到 jobstore 
        job = Job.deserialize(serialized_job)
        last_run_time = Job.get_serial_run_times(job, now)
        job.next_run_time = Job.get_next_trigger_time(job, last_run_time[-1])   
        self.update_job(job)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h1&gt;六. 后续优化&lt;/h1&gt;

&lt;p&gt;Elric 目前来说还比较粗糙，后续有时间我希望对下面这几个方面做些优化：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;配置规范化：目前我的配置文件 settings.py （包括logging模块）的实现并不规范，后续希望参考 &lt;a href=&quot;https://www.djangoproject.com/&quot;&gt;Django&lt;/a&gt; 的做法来实现配置管理。 &lt;/li&gt;
&lt;li&gt;防雪崩机制优化：目前防雪崩机制比较简单，在任务队列满的时候 Master 会缓存一部分任务。后期改造成在下发的任务里带上任务的下发时间，Worker 取到任务后如果发现任务已经过期一段时间则直接抛弃。&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 07 Jul 2016 15:02:11 +0800</pubDate>
        <link>http://masutangu.com/2016/07/elric-documentation/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/07/elric-documentation/</guid>
        
        
        <category>个人项目</category>
        
      </item>
    
      <item>
        <title>Python 笔记</title>
        <description>&lt;p&gt;这篇文章整理了python相关的资料，包括性能优化、常见错误和高级用法。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;注：本文内容整理自网上博客，《Python Cookbook》等，非原创。&lt;/em&gt;&lt;/p&gt;

&lt;h2&gt;性能优化&lt;/h2&gt;

&lt;h3&gt;1. 字典和列表&lt;/h3&gt;

&lt;p&gt;Python 字典中使用了 hash table，因此查找操作的复杂度为 O(1)，而 list 实际是个数组，在 list 中，查找需要遍历整个 list，其复杂度为 O(n)，因此对成员的查找访问等操作字典要比 list 更快。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;from time import time
t = time()
list = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;is&amp;#39;,&amp;#39;python&amp;#39;,&amp;#39;jason&amp;#39;,&amp;#39;hello&amp;#39;,&amp;#39;hill&amp;#39;,&amp;#39;with&amp;#39;,&amp;#39;phone&amp;#39;,&amp;#39;test&amp;#39;,
&amp;#39;dfdf&amp;#39;,&amp;#39;apple&amp;#39;,&amp;#39;pddf&amp;#39;,&amp;#39;ind&amp;#39;,&amp;#39;basic&amp;#39;,&amp;#39;none&amp;#39;,&amp;#39;baecr&amp;#39;,&amp;#39;var&amp;#39;,&amp;#39;bana&amp;#39;,&amp;#39;dd&amp;#39;,&amp;#39;wrd&amp;#39;]
#list = dict.fromkeys(list,True)
print list
filter = []
for i in range (1000000):
    for find in [&amp;#39;is&amp;#39;,&amp;#39;hat&amp;#39;,&amp;#39;new&amp;#39;,&amp;#39;list&amp;#39;,&amp;#39;old&amp;#39;,&amp;#39;.&amp;#39;]:
        if find not in list:
            filter.append(find)
print &amp;quot;total run time:&amp;quot;
print time()-t
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;将list转化为dict后速度提升了将近一半。&lt;/p&gt;

&lt;h3&gt;2. 集合和列表&lt;/h3&gt;

&lt;p&gt;set 的 union， intersection，difference 操作要比 list 的迭代要快。因此如果涉及到求 list 交集，并集或者差的问题可以转换为 set 来操作。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;# 使用list：
from time import time
t = time()
lista=[1,2,3,4,5,6,7,8,9,13,34,53,42,44]
listb=[2,4,6,9,23]
intersection=[]
for i in range (1000000):
for a in lista:
    for b in listb:
        if a == b:
            intersection.append(a)

print &amp;quot;total run time:&amp;quot;
print time()-t

# 使用set：
from time import time
t = time()
lista=[1,2,3,4,5,6,7,8,9,13,34,53,42,44]
listb=[2,4,6,9,23]
intersection=[]
for i in range (1000000):
    list(set(lista)&amp;amp;set(listb))
print &amp;quot;total run time:&amp;quot;
print time()-t
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;3. 字符串的优化&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;在字符串连接的使用尽量使用 join() 而不是 +。&lt;/li&gt;
&lt;li&gt;当对字符串可以使用正则表达式或者内置函数来处理的时候，选择内置函数。如 str.isalpha()，str.isdigit()，str.startswith((‘x’, ‘yz’))，str.endswith((‘x’, ‘yz’))&lt;/li&gt;
&lt;li&gt;&lt;p&gt;对字符进行格式化比直接串联读取要快，因此要&lt;/p&gt;

&lt;p&gt;使用：&lt;code&gt;out = &amp;quot;&amp;lt;html&amp;gt;%s%s%s%s&amp;lt;/html&amp;gt;&amp;quot; % (head, prologue, query, tail)&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;避免：&lt;code&gt;out = &amp;quot;&amp;lt;html&amp;gt;&amp;quot; + head + prologue + query + tail + &amp;quot;&amp;lt;/html&amp;gt;&amp;quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;4. 使用列表解析和生成器表达式&lt;/h3&gt;

&lt;p&gt;列表解析要比在循环中重新构建一个新的 list 更为高效，因此我们可以利用这一特性来提高运行的效率。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;from time import time
t = time()
list = [&amp;#39;a&amp;#39;,&amp;#39;b&amp;#39;,&amp;#39;is&amp;#39;,&amp;#39;python&amp;#39;,&amp;#39;jason&amp;#39;,&amp;#39;hello&amp;#39;,&amp;#39;hill&amp;#39;,&amp;#39;with&amp;#39;,&amp;#39;phone&amp;#39;,&amp;#39;test&amp;#39;,
&amp;#39;dfdf&amp;#39;,&amp;#39;apple&amp;#39;,&amp;#39;pddf&amp;#39;,&amp;#39;ind&amp;#39;,&amp;#39;basic&amp;#39;,&amp;#39;none&amp;#39;,&amp;#39;baecr&amp;#39;,&amp;#39;var&amp;#39;,&amp;#39;bana&amp;#39;,&amp;#39;dd&amp;#39;,&amp;#39;wrd&amp;#39;]
total=[]
for i in range (1000000):
for w in list:
    total.append(w)
print &amp;quot;total run time:&amp;quot;
print time()-t

# 使用列表解析：
for i in range (1000000):
    a = [w for w in list]
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;在上述例子上中代码 &lt;code&gt;a = [w for w in list]&lt;/code&gt; 修改为 &lt;code&gt;a = (w for w in list)&lt;/code&gt;，运行时间将进一步减少。&lt;/p&gt;

&lt;h3&gt;5. 其他优化技巧&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;如果需要交换两个变量的值使用 a,b=b,a 而不是借助中间变量 t=a;a=b;b=t；&lt;/li&gt;
&lt;li&gt;在循环的时候使用 xrange 而不是 range；使用 xrange 可以节省大量的系统内存，因为 xrange() 在序列中每次调用只产生一个整数元素。而 range() 將直接返回完整的元素列表，用于循环时会有不必要的开销。在 python3 中 xrange 不再存在，里面 range 提供一个可以遍历任意长度的范围的 iterator。&lt;/li&gt;
&lt;li&gt;使用局部变量，避免”global” 关键字。python 访问局部变量会比全局变量要快得多，因 此可以利用这一特性提升性能。&lt;/li&gt;
&lt;li&gt;if done is not None 比语句 if done != None 更快，读者可以自行验证；&lt;/li&gt;
&lt;li&gt;在耗时较多的循环中，可以把函数的调用改为内联的方式；&lt;/li&gt;
&lt;li&gt;使用级联比较 “x &amp;lt; y &amp;lt; z” 而不是 “x &amp;lt; y and y &amp;lt; z”；&lt;/li&gt;
&lt;li&gt;while 1 要比 while True 更快（当然后者的可读性更好）；&lt;/li&gt;
&lt;li&gt;build in 函数通常较快，add(a,b) 要优于 a+b。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;常见错误&lt;/h2&gt;

&lt;h3&gt;1. range的使用&lt;/h3&gt;

&lt;p&gt;不恰当的使用range，容易出bug：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;for i range(len(alist)):
    print alist[i]
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;正确的做法：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;for item in alist:
    print item
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;不恰当使用range的理由：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;需要在循环中使用索引：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;for index, value in enumerate(alist):
    print index, value
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;需要同时迭代两个循环：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;for word, number in zip(words, numbers):
    print word, number
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;需要迭代序列的一部分：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;for word in words[1:]: # 不包括第一个元素
    print word
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;range的正确用法是生成一个数字序列，而不是生成索引：&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;# Print foo(x) for 0&amp;lt;=x&amp;lt;5
for x in range(5):
    print foo(x)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;2. 变量泄漏&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;循环&lt;/p&gt;

&lt;p&gt;错误的代码：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;for idx, value in enumerate(y):
    if value &amp;gt; max_value:
        break

processList(y, idx)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;当y为空，processList将会抛出异常，原因是idx没有定义。&lt;/p&gt;

&lt;p&gt;正确的处理方式：&lt;strong&gt;哨兵模式&lt;/strong&gt;，在循环前为idx设置一些特殊的值。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;idx ＝ None
for idx, value in enumerate(y):
    if value &amp;gt; max_value:
        break

if idex:
    processList(y, idx)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;外作用域&lt;/p&gt;

&lt;p&gt;错误的代码：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;import sys

# See the bug in the function declaration?
def print_file(filenam):
    &amp;quot;&amp;quot;&amp;quot;Print every line of a file.&amp;quot;&amp;quot;&amp;quot;
    with open(filename) as input_file:
        for line in input_file:
            print line.strip()

if __name__ == &amp;quot;__main__&amp;quot;:
    filename = sys.argv[1]
    print_file(filename)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;此时函数定义中的参数被错误的写为filenam，但是程序依然可以运行。因为print_file的外部作用域存在一个filename的变量。&lt;/p&gt;

&lt;p&gt;正确的做法：&lt;strong&gt;外部作用域的全局变量命名要明显&lt;/strong&gt;，例如IN_ALL_CAPS。&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;3. 循环的数据结构导致循环&lt;/h3&gt;

&lt;p&gt;如果在一个对象中发现一个循环，python会输出一个[...]。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;mylist ＝ ［&amp;#39;test&amp;#39;]
mylist.append(mylist)
#此时会打印[&amp;#39;test&amp;#39;,[...]]
print mylist
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;4. 赋值创建引用&lt;/h3&gt;

&lt;p&gt;python中赋值语句不会创建对象副本,只会创建引用：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;arr = [1, 2, 3, 4]
arr_cp = arr
arr_cp[0] = 100
#print打印出[100, 2, 3, 4]
print arr
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;5. 静态识别局部变量&lt;/h3&gt;

&lt;p&gt;python默认将一个在函数中赋值的变量名视为局部变量，存在于该函数的作用域并当函数运行时才存在。python是在编译def代码时去静态识别局部变量的。&lt;/p&gt;

&lt;p&gt;错误的代码：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;a ＝ 100

＃你可能想先打印a的值，再对a的值进行修改
def myfunc():
    print a
    a = 200
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;因为在预编译的时候python发现函数中对a有赋值，因此把a当作局部变量。而运行到‘print a’语句的时候，局部变量a尚未赋值，因此会报错。&lt;/p&gt;

&lt;p&gt;正确的代码：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;a ＝ 100

def myfunc():
    global a
    print a
    a = 200
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;更隐晦的错误代码：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;myVar = 1

def myfunc():
    myVar += 1
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;myVar += 1&lt;/code&gt;其实相当于&lt;code&gt;myVar = myVar + 1&lt;/code&gt;，python检测到myVar变量有赋值操作，因此将myVar添加到局部命名空间中。当执行到&lt;code&gt;myVar += 1&lt;/code&gt;时会读取myVar的值，此时该变量尚未有值关联，因此会报错。&lt;/p&gt;

&lt;h3&gt;6. 默认参数&lt;/h3&gt;

&lt;p&gt;在执行def语句时，默认参数的值只被解析并保存一次。因此在修改可变的默认变量时可能会出现意想不到的效果。&lt;/p&gt;

&lt;p&gt;错误的代码：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;def saver(x=[]):
    x.append(1)
    print x

saver() # 打印[1]
saver() # 打印[1,1]
saver() # 打印[1,1,1]
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;因为默认参数只被解析并保存一次。因此可变的默认参数在每次函数调用都会保存状态。&lt;/p&gt;

&lt;p&gt;正确的代码：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;def saver(x=None):
    if x is None: x = []
    x.append(1)
    print x
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;def是python中的可执行语句。默认参数在def的语句环境里被计算。如果你执行了def语句多次，每次它都将会创建一个新的函数对象。&lt;/p&gt;

&lt;p&gt;看看stackoverflow的一个例子：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;flist = []

for i in xrange(3):
    def func(x): return x * i
    flist.append(func)

for f in flist:
    print f(2) ＃expect 0 2 4 but print 4 4 4
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;我们可以借助默认参数的机制，在执行def时解析默认参数的值：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;flist=[]
for i in xrange(3):
    def func(x,i=i): return x*i
    flist.append(func)

for f in flist:
    print f(2)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;默认参数还可以用来做缓存：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;def calculate(a, b, c, memo={}):
    try:
        value = memo[a, b, c] # return already calculated value
    except KeyError:
        value = heavy_calculation(a, b, c)
    memo[a, b, c] = value # update the memo dictionary
    return value
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;牢记：当Python执行一条def语句时， 它会使用已经准备好的东西（包括函数的代码对象和函数的上下文属性），创建了一个新的函数对象。同时，计算了函数的默认参数值。&lt;/p&gt;

&lt;h3&gt;7. 谨慎使用super()&lt;/h3&gt;

&lt;p&gt;原文&lt;a href=&quot;https://fuhm.net/super-harmful/&quot;&gt;Python&amp;#39;s Super is nifty, but you can&amp;#39;t use it&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;作者提出两个观点：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;People omit calls to super(...).&lt;strong&gt;init&lt;/strong&gt; if the only superclass is &amp;#39;object&amp;#39;, as, after all, object.&lt;strong&gt;init&lt;/strong&gt; doesn&amp;#39;t do anything! However, this is very incorrect. Doing so will cause other classes&amp;#39; &lt;strong&gt;init&lt;/strong&gt; methods to not be called.&lt;/li&gt;
&lt;li&gt;People think they know what arguments their method will get, and what arguments they should pass along to super. This is also incorrect.
先看第二点，比较好理解，代码如下：&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;class A(object):
    def __init__(self):
        print &amp;quot;A&amp;quot;
        super(A, self).__init__()

class B(object):
    def __init__(self):
        print &amp;quot;B&amp;quot;
        super(B, self).__init__()

class C(A):
    def __init__(self, arg):
        print &amp;quot;C&amp;quot;,&amp;quot;arg=&amp;quot;,arg
        super(C, self).__init__()

class D(B):
    def __init__(self, arg):
        print &amp;quot;D&amp;quot;, &amp;quot;arg=&amp;quot;,arg
        super(D, self).__init__()

class E(C,D):
    def __init__(self, arg):
        print &amp;quot;E&amp;quot;, &amp;quot;arg=&amp;quot;,arg
        super(E, self).__init__(arg)

print &amp;quot;MRO:&amp;quot;, [x.__name__ for x in E.__mro__]
E(10)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;看着很正确，执行下报错：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;MRO: [&amp;#39;E&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;A&amp;#39;, &amp;#39;D&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;object&amp;#39;]
E arg= 10
C arg= 10
A

Traceback (most recent call last):
File &amp;quot;C:\Users\mustangmo\Desktop\test1.py&amp;quot;, line 27, in &amp;lt;module&amp;gt;
    E(10)
File &amp;quot;C:\Users\mustangmo\Desktop\test1.py&amp;quot;, line 24, in __init__
    super(E, self).__init__(arg)
File &amp;quot;C:\Users\mustangmo\Desktop\test1.py&amp;quot;, line 14, in __init__
    super(C, self).__init__()
File &amp;quot;C:\Users\mustangmo\Desktop\test1.py&amp;quot;, line 4, in __init__
    super(A, self).__init__()
TypeError: __init__() takes exactly 2 arguments (1 given)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;原因是：MRO: [&amp;#39;E&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;A&amp;#39;, &amp;#39;D&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;object&amp;#39;]，A的下一个是D，因此super(A, self)方法调用的是D的&lt;strong&gt;init&lt;/strong&gt;方法，D的&lt;strong&gt;init&lt;/strong&gt;方法需要一个参数，因此报错了。&lt;/p&gt;

&lt;p&gt;再看第一点，如果父类是object的话，不调用super().&lt;strong&gt;init&lt;/strong&gt;可能会导致问题，例子如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;class A(object):
    def __init__(self, *args, **kwargs):
        print &amp;quot;A&amp;quot;
        #super(A, self).__init__(*args, **kwargs) 注释掉

class B(object):
    def __init__(self, *args, **kwargs):
        print &amp;quot;B&amp;quot;
        #super(B, self).__init__(*args, **kwargs) 注释掉

class C(A):
    def __init__(self, arg, *args, **kwargs):
        print &amp;quot;C&amp;quot;,&amp;quot;arg=&amp;quot;,arg
        super(C, self).__init__(arg, *args, **kwargs)

class D(B):
    def __init__(self, arg, *args, **kwargs):
        print &amp;quot;D&amp;quot;, &amp;quot;arg=&amp;quot;,arg
        super(D, self).__init__(arg, *args, **kwargs)

class E(C,D):
    def __init__(self, arg, *args, **kwargs):
        print &amp;quot;E&amp;quot;, &amp;quot;arg=&amp;quot;,arg
        super(E, self).__init__(arg, *args, **kwargs)

print &amp;quot;MRO:&amp;quot;, [x.__name__ for x in E.__mro__]
E(10)
```python
输出结果：

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;MRO: [&amp;#39;E&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;A&amp;#39;, &amp;#39;D&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;object&amp;#39;]
E arg= 10
C arg= 10
A
```
可以发现D和B都没有输出，也就是说如果没有调用父类为object类的super.&lt;strong&gt;init&lt;/strong&gt;()，会导致其他类（在本例中为D和B）的&lt;strong&gt;init&lt;/strong&gt;()不执行。按理来说，调用了类E的super.&lt;strong&gt;init&lt;/strong&gt;()函数，应该会同时调用E的父类C和D的&lt;strong&gt;init&lt;/strong&gt;()函数。但是由于MRO是以super()调用来驱动的，上诉例子中，执行到A时，由于没有调用super的init()函数了，因此整个链路就停了。
总结：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;一定要调用父类为object的类的super.&lt;strong&gt;init&lt;/strong&gt;()函数&lt;/li&gt;
&lt;li&gt;调用的super()返回不一定是父类，因此super调用最好保持参数一致&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另附一篇也是关于super的文章&lt;a href=&quot;http://rhettinger.wordpress.com/2011/05/26/super-considered-super/&quot;&gt;Python’s super() considered super!&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;8. string转换为dict&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;str = ‘{ &amp;quot;key&amp;quot; : null}&amp;#39;
mydict = eval(str)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;eval 可能会报错，因为 json 的语义跟 Python 的 dict 不完全一样, 如果 json 串里面出现一个 null 就报错了.
因此合适的方法是采用如下写法：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;json.loads()
mydict = json.loads(str)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h2&gt;高级特性&lt;/h2&gt;

&lt;h3&gt;1. 闭包&lt;/h3&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;def return_func_that_prints_list(z):
    def f():
        print z
    return f

z = [1, 2]
g = return_func_that_prints_list(z)
g()  # print [1, 2]

z.append(3)
g()  # print [1, 2, 3]
z = [1]
g()  # print [1, 2, 3]
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;【译者】：z.append(3)时，g()内部的引用和z仍然指向一个变量，而z=[1]之后，两者就不再指向一个变量了。&lt;/p&gt;

&lt;p&gt;关于闭包，stack overflow &lt;a href=&quot;http://stackoverflow.com/questions/4020419/closures-in-python&quot;&gt;http://stackoverflow.com/questions/4020419/closures-in-python&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;2. wraps&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;给decorator加上wraps以保留原有函数的名称和docstring：&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;from functools import wraps
def my_decorator(f):
    @wraps(f)
    def wrapper(*args, **kwds):
        print &amp;#39;Calling decorated function&amp;#39;
        return f(*args, **kwds)
    return wrapper


@my_decorator
def example():
    &amp;quot;&amp;quot;&amp;quot;Docstring&amp;quot;&amp;quot;&amp;quot;
    print &amp;#39;Called example function&amp;#39;

example()  # print &amp;#39;Calling decorated function&amp;#39; &amp;#39;Called example function&amp;#39;
example.__name__  # print &amp;#39;example&amp;#39;
example.__doc__  # print &amp;#39;Docstring&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;Without the use of this decorator factory, the name of the example function would have been &amp;#39;wrapper&amp;#39;, and the docstring of the original example() would have been lost.&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;3. class decorator&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;给类的所有函数添加decorator：&lt;/strong&gt;&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;def logged(time_format, name_prefix=&amp;quot;&amp;quot;):
    def decorator(func):
        if hasattr(func, &amp;#39;_logged_decorator&amp;#39;) and func._logged_decorator:
            return func

        @wraps(func)
        def decorated_func(*args, **kwargs):
            start_time = time.time()
            print &amp;quot;- Running &amp;#39;%s&amp;#39; on %s &amp;quot; % (
                                            name_prefix + func.__name__,
                                            time.strftime(time_format)
                                )
            result = func(*args, **kwargs)
            end_time = time.time()
            print &amp;quot;- Finished &amp;#39;%s&amp;#39;, execution time = %0.3fs &amp;quot; % (
                                            name_prefix + func.__name__,
                                            end_time - start_time
                                )

            return result
        decorated_func._logged_decorator = True
        return decorated_func
    return decorator

def log_method_calls(time_format):
    def decorator(cls):
        for attr in dir(cls):
            if attr.startswith(&amp;#39;__’): #过滤掉以双下划线开头的attributes
                continue
            a = getattr(cls, attr)
            if hasattr(a, &amp;#39;__call__’): #如果包含__call__属性，说明是函数
                decorated_a = logged(time_format, cls.__name__ + &amp;quot;.&amp;quot;)(a)
                setattr(cls, attr, decorated_a)
        return cls
    return decorator

@log_method_calls(&amp;quot;%b %d %Y - %H:%M:%S&amp;quot;)
class A(object):
    def test1(self):
        print &amp;quot;test1&amp;quot;

@log_method_calls(&amp;quot;%b %d %Y - %H:%M:%S&amp;quot;)
class B(A):
    def test1(self):
        super(B, self).test1()
        print &amp;quot;child test1&amp;quot;

    def test2(self):
        print &amp;quot;test2&amp;quot;

b = B()
b.test1()
b.test2()
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;输出如下：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;- Running &amp;#39;B.test1&amp;#39; on Jul 24 2013 - 14:15:03
- Running &amp;#39;A.test1&amp;#39; on Jul 24 2013 - 14:15:03
test1
- Finished &amp;#39;A.test1&amp;#39;, execution time = 0.000s
child test1
- Finished &amp;#39;B.test1&amp;#39;, execution time = 1.001s
- Running &amp;#39;B.test2&amp;#39; on Jul 24 2013 - 14:15:04
test2
- Finished &amp;#39;B.test2&amp;#39;, execution time = 2.001s
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h3&gt;4. descriptor&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;用法1：Type Checking&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;# Descriptor for a type-checked attribute
class Typed:
    def __init__(self, name, expected_type):
        self.name = name
        self.expected_type = expected_type
    def __get__(self, instance, cls):
        if instance is None:
            return self
        else:
            return instance.__dict__[self.name]
    def __set__(self, instance, value):
        if not isinstance(value, self.expected_type):
            raise TypeError(&amp;#39;Expected &amp;#39; + str(self.expected_type))
        instance.__dict__[self.name] = value

    def __delete__(self, instance):
        del instance.__dict__[self.name]


# Class decorator that applies it to selected attributes
def typeassert(**kwargs):
    def decorate(cls):
        for name, expected_type in kwargs.items():
            # Attach a Typed descriptor to the class
            setattr(cls, name, Typed(name, expected_type))
        return cls
    return decorate

# Example use
@typeassert(name=str, shares=int, price=float)
class Stock:
    def __init__(self, name, shares, price):
        self.name = name
        self.shares = shares
        self.price = price
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;Finally, it should be stressed that you would probably not write a descriptor if you simply want to customize the access of a single attribute of a specific class. Descriptors are more useful in situations where there will be a lot of code reuse (i.e., you want to use the functionality provided by the descriptor in hundreds of places in your code or provide it as a library feature).&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;用法2：Lazily Computed Properties&lt;/li&gt;
&lt;/ul&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;class lazyproperty:
    def __init__(self, func):
        self.func = func
    def __get__(self, instance, cls):
        if instance is None:
            return self
        else:
            value = self.func(instance)
            setattr(instance, self.func.__name__, value)
            return value
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;If a descriptor only defines a &lt;strong&gt;get&lt;/strong&gt;() method, it has a much weaker binding than usual. In particular, the &lt;strong&gt;get&lt;/strong&gt;() method only fires if the attribute being accessed is not in the underlying instance dictionary.&lt;/p&gt;
</description>
        <pubDate>Wed, 06 Jul 2016 18:56:31 +0800</pubDate>
        <link>http://masutangu.com/2016/07/python-note-1/</link>
        <guid isPermaLink="true">http://masutangu.com/2016/07/python-note-1/</guid>
        
        
        <category>编程语言</category>
        
      </item>
    
  </channel>
</rss>
