<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Masutangu</title>
    <description>也許我這一生　始終在追逐那顆九號球</description>
    <link>http://masutangu.com/</link>
    <atom:link href="http://masutangu.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 26 Jul 2018 19:02:51 +0800</pubDate>
    <lastBuildDate>Thu, 26 Jul 2018 19:02:51 +0800</lastBuildDate>
    <generator>Jekyll v3.1.1</generator>
    
      <item>
        <title>Designing Data-Intensive Applications 读书笔记（一）</title>
        <description>&lt;h1&gt;Chapter 1. Reliable, Scalable, and Maintainable Applications&lt;/h1&gt;

&lt;h2&gt;Thinking About Data Systems&lt;/h2&gt;

&lt;p&gt;Increasingly many applications now have such demanding or wide-ranging requirements that a single tool can no longer meet all of its data processing and storage needs. Instead, &lt;strong&gt;the work is broken down into tasks that can be performed efficiently on a single tool, and those different tools are stitched together using application code.（在应用层代码整合多种不同的工具来实现需求）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/data-intensive-note/illustration-1.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;p&gt;In this book, we focus on three concerns that are important in most software systems:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Reliability&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The system should continue to work correctly (performing the correct function at the desired level of performance) even in the face of adversity (hardware or software faults, and even human error)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Scalability&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As the system grows (in data volume, traffic volume, or complexity), there should be reasonable ways of dealing with that growth&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Maintainability&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Over time, many different people will work on the system (engineering and operations, both maintaining current behavior and adapting the system to new use cases), and they should all be able to work on it productively.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Reliability&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Continuing to work correctly, even when things go wrong.&lt;/strong&gt; A fault is not the same as a failure. A fault is usually defined as one component of the system deviating from its spec, whereas a failure is when the system as a whole stops providing the required service to the user. &lt;strong&gt;It is impossible to reduce the probability of a fault to zero; therefore it is usually best to design fault-tolerance mechanisms that prevent faults from causing failures.（实现 fault－tolerance 以避免 faults 引发 failures）&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;Scalability&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Scalability is the term we use to describe a system’s ability to cope with increased load.&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;Describing Load&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Load can be described with a few numbers which we call load parameters.&lt;/strong&gt; The best choice of parameters depends on the architecture of your system: it may be requests per second to a web server, the ratio of reads to writes in a database, the number of simultaneously active users in a chat room, the hit rate on a cache, or something else.&lt;/p&gt;

&lt;h3&gt;Approaches for Coping with Load&lt;/h3&gt;

&lt;p&gt;People often talk of a dichotomy between &lt;strong&gt;scaling up (vertical scaling, moving to a more powerful machine)&lt;/strong&gt; and &lt;strong&gt;scaling out (horizontal scaling, distributing the load across multiple smaller machines)&lt;/strong&gt;. Distributing load across multiple machines is also known as a &lt;strong&gt;shared-nothing architecture&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;An architecture that scales well for a particular application is built around &lt;strong&gt;assumptions of which operations will be common and which will be rare—the load parameters（扩展性良好的系统是基于 load parameter 来构建的）&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;Maintainability&lt;/h2&gt;

&lt;h3&gt;Operability: Making Life Easy for Operations&lt;/h3&gt;

&lt;p&gt;Make it easy for operations teams to keep the system running smoothly.&lt;/p&gt;

&lt;h3&gt;Simplicity:Managing Complexity&lt;/h3&gt;

&lt;p&gt;Make it easy for new engineers to understand the system, by removing as much complexity as possible from the system. (Note this is not the same as simplicity of the user interface.) &lt;strong&gt;One of the best tools we have for removing accidental complexity is abstraction.&lt;/strong&gt; A good abstraction can hide a great deal of implementation detail behind a clean, simple-to-understand façade. &lt;strong&gt;SQL is an abstraction that hides complex on-disk and in-memory data structures.&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;Evolvability: Making Change Easy&lt;/h3&gt;

&lt;p&gt;Make it easy for engineers to make changes to the system in the future, adapting it for unanticipated use cases as requirements change. Also known as extensibility, modifiability, or plasticity.&lt;/p&gt;

&lt;h1&gt;Chapter 2. Data Models and Query Languages&lt;/h1&gt;

&lt;p&gt;Data models are perhaps the most important part of developing software, because they have such a profound effect: not only on how the software is written, &lt;strong&gt;but also on how we think about the problem that we are solving&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Most applications are built by layering one data model on top of another. For each layer, &lt;strong&gt;the key question is: how is it represented in terms of the next-lower layer?&lt;/strong&gt; In a complex application there may be more intermediary levels, such as APIs built upon APIs, but the basic idea is still the same: &lt;strong&gt;each layer hides the complexity of the layers below it by providing a clean data model&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;Relational Model Versus Document Model&lt;/h2&gt;

&lt;p&gt;The best-known data model today is probably that of SQL, data is organized into relations (called tables in SQL), where each relation is an unordered collection of tuples (rows in SQL).&lt;/p&gt;

&lt;h3&gt;The Birth of NoSQL&lt;/h3&gt;

&lt;p&gt;There are several driving forces behind the adoption of NoSQL databases, including:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A need for greater scalability than relational databases can easily achieve, including very large datasets or very high write throughput&lt;/li&gt;
&lt;li&gt;A widespread preference for free and open source software over commercial database products&lt;/li&gt;
&lt;li&gt;Specialized query operations that are not well supported by the relational model&lt;/li&gt;
&lt;li&gt;Frustration with the restrictiveness of relational schemas, and a desire for a more dynamic and expressive data model&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Relational Versus Document Databases Today&lt;/h3&gt;

&lt;p&gt;The main arguments in favor of the document data model are &lt;strong&gt;schema flexibility, better performance due to locality, and that for some applications it is closer to the data structures used by the application&lt;/strong&gt;.（&lt;em&gt;不需要和关系型数据库一样使用 ORM 做转换：If data is stored in relational tables, an awkward translation layer is required between the objects in the application code and the database model of tables, rows, and columns. The disconnect between the models is sometimes called an&lt;/em&gt; &lt;strong&gt;impedance mismatch&lt;/strong&gt;）The relational model counters by providing better support for &lt;strong&gt;joins, and many-to-one and many-to-many relationships&lt;/strong&gt;.&lt;/p&gt;

&lt;h4&gt;Which data model leads to simpler application code?&lt;/h4&gt;

&lt;p&gt;If the data in your application has a document-like structure, then it’s probably a good idea to use a document model. &lt;strong&gt;However, if your application does use many-to-many relationships, the document model becomes less appealing. It’s possible to reduce the need for joins by denormalizing, but then the application code needs to do additional work to keep the denormalized data consistent.&lt;/strong&gt; Joins can be emulated in application code by making multiple requests to the database, but that also moves complexity into the application and is usually slower than a join performed by specialized code inside the database. &lt;strong&gt;In such cases, using a document model can lead to significantly more complex application
code and worse performance.&lt;/strong&gt;&lt;/p&gt;

&lt;h4&gt;Schema flexibility in the document model&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Document databases are sometimes called schemaless, there is an implicit schema, but it is not enforced by the database.&lt;/strong&gt; A more accurate term is &lt;strong&gt;schema-on-read&lt;/strong&gt; (the structure of the data is implicit, and only interpreted when the data is read), in contrast with &lt;strong&gt;schema-on-write&lt;/strong&gt; (the traditional approach of relational databases, where the schema is explicit and the database ensures all written data conforms to it).&lt;/p&gt;

&lt;h4&gt;Data locality for queries&lt;/h4&gt;

&lt;p&gt;A document is usually stored as a single continuous string, encoded as JSON, XML, or a binary variant thereof. If your application often needs to access the entire document, there is a performance advantage to this &lt;strong&gt;storage locality&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The locality advantage only applies if you need large parts of the document at the same time. On updates to a document, the entire document usually needs to be rewritten—only modifications that don’t change the encoded size of a document can easily be performed in place. For these reasons, it is generally recommended that you keep documents fairly small and &lt;strong&gt;avoid writes that increase the size of a document&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;Query Languages for Data&lt;/h2&gt;

&lt;p&gt;When the relational model was introduced, it included a new way of querying data: &lt;strong&gt;SQL is a declarative query language, whereas IMS and CODASYL queried the database using imperative code&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In a declarative query language, like SQL or relational algebra, you just specify the pattern of the data you want, but not how to achieve that goal.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Declarative languages often lend themselves to parallel execution. Imperative code is very hard to parallelize across multiple cores and multiple machines&lt;/strong&gt;, because it specifies instructions that must be performed in a particular order.&lt;/p&gt;

&lt;h2&gt;Graph-Like Data Models&lt;/h2&gt;

&lt;p&gt;The relational model can handle simple cases of many-to-many relationships, but as the connections within your data become more complex, it becomes more natural to start modeling your data as a graph.&lt;/p&gt;

&lt;h3&gt;Property Graphs&lt;/h3&gt;

&lt;p&gt;In the property graph model, each vertex consists of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A unique identifier&lt;/li&gt;
&lt;li&gt;A set of outgoing edges&lt;/li&gt;
&lt;li&gt;A set of incoming edges&lt;/li&gt;
&lt;li&gt;A collection of properties (key-value pairs)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each edge consists of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A unique identifier&lt;/li&gt;
&lt;li&gt;The vertex at which the edge starts (the tail vertex)&lt;/li&gt;
&lt;li&gt;The vertex at which the edge ends (the head vertex)&lt;/li&gt;
&lt;li&gt;A label to describe the kind of relationship between the two vertices&lt;/li&gt;
&lt;li&gt;A collection of properties (key-value pairs)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Graphs are good for evolvability: as you add features to your application, a graph can easily be extended to accommodate changes in your application’s data structures.&lt;/strong&gt;&lt;/p&gt;

&lt;h1&gt;Chapter 3. Storage and Retrieval&lt;/h1&gt;

&lt;p&gt;We will examine two families of storage engines: &lt;strong&gt;log-structured storage engines, and page-oriented storage engines such as B-trees&lt;/strong&gt;.&lt;/p&gt;

&lt;h2&gt;Data Structures That Power Your Database&lt;/h2&gt;

&lt;p&gt;In order to efficiently find the value for a particular key in the database, we need a different data structure: an index. &lt;/p&gt;

&lt;h3&gt;Hash Indexes&lt;/h3&gt;

&lt;p&gt;Let’s say our data storage consists only of appending to a file. Then the simplest possible indexing strategy is this: &lt;strong&gt;keep an in-memory hash map where every key is mapped to a byte offset in the data file&lt;/strong&gt;—the location at which the value can be found. This is essentially what Bitcask (the default storage engine in Riak) does&lt;/p&gt;

&lt;p&gt;A storage engine like Bitcask is well suited to situations where the value for each key is updated frequently. For example, the key might be the URL of a cat video, and the value might be the number of times it has been played. &lt;strong&gt;In this kind of workload, there are a lot of writes, but there are not too many distinct keys—you have a large number of writes per key, but it’s feasible to keep all keys in memory.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;How do we avoid eventually running out of disk space? &lt;strong&gt;A good solution is to break the log into segments of a certain size by closing a segment file when it reaches a certain size, and making subsequent writes to a new segment file.&lt;/strong&gt; We can then perform compaction on these segments. &lt;strong&gt;Compaction means throwing away duplicate keys in the log, and keeping only the most recent update for each key.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Each segment now has its own in-memory hash table, mapping keys to file offsets.&lt;/strong&gt; In order to find the value for a key, we first check the most recent segment’s hash map; if the key is not present we check the second-most-recent segment, and so on.&lt;/p&gt;

&lt;p&gt;An append-only design turns out to be good for several reasons:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Appending and segment merging are sequential write operations, which are generally much faster than random writes, especially on magnetic spinning-disk hard drives.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Concurrency and crash recovery are much simpler if segment files are append-only or immutable.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Merging old segments avoids the problem of data files getting fragmented over time.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, the hash table index also has limitations:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The hash table must fit in memory, so if you have a very large number of keys, you’re out of luck.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Range queries are not efficient. &lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;SSTables and LSM-Trees&lt;/h3&gt;

&lt;p&gt;Now we can make a simple change to the format of our segment files: we require that the sequence of key-value pairs is sorted by key. &lt;/p&gt;

&lt;p&gt;We call this format &lt;strong&gt;Sorted String Table, or SSTable&lt;/strong&gt; for short. We also require that each key only appears once within each merged segment file (the compaction process already ensures that). SSTables have several big advantages over log segments with hash indexes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Merging segments is simple and efficient&lt;/strong&gt;, even if the files are bigger than the available memory. The approach is like the one used in the mergesort algorithm.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In order to find a particular key in the file, you no longer need to keep an index of all the keys in memory. You still need an in-memory index to tell you the offsets for some of the keys, but &lt;strong&gt;it can be sparse&lt;/strong&gt;: one key for every few kilobytes of segment file is sufficient, because a few kilobytes can be scanned very quickly.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/data-intensive-note/illustration-2.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Since read requests need to scan over several key-value pairs in the requested range anyway, &lt;strong&gt;it is possible to group those records into a block and compress it before writing it to disk&lt;/strong&gt;. Each entry of the sparse in-memory index then points at the start of a compressed block. Besides saving disk space, compression also reduces the I/O bandwidth use.&lt;/li&gt;
&lt;/ul&gt;

&lt;h4&gt;Constructing and maintaining SSTables&lt;/h4&gt;

&lt;p&gt;How do you get your data to be sorted by key in the first place? We can now make our storage engine work as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;When a write comes in, add it to an in-memory balanced tree data structure.&lt;/li&gt;
&lt;li&gt;When the memtable gets bigger than some threshold—typically a few megabytes—write it out to disk as an SSTable file.&lt;/li&gt;
&lt;li&gt;In order to serve a read request, first try to find the key in the memtable, then in the most recent on-disk segment, then in the next-older segment, etc.&lt;/li&gt;
&lt;li&gt;From time to time, run a merging and compaction process in the background to combine segment files and to discard overwritten or deleted values.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It only suffers from one problem: if the database crashes, the most recent writes (which are in the memtable but not yet written out to disk) are lost. In order to avoid that problem, we can &lt;strong&gt;keep a separate log on disk to which every write is immediately appended&lt;/strong&gt;, just like in the previous section. That log is not in sorted order, but that doesn’t matter, because &lt;strong&gt;its only purpose is to restore the memtable after a crash&lt;/strong&gt;. &lt;/p&gt;

&lt;h4&gt;Performance optimizations&lt;/h4&gt;

&lt;p&gt;The LSM-tree algorithm can be slow when looking up keys that do not exist in the database: you have to check the memtable, then the segments all the way back to the oldest before you can be sure that the key does not exist. &lt;strong&gt;In order to optimize this kind of access, storage engines often use additional Bloom filters.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;There are also different strategies to determine the order and timing of how SSTables are compacted and merged. The most common options are &lt;strong&gt;size-tiered and leveled compaction&lt;/strong&gt;.&lt;/p&gt;

&lt;h3&gt;B-Trees&lt;/h3&gt;

&lt;p&gt;The most widely used indexing structure is quite different: the B-tree.&lt;/p&gt;

&lt;p&gt;Like SSTables, B-trees keep key-value pairs sorted by key, which allows efficient key- value lookups and range queries. &lt;/p&gt;

&lt;p&gt;The log-structured indexes we saw earlier break the database down into variable-size segments, typically several megabytes or more in size, and always write a segment sequentially. &lt;strong&gt;By contrast, B-trees break the database down into fixed-size blocks or pages&lt;/strong&gt;, traditionally 4 KB in size (sometimes bigger), and &lt;strong&gt;read or write one page at a time&lt;/strong&gt;. &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Each page can be identified using an address or location&lt;/strong&gt;, which allows one page to refer to another—similar to a pointer, but on disk instead of in memory.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/data-intensive-note/illustration-3.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;p&gt;One page is designated as the root of the B-tree; whenever you want to look up a key in the index, you start here. The page contains several keys and references to child pages. Each child is responsible for a continuous range of keys, and &lt;strong&gt;the keys between the references indicate where the boundaries between those ranges lie&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The number of references to child pages in one page of the B-tree is called the &lt;strong&gt;branching factor&lt;/strong&gt;. If you want to add a new key, you need to find the page whose range encompasses the new key and add it to that page. If there isn’t enough free space in the page to accommodate the new key, it is split into two half-full pages, and the parent page is updated to account for the new subdivision of key ranges.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/data-intensive-note/illustration-4.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;p&gt;This algorithm ensures that the tree remains balanced: a B-tree with n keys always has a depth of O(log n). Most databases can fit into a B-tree that is three or four levels deep, so you don’t need to follow many page references to find the page you are look‐ ing for. (A four-level tree of 4 KB pages with a branching factor of 500 can store up to 256 TB.)&lt;/p&gt;

&lt;h4&gt;Making B-trees reliable&lt;/h4&gt;

&lt;p&gt;If you split a page because an insertion caused it to be overfull, you need to write the two pages that were split, and also overwrite their parent page to update the references to the two child pages. &lt;strong&gt;This is a dangerous operation, because if the database crashes after only some of the pages have been written, you end up with a corrupted index.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In order to make the database resilient to crashes, &lt;strong&gt;it is common for B-tree implementations to include an additional data structure on disk: a write-ahead log (WAL, also known as a redo log)&lt;/strong&gt;.  This is an append-only file to which every B-tree modification must be written before it can be applied to the pages of the tree itself. When the database comes back up after a crash, this log is used to restore the B-tree back to a consistent state.&lt;/p&gt;

&lt;p&gt;An additional complication of updating pages in place is that careful concurrency control is required if multiple threads are going to access the B-tree at the same time. &lt;strong&gt;This is typically done by protecting the tree’s data structures with latches (lightweight locks).&lt;/strong&gt;&lt;/p&gt;

&lt;h4&gt;B-tree optimizations&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Instead of overwriting pages and maintaining a WAL for crash recovery, some databases (like LMDB) use a copy-on-write scheme. A modified page is written to a different location, and a new version of the parent pages in the tree is created, pointing at the new location.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We can save space in pages by not storing the entire key, but abbreviating it. Especially in pages on the interior of the tree, keys only need to provide enough information to act as boundaries between key ranges. Packing more keys into a page allows the tree to have a higher branching factor, and thus fewer levels.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Additional pointers have been added to the tree. For example, each leaf page may have references to its sibling pages to the left and right, which allows scanning keys in order without jumping back to parent pages.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Comparing B-Trees and LSM-Trees&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;As a rule of thumb, LSM-trees are typically faster for writes, whereas B-trees are thought to be faster for reads.&lt;/strong&gt;&lt;/p&gt;

&lt;h4&gt;Advantages of LSM-trees&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;A B-tree index must write every piece of data at least twice: once to the write-ahead log, and once to the tree page itself (and perhaps again as pages are split).&lt;/strong&gt; There is also overhead from having to write an entire page at a time, even if only a few bytes in that page changed.&lt;/p&gt;

&lt;p&gt;Log-structured indexes also rewrite data multiple times due to repeated compaction and merging of SSTables. &lt;/p&gt;

&lt;p&gt;In write-heavy applications, the performance bottleneck might be the rate at which the database can write to disk.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Moreover, LSM-trees are typically able to sustain higher write throughput than B-trees, partly because they sometimes have lower write amplification, and partly because they sequentially write compact SSTable files rather than having to overwrite several pages in the tree.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Since LSM-trees are not page-oriented and periodically rewrite SSTables to remove fragmentation, they have lower storage overheads, especially when using leveled compaction.&lt;/p&gt;

&lt;h4&gt;Downsides of LSM-trees&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;A downside of log-structured storage is that the compaction process can sometimes interfere with the performance of ongoing reads and writes.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An advantage of B-trees is that each key exists in exactly one place in the index&lt;/strong&gt;, whereas a log-structured storage engine may have multiple copies of the same key in different segments. This aspect makes B-trees attractive in databases that want to offer strong transactional semantics: &lt;strong&gt;in many relational databases, transaction isolation is implemented using locks on ranges of keys, and in a B-tree index, those locks can be directly attached to the tree.&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;Other Indexing Structures&lt;/h3&gt;

&lt;p&gt;A secondary index can easily be constructed from a key-value index. The main difference is that keys are not unique. This can be solved in two ways: &lt;strong&gt;either by making each value in the index a list of matching row identifiers (like a postings list in a full-text index) or by making each key unique by appending a row identifier to it.&lt;/strong&gt; &lt;/p&gt;

&lt;h4&gt;Storing values within the index&lt;/h4&gt;

&lt;p&gt;The key in an index is the thing that queries search for, but the value can be one of two things: it could be the actual row (document, vertex) in question, or it could be a reference to the row stored elsewhere. In the latter case, the place where rows are stored is known as a &lt;strong&gt;heap file&lt;/strong&gt;. &lt;strong&gt;The heap file approach is common because it avoids duplicating data when multiple secondary indexes are present: each index just references a location in the heap file, and the actual data is kept in one place.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;In some situations, the extra hop from the index to the heap file is too much of a performance penalty for reads, so it can be desirable to store the indexed row directly within an index. This is known as a &lt;strong&gt;clustered index&lt;/strong&gt;. For example, in MySQL’s InnoDB storage engine, the primary key of a table is always a clustered index, and secondary indexes refer to the primary key (rather than a heap file location)（每一 个 Secondary Index 包含主健，再根据主键索引找到相应的数据）&lt;/p&gt;

&lt;h4&gt;Multi-column indexes&lt;/h4&gt;

&lt;p&gt;The most common type of multi-column index is called a &lt;strong&gt;concatenated index&lt;/strong&gt;, which simply combines several fields into one key by appending one column to another(the index definition specifies in which order the fields are concatenated).&lt;/p&gt;

&lt;p&gt;Multi-dimensional indexes are a more general way of querying several columns at once, which is particularly important for geospatial data. One option is to translate a two-dimensional location into a single number using a space-filling curve, and then to use a regular B-tree index. &lt;strong&gt;More commonly, specialized spatial indexes such as R-trees are used.&lt;/strong&gt;&lt;/p&gt;

&lt;h4&gt;Full-text search and fuzzy indexes&lt;/h4&gt;

&lt;p&gt;To cope with typos in documents or queries, Lucene is able to search text for words within a certain edit distance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Lucene uses a SSTable-like structure for its term dictionary.&lt;/strong&gt; This structure requires a small in- memory index that tells queries at which offset in the sorted file they need to look for a key. In LevelDB, this in-memory index is a sparse collection of some of the keys, but &lt;strong&gt;in Lucene, the in-memory index is a finite state automaton over the characters in the keys, similar to a trie&lt;/strong&gt;. This automaton can be transformed into a Levenshtein automaton, which supports efficient search for words within a given edit distance.&lt;/p&gt;

&lt;h4&gt;Keeping everything in memory&lt;/h4&gt;

&lt;p&gt;Counterintuitively, the performance advantage of in-memory databases is not due to the fact that they don’t need to read from disk. Rather, &lt;strong&gt;they can be faster because they can avoid the overheads of encoding in-memory data structures in a form that can be written to disk.&lt;/strong&gt;&lt;/p&gt;

&lt;h2&gt;Transaction Processing or Analytics?&lt;/h2&gt;

&lt;h3&gt;Data Warehousing&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;A data warehouse is a separate database that analysts can query to their hearts’ content, without affecting OLTP operations.&lt;/strong&gt; The data warehouse contains a read-only copy of the data in all the various OLTP systems in the company. Data is extracted from OLTP databases (using either a periodic data dump or a continuous stream of updates), transformed into an analysis-friendly schema, cleaned up, and then loaded into the data warehouse. This process of getting data into the warehouse is known as Extract–Transform–Load (ETL).&lt;/p&gt;

&lt;p&gt;A big advantage of using a separate data warehouse, rather than querying OLTP systems directly for analytics, is that the data warehouse can be optimized for analytic access patterns. It turns out that the indexing algorithms discussed in the first half of this chapter work well for OLTP, but are not very good at answering analytic queries.&lt;/p&gt;

&lt;h4&gt;The divergence between OLTP databases and data warehouses&lt;/h4&gt;

&lt;p&gt;The data model of a data warehouse is most commonly relational, because SQL is generally a good fit for analytic queries. &lt;/p&gt;

&lt;h3&gt;Stars and Snowflakes: Schemas for Analytics&lt;/h3&gt;

&lt;p&gt;A wide range of different data models are used in the realm of transaction processing, depending on the needs of the application. On the other hand, &lt;strong&gt;in analytics, there is much less diversity of data models. Many data warehouses are used in a fairly formulaic style, known as a star schema&lt;/strong&gt; (also known as dimensional modeling).&lt;/p&gt;

&lt;h2&gt;Column-Oriented Storage&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;In most OLTP databases, storage is laid out in a row-oriented fashion&lt;/strong&gt;: all the values from one row of a table are stored next to each other. Document databases are similar: an entire document is typically stored as one contiguous sequence of bytes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The idea behind column-oriented storage is simple: don’t store all the values from one row together, but store all the values from each column together instead.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/data-intensive-note/illustration-5.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;h3&gt;Column Compression&lt;/h3&gt;

&lt;p&gt;Depending on the data in the column, different compression techniques can be used. One technique that is particularly effective in data warehouses is bitmap encoding.&lt;/p&gt;

&lt;h3&gt;Sort Order in Column Storage&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Another advantage of sorted order is that it can help with compression of columns.&lt;/strong&gt;&lt;/p&gt;

&lt;h3&gt;Writing to Column-Oriented Storage&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Column-oriented storage, compression, and sorting all help to make those read queries faster.&lt;/strong&gt; However, they have the downside of making writes more difficult.&lt;/p&gt;

&lt;p&gt;An update-in-place approach, like B-trees use, is not possible with compressed columns. If you wanted to insert a row in the middle of a sorted table, you would most likely have to rewrite all the column files.&lt;/p&gt;

&lt;p&gt;Fortunately, we have already seen a good solution earlier in this chapter: LSM-trees. All writes first go to an in-memory store, where they are added to a sorted structure and prepared for writing to disk. It doesn’t matter whether the in-memory store is row-oriented or column-oriented. When enough writes have accumulated, they are merged with the column files on disk and written to new files in bulk. &lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;On a high level, we saw that storage engines fall into two broad categories: those optimized for transaction processing (OLTP), and those optimized for analytics (OLAP). There are big differences between the access patterns in those use cases:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;OLTP systems are typically user-facing, which means that they may see a huge volume of requests. &lt;strong&gt;Disk seek time is often the bottleneck here.&lt;/strong&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Data warehouses and similar analytic systems are less well known, because they are primarily used by business analysts, not by end users. &lt;strong&gt;Disk bandwidth (not seek time) is often the bottleneck here&lt;/strong&gt;, and column-oriented storage is an increasingly popular solution for this kind of workload.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;On the OLTP side, we saw storage engines from two main schools of thought:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The log-structured school, which only permits appending to files and deleting obsolete files, but never updates a file that has been written. Bitcask, SSTables, LSM-trees, LevelDB, Cassandra, HBase, Lucene, and others belong to this group.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The update-in-place school, which treats the disk as a set of fixed-size pages that can be overwritten. B-trees are the biggest example of this philosophy, being used in all major relational databases and also many nonrelational ones.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Analytic workloads are so different from OLTP: when your queries require sequentially scanning across a large number of rows, indexes are much less relevant. Instead it becomes important to encode data very compactly, to minimize the amount of data that the query needs to read from disk.&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 26 Jul 2018 18:57:23 +0800</pubDate>
        <link>http://masutangu.com/2018/07/data-intensive-note-1/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/data-intensive-note-1/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>TiKV 源码阅读（未完成）</title>
        <description>&lt;p&gt;TiKV 使用 RocksDB 做持久化存储引擎。将 key 分 range，每一段称为 Region。Region 分散在多台机器上以实现存储的水平扩展。每个 Region 会存放多个副本在不同机器上，使用 raft 算法管理：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/tikv-note-1/illustration-1.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;p&gt;PD 负责整个 TiKV 集群的调度。&lt;/p&gt;

&lt;p&gt;TiKV 使用 version 的方式进行多版本控制（MVCC）：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;Key1-Version3 -&amp;gt; Value
Key1-Version2 -&amp;gt; Value
Key1-Version1 -&amp;gt; Value
...
Key2-Version2 -&amp;gt; Value
Key2-Version1 -&amp;gt; Value
...
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;TiKV 事务使用 &lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/36726.pdf&quot;&gt;Percolator&lt;/a&gt; 模型。采用乐观锁，事务提交才进行冲突检测。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/24564094&quot;&gt;https://zhuanlan.zhihu.com/p/24564094&lt;/a&gt;
&lt;a href=&quot;https://pingcap.com/blog-cn/tidb-internal-1/&quot;&gt;https://pingcap.com/blog-cn/tidb-internal-1/&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 09 Jul 2018 21:59:16 +0800</pubDate>
        <link>http://masutangu.com/2018/07/tikv-note-1/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/tikv-note-1/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>raft-rust 初体验</title>
        <description>&lt;p&gt;之前分析了使用 golang 实现的 etcd-raft，这几天再读了下 rust 实现的 &lt;a href=&quot;https://github.com/pingcap/raft-rs&quot;&gt;raft-rs&lt;/a&gt;，简单说下对比。rust 版应该是基于 golang 版来实现的，所有的类、方法基本上是一致的。&lt;/p&gt;

&lt;p&gt;从样例看起，&lt;code&gt;let (sender, receiver) = mpsc::channel();&lt;/code&gt; 创建了 channel 用于线程之间数据传递（类似 golang 的 channel）。调用 &lt;code&gt;send_propose&lt;/code&gt; 创建一个线程，通过 &lt;code&gt;sender&lt;/code&gt; 发送 propose 请求。&lt;code&gt;main&lt;/code&gt; 主线程则在 loop 循环中监听 &lt;code&gt;receiver&lt;/code&gt; channel 的请求。如果是 propose 请求，调用 RawNode 的 &lt;code&gt;propose&lt;/code&gt; 方法处理（其内部调用 &lt;code&gt;self.raft.step&lt;/code&gt; 方法），如果是其他请求，直接调用 RawNode 的 &lt;code&gt;step&lt;/code&gt; 方法处理（其内部也是调用 &lt;code&gt;self.raft.step&lt;/code&gt; 方法）。loop 循环最后调用 &lt;code&gt;on_ready&lt;/code&gt;，处理 raft 层返回的 ready 对象，这个逻辑和之前 golang 实现的 etcd-raft 是很类似的：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;// A simple example about how to use the Raft library in Rust.
fn main() {
    // Create a storage for Raft, and here we just use a simple memory storage.
    // You need to build your own persistent storage in your production.
    // Please check the Storage trait in src/storage.rs to see how to implement one.
    let storage = MemStorage::new();

    // Create the configuration for the Raft node.
    let cfg = Config {
        ..Default::default()
    };

    // Create the Raft node.
    let mut r = RawNode::new(&amp;amp;cfg, storage, vec![]).unwrap();

    let (sender, receiver) = mpsc::channel();

    // Use another thread to propose a Raft request.
    send_propose(sender);

    // Loop forever to drive the Raft.
    let mut t = Instant::now();
    let mut timeout = Duration::from_millis(100);

    // Use a HashMap to hold the `propose` callbacks.
    let mut cbs = HashMap::new();

    loop {
        match receiver.recv_timeout(timeout) {
            Ok(Msg::Propose { id, cb }) =&amp;gt; {
                cbs.insert(id, cb);
                r.propose(vec![], vec![id]).unwrap();
            }
            Ok(Msg::Raft(m)) =&amp;gt; r.step(m).unwrap(),
            Err(RecvTimeoutError::Timeout) =&amp;gt; (),
            Err(RecvTimeoutError::Disconnected) =&amp;gt; return,
        }

        let d = t.elapsed();
        if d &amp;gt;= timeout {
            t = Instant::now();
            timeout = Duration::from_millis(100);
            // We drive Raft every 100ms.
            r.tick();
        } else {
            timeout -= d;
        }

        on_ready(&amp;amp;mut r, &amp;amp;mut cbs);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;留意这里，往 sender 发了个包在 Box 里的闭包 &lt;code&gt;s1.send(0).unwrap()&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn send_propose(sender: mpsc::Sender&amp;lt;Msg&amp;gt;) {
    thread::spawn(move || {
        // Wait some time and send the request to the Raft.
        thread::sleep(Duration::from_secs(10));

        let (s1, r1) = mpsc::channel::&amp;lt;u8&amp;gt;();

        println!(&amp;quot;propose a request&amp;quot;);

        // Send a command to the Raft, wait for the Raft to apply it
        // and get the result.
        sender
            .send(Msg::Propose {
                id: 1,
                // cb 为 closure
                cb: Box::new(move || {
                    s1.send(0).unwrap();
                }),
            })
            .unwrap();

        // 当该 propose 请求被处理时，会调用 cb，往 s1 send 值，于是 r1 的 recv 会返回
        let n = r1.recv().unwrap();
        assert_eq!(n, 0);

        println!(&amp;quot;receive the propose callback&amp;quot;);
    });
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-rust&quot; data-lang=&quot;rust&quot;&gt;fn on_ready(r: &amp;amp;mut RawNode&amp;lt;MemStorage&amp;gt;, cbs: &amp;amp;mut HashMap&amp;lt;u8, ProposeCallback&amp;gt;) {
    let mut ready = r.ready(); // 调用 ready 方法，拿到 ready 对象
    // 一波处理 忽略，处理完后也是调用了 advance 方法
    ...
    // Advance the Raft
    r.advance(ready);
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;和 golang 版最大的区别，是 golang 用了 channel 来做进行模块之间的数据通信：&lt;code&gt;recvc&lt;/code&gt; channel 收发请求，&lt;code&gt;advancec&lt;/code&gt; channel 收发 advance 消息，&lt;code&gt;readyc&lt;/code&gt; channel 收发 ready 对象。而 rust 中则直接调用 &lt;code&gt;step&lt;/code&gt;、&lt;code&gt;propose&lt;/code&gt;、&lt;code&gt;ready&lt;/code&gt; 和 &lt;code&gt;advance&lt;/code&gt; 方法来驱动状态机，没有通过 rust 的 channel 机制做消息传递。也许是考虑到效率？由于 raft-rs 提供的例子有点简单，等之后读 tikv 的代码，再来做下一步的对比。&lt;/p&gt;
</description>
        <pubDate>Mon, 09 Jul 2018 21:59:16 +0800</pubDate>
        <link>http://masutangu.com/2018/07/raft-rust/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/raft-rust/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>etcd-raft 源码学习笔记（PreVote）</title>
        <description>&lt;p&gt;这篇文章介绍 etcd-raft 的 PreVote 机制，避免由于网络分区导致 candidate 的 term 不断增大。&lt;/p&gt;

&lt;p&gt;Election timeout 之后，发送 type 为 pb.MsgHup 的请求，进入选举阶段：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// tickElection is run by followers and candidates after r.electionTimeout.
func (r *raft) tickElection() {
    r.electionElapsed++

    if r.promotable() &amp;amp;&amp;amp; r.pastElectionTimeout() {
        r.electionElapsed = 0
        r.Step(pb.Message{From: r.id, Type: pb.MsgHup})
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;如果设置了 preVote 为 true，则先进入 prevote 阶段。调用 &lt;code&gt;r.campaign&lt;/code&gt; 传入 type &lt;code&gt;campaignPreElection&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (r *raft) Step(m pb.Message) error {
    switch m.Type {
    case pb.MsgHup:
        if r.state != StateLeader {
            r.logger.Infof(&amp;quot;%x is starting a new election at term %d&amp;quot;, r.id, r.Term)
            if r.preVote {
                // 如果 preVote 设置为 true，先发起 campaignPreElection
                r.campaign(campaignPreElection)
            } else {
                r.campaign(campaignElection)
            }
        } else {
            r.logger.Debugf(&amp;quot;%x ignoring MsgHup because already leader&amp;quot;, r.id)
        }
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;campaign&lt;/code&gt; 方法处理选举逻辑。如果是 &lt;code&gt;campaignPreElection&lt;/code&gt;，设置节点状态为 &lt;code&gt;StatePreCandidate&lt;/code&gt;，此时不会递增节点的 Term（避免 term 增长过快）。然后向其他 peers 发送 type 为 &lt;code&gt;pb.MsgPreVote&lt;/code&gt; 的请求：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (r *raft) campaign(t CampaignType) {
    var term uint64
    var voteMsg pb.MessageType
    if t == campaignPreElection {
        r.becomePreCandidate()  // state 设置为 StatePreCandidate
        voteMsg = pb.MsgPreVote  // msg type 设置为 preVote
        // PreVote RPCs are sent for the next term before we&amp;#39;ve incremented r.Term.
        term = r.Term + 1  // preVote 不会递增 r.Term
    } else {
        ...
    }
    if r.quorum() == r.poll(r.id, voteRespMsgType(voteMsg), true) {
        // We won the election after voting for ourselves (which must mean that
        // this is a single-node cluster). Advance to the next state.
        if t == campaignPreElection {
            r.campaign(campaignElection)  // prevote 成功，可以发起 campaignElection 了
        } else {
            ... 
        }
        return
    }

    // 广播 pb.MsgPreVote
    for id := range r.prs {
        if id == r.id {
            continue
        }
        var ctx []byte
        r.send(pb.Message{Term: term, To: id, Type: voteMsg, Index: r.raftLog.lastIndex(), LogTerm: r.raftLog.lastTerm(), Context: ctx})
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;看看 &lt;code&gt;stepCandidate&lt;/code&gt; 如何处理 &lt;code&gt;pb.MsgPreVote&lt;/code&gt; 请求的回包。检查选票是否达到 quorum 数量，如果已经达到，prevote 成功，可以发起真正的选举了，调用 &lt;code&gt;r.campaign&lt;/code&gt; 传入 type &lt;code&gt;campaignElection&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// stepCandidate is shared by StateCandidate and StatePreCandidate; the difference is
// whether they respond to MsgVoteResp or MsgPreVoteResp.
func stepCandidate(r *raft, m pb.Message) error {
    // Only handle vote responses corresponding to our candidacy (while in
    // StateCandidate, we may get stale MsgPreVoteResp messages in this term from
    // our pre-candidate state).
    var myVoteRespType pb.MessageType
    if r.state == StatePreCandidate {
        myVoteRespType = pb.MsgPreVoteResp
    } else {
        myVoteRespType = pb.MsgVoteResp
    }
    switch m.Type {
    case myVoteRespType:
        gr := r.poll(m.From, m.Type, !m.Reject)
        switch r.quorum() {
        case gr:
            if r.state == StatePreCandidate {
                r.campaign(campaignElection)  // prevote 成功，可以发起 campaignElection
            } else {
                ...
            }
        case len(r.votes) - gr:  // prevote 失败（m.Reject 为 true，此时 m.Term &amp;gt; r.Term），转为 follower 角色
            // pb.MsgPreVoteResp contains future term of pre-candidate
            // m.Term &amp;gt; r.Term; reuse r.Term
            r.becomeFollower(r.Term, None)
        }
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;如果 campaign 类型为 &lt;code&gt;campaignElection&lt;/code&gt;，则调用 &lt;code&gt;r.becomeCandidate&lt;/code&gt;，此时设置节点状态为 &lt;code&gt;StateCandidate&lt;/code&gt;，递增节点的 Term，并向其他 peers 发送 &lt;code&gt;pb.MsgVote&lt;/code&gt; 请求：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (r *raft) campaign(t CampaignType) {
    var term uint64
    var voteMsg pb.MessageType
    if t == campaignPreElection {
        ...
    } else {
        r.becomeCandidate()  // become cancdidate，term 递增
        voteMsg = pb.MsgVote
        term = r.Term
    }
    if r.quorum() == r.poll(r.id, voteRespMsgType(voteMsg), true) {
        // We won the election after voting for ourselves (which must mean that
        // this is a single-node cluster). Advance to the next state.
        if t == campaignPreElection {
            ...
        } else {
            r.becomeLeader()  // 得到 quorum 的选票，选举 leader 成功，become leader
        }
        return
    }

    // 广播 pb.MsgVote，进行选举
    for id := range r.prs {
        if id == r.id {
            continue
        }
        var ctx []byte
        r.send(pb.Message{Term: term, To: id, Type: voteMsg, Index: r.raftLog.lastIndex(), LogTerm: r.raftLog.lastTerm(), Context: ctx})
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;收到 &lt;code&gt;pb.MsgVote&lt;/code&gt; 的回包后，同样检查是否选票数量是否达到 quorum，成功则该节点当选 leader：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepCandidate(r *raft, m pb.Message) error {
    // Only handle vote responses corresponding to our candidacy (while in
    // StateCandidate, we may get stale MsgPreVoteResp messages in this term from
    // our pre-candidate state).
    var myVoteRespType pb.MessageType
    if r.state == StatePreCandidate {
        myVoteRespType = pb.MsgPreVoteResp
    } else {
        myVoteRespType = pb.MsgVoteResp
    }
    switch m.Type {
    case myVoteRespType:
        gr := r.poll(m.From, m.Type, !m.Reject)
        r.logger.Infof(&amp;quot;%x [quorum:%d] has received %d %s votes and %d vote rejections&amp;quot;, r.id, r.quorum(), gr, m.Type, len(r.votes)-gr)
        switch r.quorum() {
        case gr:
            if r.state == StatePreCandidate {
                ...
            } else {
                r.becomeLeader() // 收到 quorum 选票，选举成功
                r.bcastAppend()  // 广播 append 消息
            }
        case len(r.votes) - gr:
            // pb.MsgPreVoteResp contains future term of pre-candidate
            // m.Term &amp;gt; r.Term; reuse r.Term
            r.becomeFollower(r.Term, None)
        }
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Sun, 08 Jul 2018 10:19:08 +0800</pubDate>
        <link>http://masutangu.com/2018/07/etcd-raft-note-6/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/etcd-raft-note-6/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>etcd-raft 源码学习笔记（Leader Transfer）</title>
        <description>&lt;p&gt;这篇文章介绍 etcd-raft 如何实现 leadership transfer，把 leader 身份转移给某个 follower。&lt;/p&gt;

&lt;p&gt;应用层调用 &lt;code&gt;TransferLeadership&lt;/code&gt; 方法，发送一个 type 为 pb.MsgTransferLeader 的请求给 raft 处理。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (n *node) TransferLeadership(ctx context.Context, lead, transferee uint64) {
    select {
    // manually set &amp;#39;from&amp;#39; and &amp;#39;to&amp;#39;, so that leader can voluntarily transfers its leadership
    case n.recvc &amp;lt;- pb.Message{Type: pb.MsgTransferLeader, From: transferee, To: lead}:
    case &amp;lt;-n.done:
    case &amp;lt;-ctx.Done():
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;stepLeader&lt;/code&gt; 收到 pb.MsgTransferLeader 后，检查下是否有正在进行的 leader transfer，并检查 tranferee 的 log 是否是最新的，如果是，调用 &lt;code&gt;sendTimeoutNow&lt;/code&gt;，如果不是最新日志，则发送 appendEntriesReq，收到 MsgAppResp 后，如果条件符合，再调用 &lt;code&gt;sendTimeoutNow&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepLeader(r *raft, m pb.Message) error {
    // All other message types require a progress for m.From (pr).
    pr := r.getProgress(m.From)
    // These message types do not require any progress for m.From.
    switch m.Type {
        case pb.MsgTransferLeader:
        leadTransferee := m.From
        lastLeadTransferee := r.leadTransferee
        if lastLeadTransferee != None {
            if lastLeadTransferee == leadTransferee {
                return nil
            }
            // 取消之前的
            r.abortLeaderTransfer()
        }
        if leadTransferee == r.id {
            // leadTransferee 已经是 leader 了
            return nil
        }
        // Transfer leadership should be finished in one electionTimeout, so reset r.electionElapsed.
        r.electionElapsed = 0
        r.leadTransferee = leadTransferee
        // 如果 leadTransferee 的 log 已经是最新的了 则马上调用 sendTimeoutNow，开始 transfer
        if pr.Match == r.raftLog.lastIndex() {
            r.sendTimeoutNow(leadTransferee)
        } else {
            // 否则先往 leadTransferee append 日志
            r.sendAppend(leadTransferee)
        }

        ...
        // 收到 append 回包后，检查是不是有 in progress 的 leader transfer，并且 log 也是最新了的话，则调用 sendTimeoutNow
        case pb.MsgAppResp:
        pr.RecentActive = true

        ...
        // Transfer leadership is in progress.
        if m.From == r.leadTransferee &amp;amp;&amp;amp; pr.Match == r.raftLog.lastIndex() {
            r.sendTimeoutNow(m.From)
        }
        ...
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;Leader transfer 过程中不处理 pb.MsgProp 类型的请求：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepLeader(r *raft, m pb.Message) error {
    // These message types do not require any progress for m.From.
    switch m.Type {
    case pb.MsgProp:
        ...
        if r.leadTransferee != None {
            // 正在 leader tranfer，不处理 Propose 请求
            return ErrProposalDropped
        }
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;sendTimeoutNow&lt;/code&gt; 发送 pb.MsgTimeoutNow 的请求，看看 follower 如何处理：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepFollower(r *raft, m pb.Message) error {
    switch m.Type {
        case pb.MsgTimeoutNow:
        if r.promotable() {
            // Leadership transfers never use pre-vote even if r.preVote is true; we
            // know we are not recovering from a partition so there is no need for the
            // extra round trip.
            r.campaign(campaignTransfer)
        }
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;campain&lt;/code&gt; 会发送 voteMsg 给 peers 进行选举：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;
func (r *raft) campaign(t CampaignType) {
    var term uint64
    var voteMsg pb.MessageType
    if t == campaignPreElection {
        r.becomePreCandidate()
        voteMsg = pb.MsgPreVote
        // PreVote RPCs are sent for the next term before we&amp;#39;ve incremented r.Term.
        term = r.Term + 1
    } else {
        r.becomeCandidate()  // 变成 Candidate term + 1，此时该节点 term 最大，所以该节点将成为新的 leader
        voteMsg = pb.MsgVote
        term = r.Term
    }
    if r.quorum() == r.poll(r.id, voteRespMsgType(voteMsg), true) {
        // We won the election after voting for ourselves (which must mean that
        // this is a single-node cluster). Advance to the next state.
        if t == campaignPreElection {
            r.campaign(campaignElection)
        } else {
            r.becomeLeader()
        }
        return
    }

    // 发送 voteMsg
    for id := range r.prs {
        if id == r.id {
            continue
        }
        var ctx []byte
        if t == campaignTransfer {
            ctx = []byte(t)
        }
        r.send(pb.Message{Term: term, To: id, Type: voteMsg, Index: r.raftLog.lastIndex(), LogTerm: r.raftLog.lastTerm(), Context: ctx})
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;当前 leader 变成 follower 之后，会调用 &lt;code&gt;reset&lt;/code&gt;，&lt;code&gt;reset&lt;/code&gt; 将调用 &lt;code&gt;abortLeaderTransfer&lt;/code&gt; 把 &lt;code&gt;r.leadTransferee&lt;/code&gt; 设置为 None，leader transfer 完成。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (r *raft) reset(term uint64) {
    if r.Term != term {
        r.Term = term
        r.Vote = None
    }
    r.lead = None

    r.electionElapsed = 0
    r.heartbeatElapsed = 0
    r.resetRandomizedElectionTimeout()
    r.abortLeaderTransfer()
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Fri, 06 Jul 2018 22:56:37 +0800</pubDate>
        <link>http://masutangu.com/2018/07/etcd-raft-note-5/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/etcd-raft-note-5/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>etcd-raft 源码学习笔记（Linearizable Read 之 Lease）</title>
        <description>&lt;p&gt;这篇文章介绍 etcd-raft 如何实现 linearizable read（linearizable read 简单的说就是不返回 stale 数据，具体可以看这篇文章 &lt;a href=&quot;https://aphyr.com/posts/313-strong-consistency-models&quot;&gt;《Strong consistency models》&lt;/a&gt;）。&lt;/p&gt;

&lt;p&gt;除了基于 &lt;a href=&quot;http://masutangu.com/2018/07/etcd-raft-note-3/&quot;&gt;ReadIndex&lt;/a&gt; 之外，raft 论文第 8 节还阐述了另一种基于 heartbeat 的 lease 思路：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Alternatively, the leader could rely on the heartbeat mechanism to provide a form of lease, but this would rely on timing for safety (it
assumes bounded clock skew).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;raft 中，follower 至少会在 election timeout 之后才重新进行选举。leader 定期发送 heartbeat，在收到 quonum 节点的回包后的 election timeout 这段时间间隔内，不会有新一轮的选举（因为各个机器的 cpu 时钟有误差，所以这个方案有风险）。&lt;/p&gt;

&lt;p&gt;lease 模式对应用层提供的接口还是 &lt;code&gt;ReadIndex&lt;/code&gt;，应用层处理的方式也和基于 ReadIndex 模式相同。只是 raft 内部逻辑不同。&lt;/p&gt;

&lt;p&gt;如果指定了 leaseBase 的模式，那要求 &lt;code&gt;CheckQuorum&lt;/code&gt; 为 true，&lt;code&gt;validate&lt;/code&gt; 方法做了这个检查：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (c *Config) validate() error {
    ...
    if c.ReadOnlyOption == ReadOnlyLeaseBased &amp;amp;&amp;amp; !c.CheckQuorum {
        return errors.New(&amp;quot;CheckQuorum must be enabled when ReadOnlyOption is ReadOnlyLeaseBased&amp;quot;)
    }

    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;指定了 &lt;code&gt;checkQuorum&lt;/code&gt; 为 true 之后，每次 tick 都会看是否应该检查 Quorum（间隔 electionTimeout），通过发送 pb.MsgCheckQuorum 类型的请求：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// tickHeartbeat is run by leaders to send a MsgBeat after r.heartbeatTimeout.
func (r *raft) tickHeartbeat() {
    r.heartbeatElapsed++
    r.electionElapsed++

    if r.electionElapsed &amp;gt;= r.electionTimeout {  // 每隔 electionTimeout 检查一次
        r.electionElapsed = 0
        if r.checkQuorum {
            r.Step(pb.Message{From: r.id, Type: pb.MsgCheckQuorum})  // 检查 Quorum
        }
        // If current leader cannot transfer leadership in electionTimeout, it becomes leader again.
        if r.state == StateLeader &amp;amp;&amp;amp; r.leadTransferee != None {
            r.abortLeaderTransfer()
        }
    }

    if r.state != StateLeader {
        return
    }

    if r.heartbeatElapsed &amp;gt;= r.heartbeatTimeout {
        r.heartbeatElapsed = 0
        r.Step(pb.Message{From: r.id, Type: pb.MsgBeat})
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;stepLeader&lt;/code&gt; 收到 pb.MsgCheckQuorum 后调用 &lt;code&gt;checkQuorumActive&lt;/code&gt; 进行检查，如果返回 false，此时把节点变更为 follower：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepLeader(r *raft, m pb.Message) error {
    // These message types do not require any progress for m.From.
    switch m.Type {
    case pb.MsgCheckQuorum:
        if !r.checkQuorumActive() {  
            r.becomeFollower(r.Term, None)  // checkQuorumActive 失败，变成 follower
        }
        return nil
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;checkQuorumActive&lt;/code&gt; 即统计 active 的 peers 数量是否超过 quonum：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// checkQuorumActive also resets all RecentActive to false.
func (r *raft) checkQuorumActive() bool {
    var act int

    r.forEachProgress(func(id uint64, pr *Progress) {
        if id == r.id { // self is always active
            act++
            return
        }

        if pr.RecentActive &amp;amp;&amp;amp; !pr.IsLearner {
            act++
        }

        pr.RecentActive = false
    })

    return act &amp;gt;= r.quorum()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;RecentActive&lt;/code&gt; 是 leader 收到 peers 的心跳回包或者 appendEntriesReq 的回包时设置的：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepLeader(r *raft, m pb.Message) error {
    // All other message types require a progress for m.From (pr).
    pr := r.getProgress(m.From)

    switch m.Type {
    case pb.MsgAppResp:
        pr.RecentActive = true
        ...
    case pb.MsgHeartbeatResp:
        pr.RecentActive = true
        ...
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;文章开头提到， leaseBase 模式下 etcd-raft 对应用层暴露的也是 &lt;code&gt;ReadIndex&lt;/code&gt; 接口。在收到 pb.MsgReadIndex 类型的请求时，由于 CheckQuonum 保证了我们 leader 有效，就可以直接 append 到 r.readStates 中。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepLeader(r *raft, m pb.Message) error {
    // These message types do not require any progress for m.From.
    switch m.Type {
    case pb.MsgReadIndex:
        // 5.4 safety
        if r.raftLog.zeroTermOnErrCompacted(r.raftLog.term(r.raftLog.committed)) != r.Term {
            // Reject read only request when this leader has not committed any log entry at its term.
            return nil
        }

        // thinking: use an interally defined context instead of the user given context.
        // We can express this in terms of the term and index instead of a user-supplied value.
        // This would allow multiple reads to piggyback on the same message.
        switch r.readOnly.option {
        case ReadOnlyLeaseBased: // leaseBase 模式
            ri := r.raftLog.committed
            if m.From == None || m.From == r.id { // from local member
                r.readStates = append(r.readStates, ReadState{Index: r.raftLog.committed, RequestCtx: m.Entries[0].Data})
            } else {
                r.send(pb.Message{To: m.From, Type: pb.MsgReadIndexResp, Index: ri, Entries: m.Entries})
            }
        }

        return nil
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Fri, 06 Jul 2018 08:46:43 +0800</pubDate>
        <link>http://masutangu.com/2018/07/etcd-raft-note-4/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/etcd-raft-note-4/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>etcd-raft 源码学习笔记（Linearizable Read 之 ReadIndx）</title>
        <description>&lt;p&gt;这篇文章介绍 etcd-raft 如何实现 linearizable read（linearizable read 简单的说就是不返回 stale 数据，具体可以看这篇文章 &lt;a href=&quot;https://aphyr.com/posts/313-strong-consistency-models&quot;&gt;《Strong consistency models》&lt;/a&gt;）。&lt;/p&gt;

&lt;p&gt;raft 论文第 8 节阐述了思路：&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Read-only operations can be handled without writing anything into the log. However, with no additional measures, this would run the risk of returning stale data, since the leader responding to the request might have been superseded by a newer leader of which it is unaware. Linearizable reads must not return stale data, and Raft needs two extra precautions to guarantee this without using the log. First, a leader must have the latest information on which entries are committed. The Leader Completeness Property guarantees that a leader has all committed entries, but at the start of its term, it may not know which those are. To find out, it needs to commit an entry from its term. Raft handles this by having each leader commit a blank no-op entry into the log at the start of its term. Second, a leader must check whether it has been deposed before processing a read-only request (its information may be stale if a more recent leader has been elected). Raft handles this by having the leader exchange heartbeat messages with a majority of the cluster before responding to read-only requests.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;在收到读请求时，leader 节点保存下当前的 commit index，并往 peers 发送心跳。如果确定该节点依然是 leader，则只需要等到该 commit index 的 log entry 被 apply 到状态机时就可以返回客户端结果。&lt;/p&gt;

&lt;p&gt;我们先通过位于 etcd/etcdserver 目录下的样例来看看应用层是如何使用 ReadIndex 来保证 linearizable read 的：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// v3_server.go

type RaftKV interface {
    Range(ctx context.Context, r *pb.RangeRequest) (*pb.RangeResponse, error)
    Put(ctx context.Context, r *pb.PutRequest) (*pb.PutResponse, error)
    DeleteRange(ctx context.Context, r *pb.DeleteRangeRequest) (*pb.DeleteRangeResponse, error)
    Txn(ctx context.Context, r *pb.TxnRequest) (*pb.TxnResponse, error)
    Compact(ctx context.Context, r *pb.CompactionRequest) (*pb.CompactionResponse, error)
}

func (s *EtcdServer) Range(ctx context.Context, r *pb.RangeRequest) (*pb.RangeResponse, error) {
    var resp *pb.RangeResponse
    var err error

    if !r.Serializable {
        err = s.linearizableReadNotify(ctx)  // 等待 linearizableReadNotify 返回 才能继续往下走
        if err != nil {
            return nil, err
        }
    }
    // 读取数据逻辑 省略..
    ...
    return resp, err
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;在读请求 &lt;code&gt;Range&lt;/code&gt; 执行前，调用了 &lt;code&gt;linearizableReadNotify&lt;/code&gt;：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (s *EtcdServer) linearizableReadNotify(ctx context.Context) error {
    s.readMu.RLock()
    nc := s.readNotifier
    s.readMu.RUnlock()

    // signal linearizable loop for current notify if it hasn&amp;#39;t been already
    select {
    case s.readwaitc &amp;lt;- struct{}{}:
    default:
    }

    // wait for read state notification
    select {
    case &amp;lt;-nc.c:
        return nc.err
    case &amp;lt;-ctx.Done():
        return ctx.Err()
    case &amp;lt;-s.done:
        return ErrStopped
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;linearizableReadNotify&lt;/code&gt; 往 &lt;code&gt;readwaitc&lt;/code&gt; 发送个空的结构体，并且等待 &lt;code&gt;nc.c&lt;/code&gt; 的返回。&lt;code&gt;readwaitc&lt;/code&gt; 是在另外的 goroutine &lt;code&gt;linearizableReadLoop&lt;/code&gt; 里监听的：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;
func (s *EtcdServer) linearizableReadLoop() {
    var rs raft.ReadState

    for {
        ctx := make([]byte, 8)
        binary.BigEndian.PutUint64(ctx, s.reqIDGen.Next())  // ctx 即请求唯一标识 reqId

        select {
        case &amp;lt;-s.readwaitc:  // 监听 readwaitc
        case &amp;lt;-s.stopping:
            return
        }

        nextnr := newNotifier()
        nr := s.readNotifier
        s.readNotifier = nextnr

        s.r.ReadIndex(cctx, ctx)  // 调用 ReadIndex 接口，往 recvc channel 发送 type 为 pb.MsgReadIndex 的请求

        var (
            timeout bool
            done    bool
        )
        for !timeout &amp;amp;&amp;amp; !done {
            select {
            case rs = &amp;lt;-s.r.readStateC:  // 收到 ready 对象时，会往 readStateC channel 传回来 readState，见 etcd/etcdserver/raft.go 文件的 func (r *raftNode) start(rh *raftReadyHandler)
                done = bytes.Equal(rs.RequestCtx, ctx)  // 比较下 reqId 是否一致
            case &amp;lt;-time.After(s.Cfg.ReqTimeout()):
                nr.notify(ErrTimeout)
                timeout = true
            case &amp;lt;-s.stopping:
                return
            }
        }
        if !done {
            continue
        }

        // 等待 readState 里的 index，也就是收到 pb.MsgReadIndex 请求时，leader 节点当前的 commit index 被 apply 到状态机时，此时调用 nr.notify(nil) 通知应用层可以读取状态机里的数据了，确保读到的不是 stale 数据
        if ai := s.getAppliedIndex(); ai &amp;lt; rs.Index {
            select {
            case &amp;lt;-s.applyWait.Wait(rs.Index):
            case &amp;lt;-s.stopping:
                return
            }
        }
        // unblock all l-reads requested at indices before rs.Index
        nr.notify(nil)
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;在 &lt;code&gt;linearizableReadLoop&lt;/code&gt; 调用 &lt;code&gt;nr.notify&lt;/code&gt; 后，&lt;code&gt;linearizableReadNotify&lt;/code&gt; 从 select 阻塞中返回，此时就可以继续走 &lt;code&gt;Range&lt;/code&gt; 的逻辑，读取数据，返回给客户端。&lt;/p&gt;

&lt;p&gt;从上面的例子，我们了解了应用层如何使用 Node 的 &lt;code&gt;ReadIndex&lt;/code&gt; 接口来实现 linearizable read。下面我们来介绍 &lt;code&gt;ReadIndex&lt;/code&gt; 这个新接口：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// Node represents a node in a raft cluster.
type Node interface {
    // Propose proposes that data be appended to the log.
    Propose(ctx context.Context, data []byte) error

    // Ready returns a channel that returns the current point-in-time state.
    // Users of the Node must call Advance after retrieving the state returned by Ready.
    //
    // NOTE: No committed entries from the next Ready may be applied until all committed entries
    // and snapshots from the previous one have finished.
    Ready() &amp;lt;-chan Ready

    // Advance notifies the Node that the application has saved progress up to the last Ready.
    // It prepares the node to return the next available Ready.
    //
    // The application should generally call Advance after it applies the entries in last Ready.
    //
    // However, as an optimization, the application may call Advance while it is applying the
    // commands. For example. when the last Ready contains a snapshot, the application might take
    // a long time to apply the snapshot data. To continue receiving Ready without blocking raft
    // progress, it can call Advance before finishing applying the last ready.
    Advance()

    // ReadIndex request a read state. The read state will be set in the ready.
    // Read state has a read index. Once the application advances further than the read
    // index, any linearizable read requests issued before the read request can be
    // processed safely. The read state will have the same rctx attached.
    ReadIndex(ctx context.Context, rctx []byte) error
}

func (n *node) ReadIndex(ctx context.Context, rctx []byte) error {
    return n.step(ctx, pb.Message{Type: pb.MsgReadIndex, Entries: []pb.Entry})
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;上篇文章 &lt;a href=&quot;http://masutangu.com/2018/07/etcd-raft-note-2/&quot;&gt;《etcd-raft 源码学习笔记（概览篇）》&lt;/a&gt; 提到当节点为 leader 时，&lt;code&gt;step&lt;/code&gt; 被设置为 &lt;code&gt;stepLeader&lt;/code&gt; 。我们来看看 &lt;code&gt;stepLeader&lt;/code&gt; 是如何处理 type 为 pb.MsgReadIndex 的 readIndexReq 的：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepLeader(r *raft, m pb.Message) error {
    // These message types do not require any progress for m.From.
    switch m.Type {
    case pb.MsgReadIndex:
        // raft 5.4 safty 检查
        if r.raftLog.zeroTermOnErrCompacted(r.raftLog.term(r.raftLog.committed)) != r.Term {
            // Reject read only request when this leader has not committed any log entry at its term.
            return nil
        }

        // thinking: use an interally defined context instead of the user given context.
        // We can express this in terms of the term and index instead of a user-supplied value.
        // This would allow multiple reads to piggyback on the same message.
        switch r.readOnly.option {
        case ReadOnlySafe:
            r.readOnly.addRequest(r.raftLog.committed, m)  // r.raftLog.committed 为 当前 commit index
            r.bcastHeartbeatWithCtx(m.Entries[0].Data)  // 广播心跳包
        }
        return nil
    }
    return nil
}


&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;收到 readIndexReq 后，首先调用 &lt;code&gt;r.readOnly.addRequest&lt;/code&gt; 保存下，然后调用 &lt;code&gt;bcastHeartbeatWithCtx&lt;/code&gt; 广播心跳包， ctx 即唯一标识 readIndexReq 的 reqId。&lt;/p&gt;

&lt;p&gt;来看看 raft 是如何管理 readIndexReq 的：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// addRequest adds a read only reuqest into readonly struct.
// `index` is the commit index of the raft state machine when it received
// the read only request.
// `m` is the original read only request message from the local or remote node.
func (ro *readOnly) addRequest(index uint64, m pb.Message) {
    ctx := string(m.Entries[0].Data)  // ctx 即 reqId
    if _, ok := ro.pendingReadIndex[ctx]; ok {
        return
    }
    ro.pendingReadIndex[ctx] = &amp;amp;readIndexStatus{index: index, req: m, acks: make(map[uint64]struct{})}  // acks 用于记录哪些 peer 已经 ack 确认。之后用于统计是否大于 quonum
    ro.readIndexQueue = append(ro.readIndexQueue, ctx)  // append 进 readIndexQueue
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;再看看 &lt;code&gt;stepLeader&lt;/code&gt; 如何处理心跳回包：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func stepLeader(r *raft, m pb.Message) error {
    // These message types do not require any progress for m.From.
    switch m.Type {
    case pb.MsgHeartbeatResp:
        pr.RecentActive = true
        pr.resume()

        if r.readOnly.option != ReadOnlySafe || len(m.Context) == 0 {
            return nil
        }

        ackCount := r.readOnly.recvAck(m)
        if ackCount &amp;lt; r.quorum() {  // 判断是否收到 quorum 的心跳回包
            return nil
        }

        // 收到 quorum 的心跳回包了，把 readIndexReq 依次 append r.readStates 中，返回 ready 对象时会包含 r.readStates
        rss := r.readOnly.advance(m)
        for _, rs := range rss {
            req := rs.req
            if req.From == None || req.From == r.id { // from local member
                r.readStates = append(r.readStates, ReadState{Index: rs.index, RequestCtx: req.Entries[0].Data})
            } else {
                r.send(pb.Message{To: req.From, Type: pb.MsgReadIndexResp, Index: rs.index, Entries: req.Entries})
            }
        }
    return nil
    }
    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;调用 &lt;code&gt;r.readOnly.recvAck&lt;/code&gt;，根据 readIndeReq 的 reqId 统计收到心跳回包的数量：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// recvAck notifies the readonly struct that the raft state machine received
// an acknowledgment of the heartbeat that attached with the read only request
// context.
func (ro *readOnly) recvAck(m pb.Message) int {
    rs, ok := ro.pendingReadIndex[string(m.Context)]
    if !ok {
        return 0
    }

    rs.acks[m.From] = struct{}{}  // 记录下收到 m.From 这个节点的 ack
    // add one to include an ack from local node
    return len(rs.acks) + 1
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;如果超过 quonum 表示该节点依然是 leader，此时从 &lt;code&gt;r.readOnly.advance&lt;/code&gt; 拿到保存的 readIndexReq，append 到 &lt;code&gt;r.readStates&lt;/code&gt; 中：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// advance advances the read only request queue kept by the readonly struct.
// It dequeues the requests until it finds the read only request that has
// the same context as the given `m`.
func (ro *readOnly) advance(m pb.Message) []*readIndexStatus {
    var (
        i     int
        found bool
    )

    ctx := string(m.Context)
    rss := []*readIndexStatus{}

    for _, okctx := range ro.readIndexQueue {
        i++
        rs, ok := ro.pendingReadIndex[okctx]
        if !ok {
            panic(&amp;quot;cannot find corresponding read state from pending map&amp;quot;)
        }
        rss = append(rss, rs)
        if okctx == ctx {
            // 取出 reqId 相同的 ReadState 和其前面的所有 ReadState 
            found = true
            break
        }
    }

    if found {
        ro.readIndexQueue = ro.readIndexQueue[i:]
        for _, rs := range rss {
            delete(ro.pendingReadIndex, string(rs.req.Entries[0].Data))
        }
        return rss
    }

    return nil
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;之后调用 &lt;code&gt;newReady&lt;/code&gt; 会把 &lt;code&gt;r.readStates&lt;/code&gt; 返回给应用层，应用层取出 readIndexReq 中的 commit index，等到其被 apply 到状态机就可以允许读操作了。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func newReady(r *raft, prevSoftSt *SoftState, prevHardSt pb.HardState) Ready {
    rd := Ready{
        Entries:          r.raftLog.unstableEntries(),
        CommittedEntries: r.raftLog.nextEnts(),
        Messages:         r.msgs,
    }
    ...

    if len(r.readStates) != 0 {
        rd.ReadStates = r.readStates  // 附上 r.readStates
    }
    ...
    return rd
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Thu, 05 Jul 2018 13:46:43 +0800</pubDate>
        <link>http://masutangu.com/2018/07/etcd-raft-note-3/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/etcd-raft-note-3/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>etcd-raft 源码学习笔记（概览篇）</title>
        <description>&lt;p&gt;这篇文章主要整体上介绍 etcd-raft 库，包括各个类的作用，类之间的串联。不涉及 raft 算法。先来看看 etcd-raft 几个结构体的定义：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;type raft struct {
    id uint64

    Term uint64
    Vote uint64

    // the log
    raftLog *raftLog

    state StateType

    // isLearner is true if the local raft node is a learner.
    isLearner bool

    votes map[uint64]bool

    msgs []pb.Message

    // the leader id
    lead uint64

    tick func()
    step stepFunc
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;type raftLog struct {
    // storage contains all stable entries since the last snapshot.
    storage Storage

    // unstable contains all unstable entries and snapshot.
    // they will be saved into storage.
    unstable unstable

    // committed is the highest log position that is known to be in
    // stable storage on a quorum of nodes.
    committed uint64
    // applied is the highest log position that the application has
    // been instructed to apply to its state machine.
    // Invariant: applied &amp;lt;= committed
    applied uint64
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// unstable.entries[i] has raft log position i+unstable.offset.
// Note that unstable.offset may be less than the highest log
// position in storage; this means that the next write to storage
// might need to truncate the log before persisting unstable.entries.
type unstable struct {
    // the incoming unstable snapshot, if any.
    snapshot *pb.Snapshot
    // all entries that have not yet been written to storage.
    entries []pb.Entry
    offset  uint64
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// node is the canonical implementation of the Node interface
type node struct {
    propc      chan msgWithResult
    recvc      chan pb.Message
    readyc     chan Ready
    advancec   chan struct{}
    tickc      chan struct{}
    done       chan struct{}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// Ready encapsulates the entries and messages that are ready to read,
// be saved to stable storage, committed or sent to other peers.
// All fields in Ready are read-only.
type Ready struct {
    // The current volatile state of a Node.
    // SoftState will be nil if there is no update.
    // It is not required to consume or store SoftState.
    *SoftState

    // The current state of a Node to be saved to stable storage BEFORE
    // Messages are sent.
    // HardState will be equal to empty state if there is no update.
    pb.HardState

    // ReadStates can be used for node to serve linearizable read requests locally
    // when its applied index is greater than the index in ReadState.
    // Note that the readState will be returned when raft receives msgReadIndex.
    // The returned is only valid for the request that requested to read.
    ReadStates []ReadState

    // Entries specifies entries to be saved to stable storage BEFORE
    // Messages are sent.
    Entries []pb.Entry

    // Snapshot specifies the snapshot to be saved to stable storage.
    Snapshot pb.Snapshot

    // CommittedEntries specifies entries to be committed to a
    // store/state-machine. These have previously been committed to stable
    // store.
    CommittedEntries []pb.Entry

    // Messages specifies outbound messages to be sent AFTER Entries are
    // committed to stable storage.
    // If it contains a MsgSnap message, the application MUST report back to raft
    // when the snapshot has been received or has failed by calling ReportSnapshot.
    Messages []pb.Message

    // MustSync indicates whether the HardState and Entries must be synchronously
    // written to disk or if an asynchronous write is permissible.
    MustSync bool
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这几个结构体的关系如下图：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/etcd-raft-node-2/illustration-1.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;p&gt;RaftLog 的 &lt;code&gt;Storage&lt;/code&gt; 和 RaftNode 的 &lt;code&gt;raftStorage&lt;/code&gt; 都是指向同一个 Storage 对象（虚线表示指针）。Storage 在 kvstore 的示例中的实现为 MemoryStorage，可以理解为 WAL 的一个内存缓存。重启时会从 WAL 恢复 MemoryStorage 的数据。整个逻辑由 Node 的 &lt;code&gt;run&lt;/code&gt; 方法的 for loop 驱动，从 &lt;code&gt;recvc&lt;/code&gt; channel 接收请求，调用 raft 的 &lt;code&gt;Step&lt;/code&gt; 函数进行处理。&lt;code&gt;Step&lt;/code&gt; 函数会调用 &lt;code&gt;step&lt;/code&gt;，&lt;code&gt;step&lt;/code&gt; 是函数指针，在节点成为 leader 时将其设置为 &lt;code&gt;stepLeader&lt;/code&gt;，节点变成 follower 时设置为 &lt;code&gt;stepFollower&lt;/code&gt;。&lt;code&gt;step&lt;/code&gt; 处理 append 请求时，会调用 raftLog 的 &lt;code&gt;maybeAppend&lt;/code&gt; 方法，最终会把 entries append 到 &lt;code&gt;unstable&lt;/code&gt; 中。&lt;/p&gt;

&lt;p&gt;在 Node &lt;code&gt;run&lt;/code&gt; 方法的 for loop 中，会定期通过 &lt;code&gt;newReady&lt;/code&gt; 函数构造 Ready 对象。Ready 包括如下：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HardState 即 raft 节点的 persistent state &lt;/li&gt;
&lt;li&gt;SoftState 即 raft 节点的 volatile state &lt;/li&gt;
&lt;li&gt;CommittedEntries 即已经 commit 的 log entries，需要应用层 apply 到状态机&lt;/li&gt;
&lt;li&gt;Entries 即 unstable 中的 log entries（未落盘的 log entries）&lt;/li&gt;
&lt;li&gt;Snapshot 即需要持久化的 snapshot&lt;/li&gt;
&lt;li&gt;Messages 即 mailbox，所有还未发送的消息&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;构造好的 &lt;code&gt;Ready&lt;/code&gt; 对象发送到 &lt;code&gt;readyc&lt;/code&gt; channel，RaftNode 取出后会做如下处理：&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;持久化 HardState、Entries、Snapshot 到 Storage 和 WAL (&lt;code&gt;raftStorage.ApplySnapshot()&lt;/code&gt;、&lt;code&gt;raftStorage.Append()&lt;/code&gt; 和 &lt;code&gt;wal.Save(rd.HardState, rd.Entries)&lt;/code&gt; 可以看出 memoryStorage 是 wal 的缓存，写 wal 的同时也写 memoryStorage)&lt;/li&gt;
&lt;li&gt;apply CommittedEntries 到状态机&lt;/li&gt;
&lt;li&gt;广播 Messages &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;处理完后调用 Node.Advance() 通知 Node Ready 对象处理完毕，准备好接收下一个。&lt;/p&gt;

&lt;p&gt;最后看看驱动整个逻辑的 &lt;code&gt;run&lt;/code&gt; 方法：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (n *node) run(r *raft) {
    var propc chan msgWithResult
    var readyc chan Ready
    var advancec chan struct{}
    var prevLastUnstablei, prevLastUnstablet uint64
    var havePrevLastUnstablei bool
    var prevSnapi uint64
    var rd Ready

    lead := None
    prevSoftSt := r.softState()
    prevHardSt := emptyState

    for {
        if advancec != nil {
            readyc = nil
        } else {
            // 应用层通知上一个 ready 对象已经处理完毕了 此时 advancec 为 nil 
            rd = newReady(r, prevSoftSt, prevHardSt)
            if rd.containsUpdates() { // 有更新才把 readyc 设为 非空
                readyc = n.readyc
            } else {
                readyc = nil
            }
        }

        select {
        case m := &amp;lt;-n.recvc:
            // filter out response message from unknown From.
            if pr := r.getProgress(m.From); pr != nil || !IsResponseMsg(m.Type) {
                r.Step(m)
            }
        case &amp;lt;-n.tickc:
            r.tick()
        case readyc &amp;lt;- rd:
            if rd.SoftState != nil {
                prevSoftSt = rd.SoftState
            }
            if len(rd.Entries) &amp;gt; 0 {
                prevLastUnstablei = rd.Entries[len(rd.Entries)-1].Index
                prevLastUnstablet = rd.Entries[len(rd.Entries)-1].Term
                havePrevLastUnstablei = true
            }
            if !IsEmptyHardState(rd.HardState) {
                prevHardSt = rd.HardState
            }
            if !IsEmptySnap(rd.Snapshot) {
                prevSnapi = rd.Snapshot.Metadata.Index
            }

            r.msgs = nil
            r.readStates = nil
            advancec = n.advancec
        case &amp;lt;-advancec:
            if prevHardSt.Commit != 0 {
                r.raftLog.appliedTo(prevHardSt.Commit)
            }
            // 应用层处理完了 表示 unstable 的东西不需要了 该清理就清理
            if havePrevLastUnstablei {
                r.raftLog.stableTo(prevLastUnstablei, prevLastUnstablet)
                havePrevLastUnstablei = false
            }
            r.raftLog.stableSnapTo(prevSnapi)
            advancec = nil
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;还有构造 Ready 对象的 &lt;code&gt;newReady&lt;/code&gt; 函数：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func newReady(r *raft, prevSoftSt *SoftState, prevHardSt pb.HardState) Ready {
    rd := Ready{
        Entries:          r.raftLog.unstableEntries(),
        CommittedEntries: r.raftLog.nextEnts(),
        Messages:         r.msgs,
    }
    if softSt := r.softState(); !softSt.equal(prevSoftSt) {
        rd.SoftState = softSt
    }
    if hardSt := r.hardState(); !isHardStateEqual(hardSt, prevHardSt) {
        rd.HardState = hardSt
    }
    if r.raftLog.unstable.snapshot != nil {
        rd.Snapshot = *r.raftLog.unstable.snapshot
    }
    if len(r.readStates) != 0 {
        rd.ReadStates = r.readStates
    }
    rd.MustSync = MustSync(rd.HardState, prevHardSt, len(rd.Entries))
    return rd
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Wed, 04 Jul 2018 13:33:35 +0800</pubDate>
        <link>http://masutangu.com/2018/07/etcd-raft-note-2/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/etcd-raft-note-2/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>etcd-raft 源码学习笔记（示例篇）</title>
        <description>&lt;p&gt;本系列文章为 &lt;a href=&quot;https://github.com/coreos/etcd/tree/master/raft&quot;&gt;etcd-raft&lt;/a&gt; 源码阅读笔记，采用自顶向下的方式。这篇是开篇，首先来看看 etcd 提供的基于 raft 库实现的 kv store 示例，代码目录位于 contrib/raftexample。&lt;/p&gt;

&lt;p&gt;从 main 函数开始读起：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func main() {
    ...
    proposeC := make(chan string)
    defer close(proposeC)

    var kvs *kvstore
    getSnapshot := func() ([]byte, error) { return kvs.getSnapshot() }
    commitC, errorC, snapshotterReady := newRaftNode(*id, strings.Split(*cluster, &amp;quot;,&amp;quot;), *join, getSnapshot, proposeC, confChangeC)

    kvs = newKVStore(&amp;lt;-snapshotterReady, proposeC, commitC, errorC)
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;getSnapshot&lt;/code&gt; 为应用层 kv 提供的 snapshot 方法，在 raft 中调用该方法进行 snapshot。&lt;code&gt;proposeC&lt;/code&gt; 是应用层 kv 向 raftNode 发送请求的 channel，&lt;code&gt;commitC&lt;/code&gt; 为 raftNode 通知应用层 kv 已经提交的请求的 channel。&lt;/p&gt;

&lt;p&gt;先看看 &lt;code&gt;newKVStore&lt;/code&gt; 的实现：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func newKVStore(snapshotter *snap.Snapshotter, proposeC chan&amp;lt;- string, commitC &amp;lt;-chan *string, errorC &amp;lt;-chan error) *kvstore {
    s := &amp;amp;kvstore{proposeC: proposeC, kvStore: make(map[string]string), snapshotter: snapshotter}
    // replay log into key-value map
    s.readCommits(commitC, errorC)
    // read commits from raft into kvStore map until error
    go s.readCommits(commitC, errorC)
    return s
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;readCommits&lt;/code&gt; 方法从 &lt;code&gt;commitC&lt;/code&gt; 中读取已经提交的请求进行处理：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (s *kvstore) readCommits(commitC &amp;lt;-chan *string, errorC &amp;lt;-chan error) {
    for data := range commitC {
        var dataKv kv
        dec := gob.NewDecoder(bytes.NewBufferString(*data))  // decode 
        s.mu.Lock()
        s.kvStore[dataKv.Key] = dataKv.Val  // 更新 kv
        s.mu.Unlock()
    }
    if err, ok := &amp;lt;-errorC; ok {
        log.Fatal(err)
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;再看看 &lt;code&gt;newRaftNode&lt;/code&gt; ，其会调用 &lt;code&gt;startRaft&lt;/code&gt; 启动底层 raft：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (rc *raftNode) startRaft() {
    oldwal := wal.Exist(rc.waldir)
    rc.wal = rc.replayWAL()

    rpeers := make([]raft.Peer, len(rc.peers))
    for i := range rpeers {
        rpeers[i] = raft.Peer{ID: uint64(i + 1)}
    }
    c := &amp;amp;raft.Config{
        ID:              uint64(rc.id),
        ElectionTick:    10,
        HeartbeatTick:   1,
        Storage:         rc.raftStorage,
        MaxSizePerMsg:   1024 * 1024,
        MaxInflightMsgs: 256,
    }

    if oldwal {
        rc.node = raft.RestartNode(c)
    } else {
        startPeers := rpeers
        if rc.join {
            startPeers = nil
        }
        rc.node = raft.StartNode(c, startPeers)
    }

    go rc.serveRaft()  // 监听 http 
    go rc.serveChannels()  // 监听 proposeC channel，读取应用层请求 进行处理
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;serveChannels&lt;/code&gt; 就做了两个事，1. 另起一个 goroutine，接收 proposeC 里发送自应用层的请求，通过 &lt;code&gt;Propose&lt;/code&gt; 方法交给底层 raft 处理；2. 调用 &lt;code&gt;Ready&lt;/code&gt; 方法，接收发送自 raft 的 ready 对象，调用 &lt;code&gt;publishEntries&lt;/code&gt; 将已经提交的 entries 发送到 &lt;code&gt;commitC&lt;/code&gt; channel，交由应用层处理，再调用 &lt;code&gt;Advance&lt;/code&gt; 方法通知底层 raft 准备好接收下一个 ready 对象了。&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;func (rc *raftNode) serveChannels() {
    defer rc.wal.Close()

    ticker := time.NewTicker(100 * time.Millisecond)
    defer ticker.Stop()

    // send proposals over raft
    go func() {
        var confChangeCount uint64 = 0

        for rc.proposeC != nil &amp;amp;&amp;amp; rc.confChangeC != nil {
            select {
            case prop, ok := &amp;lt;-rc.proposeC:
                if !ok {
                    rc.proposeC = nil
                } else {
                    // blocks until accepted by raft state machine
                    rc.node.Propose(context.TODO(), []byte(prop))  // 调用 Propose 发送给 raft 请求
                }
            }
        }
        // client closed channel; shutdown raft if not already
        close(rc.stopc)
    }()

    // event loop on raft state machine updates
    for {
        select {
        case &amp;lt;-ticker.C:
            rc.node.Tick()

        // store raft entries to wal, then publish over commit channel
        case rd := &amp;lt;-rc.node.Ready():  // 应用层调用 Ready() 获取 ready 对象
            if ok := rc.publishEntries(rc.entriesToApply(rd.CommittedEntries)); !ok {
                rc.stop()
                return
            }
            rc.node.Advance()  // 应用层调用 Advance() 通知 raft 已经处理完 ready 对象 

        case &amp;lt;-rc.stopc:
            rc.stop()
            return
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;&lt;code&gt;publishEntries&lt;/code&gt; 将 ready 对象里的 &lt;code&gt;CommittedEntries&lt;/code&gt; 发送到 &lt;code&gt;commitC&lt;/code&gt;，由应用层 kv 处理：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// publishEntries writes committed log entries to commit channel and returns
// whether all entries could be published.
func (rc *raftNode) publishEntries(ents []raftpb.Entry) bool {
    for i := range ents {
        switch ents[i].Type {
        case raftpb.EntryNormal:
            if len(ents[i].Data) == 0 {
                // ignore empty messages
                break
            }
            s := string(ents[i].Data)
            select {
            case rc.commitC &amp;lt;- &amp;amp;s:  // 发送到 commitC channel
            case &amp;lt;-rc.stopc:
                return false
            }
        }

        // after commit, update appliedIndex
        rc.appliedIndex = ents[i].Index

        // special nil commit to signal replay has finished
        if ents[i].Index == rc.lastIndex {
            select {
            case rc.commitC &amp;lt;- nil:
            case &amp;lt;-rc.stopc:
                return false
            }
        }
    }
    return true
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;整体架构如下，RaftNode 的角色为应用层和底层 raft 的桥梁：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/etcd-raft-node-1/illustration-1.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;p&gt;可以看出，应用层主要用到 raft.Node 的 &lt;code&gt;Propose&lt;/code&gt;、&lt;code&gt;Ready&lt;/code&gt;、&lt;code&gt;Advance&lt;/code&gt;三个接口：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-go&quot; data-lang=&quot;go&quot;&gt;// Node represents a node in a raft cluster.
type Node interface {
    // Propose proposes that data be appended to the log.
    Propose(ctx context.Context, data []byte) error

    // Ready returns a channel that returns the current point-in-time state.
    // Users of the Node must call Advance after retrieving the state returned by Ready.
    //
    // NOTE: No committed entries from the next Ready may be applied until all committed entries
    // and snapshots from the previous one have finished.
    Ready() &amp;lt;-chan Ready

    // Advance notifies the Node that the application has saved progress up to the last Ready.
    // It prepares the node to return the next available Ready.
    //
    // The application should generally call Advance after it applies the entries in last Ready.
    //
    // However, as an optimization, the application may call Advance while it is applying the
    // commands. For example. when the last Ready contains a snapshot, the application might take
    // a long time to apply the snapshot data. To continue receiving Ready without blocking raft
    // progress, it can call Advance before finishing applying the last ready.
    Advance()
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</description>
        <pubDate>Tue, 03 Jul 2018 13:21:23 +0800</pubDate>
        <link>http://masutangu.com/2018/07/etcd-raft-note-1/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/07/etcd-raft-note-1/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
      <item>
        <title>Libco 之 coctx_swap</title>
        <description>&lt;h1&gt;前言&lt;/h1&gt;

&lt;p&gt;在之前的文章&lt;a href=&quot;http://masutangu.com/2016/10/learn-libco/&quot;&gt;《浅读 Libco》&lt;/a&gt; 粗略的介绍了 libco，这篇文章则重点关注协程上下文切换的实现细节（coctx_swap.S）。&lt;/p&gt;

&lt;p&gt;首先回顾下函数调用的 stack frame layout：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/learn-libco-2/illustration-1.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;p&gt;调用子函数时，父函数从右到左将函数入栈，最后将返回地址入栈保存后，跳到子函数的地址执行。子函数压栈保存父函数的 %ebp，并将 %ebp 设置为当前 %esp。子函数通过 %ebp + 4 读取参数1，%ebp + 8 读取参数2，依次类推。&lt;/p&gt;

&lt;h1&gt;co_resume&lt;/h1&gt;

&lt;p&gt;在之前的文章提到协程的挂起和恢复通过 co_resume 来实现：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;static int CoRoutineFunc( stCoRoutine_t *co,void * )
{
    if( co-&amp;gt;pfn )
    {
        co-&amp;gt;pfn( co-&amp;gt;arg );
    }
    co-&amp;gt;cEnd = 1;

    stCoRoutineEnv_t *env = co-&amp;gt;env;

    co_yield_env( env );

    return 0;
}

void co_resume( stCoRoutine_t *co )   // 恢复 co 协程
{
    stCoRoutineEnv_t *env = co-&amp;gt;env;
    stCoRoutine_t *lpCurrRoutine = env-&amp;gt;pCallStack[ env-&amp;gt;iCallStackSize - 1 ];
    if( !co-&amp;gt;cStart )
    {
        coctx_make( &amp;amp;co-&amp;gt;ctx,(coctx_pfn_t)CoRoutineFunc,co,0 );
        co-&amp;gt;cStart = 1;
    }
    env-&amp;gt;pCallStack[ env-&amp;gt;iCallStackSize++ ] = co;  // 执行协程的时候压入 pCallStack 栈中
    coctx_swap( &amp;amp;(lpCurrRoutine-&amp;gt;ctx),&amp;amp;(co-&amp;gt;ctx) );  // 恢复 co 协程的上下文
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;这里 coctx_make 函数创建新协程的上下文：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;// 对应 CoRoutineFunc 的两个参数，s1 即 stCoRoutine_t *co，s2 即 void*
struct coctx_param_t
{
    const void *s1;
    const void *s2;
};
struct coctx_t
{
#if defined(__i386__)
    void *regs[ 8 ];
#else
    void *regs[ 14 ];
#endif
    size_t ss_size;
    char *ss_sp;
};

int coctx_make( coctx_t *ctx,coctx_pfn_t pfn,const void *s,const void *s1 )
{
    // make room for coctx_param
    char *sp = ctx-&amp;gt;ss_sp + ctx-&amp;gt;ss_size - sizeof(coctx_param_t);
    sp = (char*)((unsigned long)sp &amp;amp; -16L); // 16字节对齐

    coctx_param_t* param = (coctx_param_t*)sp ;
    param-&amp;gt;s1 = s;
    param-&amp;gt;s2 = s1;

    memset(ctx-&amp;gt;regs, 0, sizeof(ctx-&amp;gt;regs));

    ctx-&amp;gt;regs[ kESP ] = (char*)(sp) - sizeof(void*);  // 32位下 regs[ kESP ] 即 regs[7]，(char*)(sp) - sizeof(void*) 预留了返回地址的空间

    /*
     ss_sp 是在堆上分配的，地址从低到高增长，而栈是从高到低增长，这里要转下

     高地址  ------  &amp;lt;- ss_sp + ss_size 
           |pading| 
           |s2    |
           |s1    | 
            ------  &amp;lt;- sp
           |void* | 这个返回地址只是预留空间，不需要填。因为 CoRoutineFunc 函数执行完了表示该协程已经跑完，将其 end 标记位置1（co-&amp;gt;cEnd = 1）并调用 co_yield_env 切出。不需要再回到该协程来所以也不需要记录调用 CoRoutineFunc 后的返回地址了
            ------  &amp;lt;- ctx-&amp;gt;regs[ kESP ] 这里为返回地址预留空间的目的在于：参照前言中函数调用的 stack frame layout 图。函数调用压入参数后还需要压入返回地址，这样才能按照约定 ebp + 4 读取参数1，ebp + 8 读取参数2         
           |      |
     低地址  ------  &amp;lt;- ss_sp

                */

    ctx-&amp;gt;regs[ kEIP ] = (char*)pfn;  // 32位下 regs[ kEIP ] 即 regs[0] 保存 pfn 的地址 也就是 CoRoutineFunc 
    return 0;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;co_swap 调用 coctx_swap 来挂起和保存 curr 协程的上下文，恢复 pending 协程的上下文并切换执行流程至 pending 协程：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;void co_swap(stCoRoutine_t* curr, stCoRoutine_t* pending_co)
{
    //swap context
    coctx_swap(&amp;amp;(curr-&amp;gt;ctx),&amp;amp;(pending_co-&amp;gt;ctx) );

    //stack buffer may be overwrite, so get again;
    stCoRoutineEnv_t* curr_env = co_get_curr_thread_env();
    ...
}
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;进入 coctx_swap 前 stack frame layout 如下图：
&lt;img src=&quot;/assets/images/learn-libco-2/illustration-2.png&quot; width=&quot;800&quot;/&gt;&lt;/p&gt;

&lt;h1&gt;coctx_swap&lt;/h1&gt;

&lt;p&gt;下面是 coctx_swap 的汇编代码：&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c++&quot; data-lang=&quot;c++&quot;&gt;leal 4(%esp), %eax     // 由上图可以看出此时 esp 指向返回地址，esp + 4  即返回地址 + 4（也指向 curr-&amp;gt;ctx 的地址），保存在 %eax                                    
movl 4(%esp), %esp     // 将 esp 移到指向 curr-&amp;gt;ctx    

/*
此时stack layout如下：
对应的ESP地址,此时ESP已经指向了第一个参数 curr-&amp;gt;ctx，为 coctx_t 结构

| *ss_sp  |
| ss_size |
| regs[7] |
| regs[6] |
| regs[5] |
| regs[4] |
| regs[3] |
| regs[2] |
| regs[1] |
| regs[0] |
---------- &amp;lt;---ESP
*/   

leal 32(%esp), %esp    // 将esp上移 32 个字节

/*
| *ss_sp  |
| ss_size |
----------- &amp;lt;---ESP
| regs[7] |
| regs[6] |
| regs[5] |
| regs[4] |
| regs[3] |
| regs[2] |
| regs[1] |
| regs[0] |
*/     

pushl %eax         //  curr-&amp;gt;ctx-&amp;gt;regs[7] = %eax 保存返回地址 + 4
pushl %ebp         //  curr-&amp;gt;ctx-&amp;gt;regs[6] = %ebp
pushl %esi         //  curr-&amp;gt;ctx-&amp;gt;regs[5] = %esi
pushl %edi         //  curr-&amp;gt;ctx-&amp;gt;regs[4] = %edi
pushl %edx         //  curr-&amp;gt;ctx-&amp;gt;regs[3] = %edx
pushl %ecx         //  curr-&amp;gt;ctx-&amp;gt;regs[2] = %ecx
pushl %ebx         //  curr-&amp;gt;ctx-&amp;gt;regs[1] = %ebx
pushl -4(%eax)     //  curr-&amp;gt;ctx-&amp;gt;regs[0] = 返回地址 注：%eax - 4 = %old_esp 即返回地址

/*
保存寄存器后的 stack layout
| *ss_sp  |
| ss_size |
| regs[7] |  %eax
| regs[6] |  %ebp
| regs[5] |  %esi
| regs[4] |  %edi
| regs[3] |  %edx
| regs[2] |  %ecx
| regs[1] |  %ebx
| regs[0] |  返回地址
----------- &amp;lt;---ESP
*/     

movl 4(%eax), %esp // 将 esp 移到 curr-&amp;gt;ctx 向上偏移 4 个字节的地址，也即 pending_co-&amp;gt;ctx 的地址，

/*
此时的 stack layout（pending_co-&amp;gt;ctx）
| *ss_sp  |
| ss_size |
| regs[7] | 
| regs[6] | 
| regs[5] |
| regs[4] |
| regs[3] | 
| regs[2] |
| regs[1] |
| regs[0] |
----------- &amp;lt;---ESP  指向第二个参数 pending_co-&amp;gt;ctx-&amp;gt;regs[0]
*/     

// 依次恢复寄存器
popl %eax  // pop from regs[0] regs[0] 保存返回地址
popl %ebx  // pop from regs[1]
popl %ecx  // pop from regs[2]
popl %edx  // pop from regs[3]
popl %edi  // pop from regs[4]
popl %esi  // pop from regs[5]
popl %ebp  // pop from regs[6]
popl %esp  // pop from regs[7] 此时 esp指向 regs[7] 即返回地址 + 4 的位置


/*
此时的堆栈
|   s2    |
|   s1    |
|  void*  | 
---------- &amp;lt;- ESP
| 返回地址 |

*/

// 下面这行有点ticky, esp 此时指向的是返回地址 + 4的位置，所以这里 push %eax，入栈 %eax 中保存的返回地址，esp 刚好也指向存放该返回地址的位置
pushl %eax

/*
此时的堆栈
|   s2    |
|   s1    |
|  void*  | 
| 返回地址 |
---------- &amp;lt;- ESP
*/


xorl %eax, %eax

ret // ret 指令弹出返回地址，此时 %esp += 4 并跳转到该地址继续执行

/*
此时的堆栈
|   s2    |
|   s1    |
|  void*  | 
---------- &amp;lt;- ESP / EBP
| 返回地址 | 弹出返回地址

在 coctx_make 的情况下，将跳转到 pfn 执行，esp 执行预留的返回地址 void*，此时stack frame layout 和平台函数调用一样，同样通过 %ebp + 4 访问参数1，%ebp + 8 访问参数2
*/

&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;h1&gt;参考文献&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;http://kaiyuan.me/2017/07/10/libco/&quot;&gt;《libco 分析(上)：协程的实现》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27409164&quot;&gt;《libco协程库上下文切换原理详解》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://zhuanlan.zhihu.com/p/27339191&quot;&gt;《x86-64 下函数调用及栈帧原理》&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://rangechow.com/2016/09/01/%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E5%8E%9F%E7%90%86.html&quot;&gt;《函数调用原理》&lt;/a&gt;&lt;/p&gt;
</description>
        <pubDate>Fri, 27 Apr 2018 20:57:21 +0800</pubDate>
        <link>http://masutangu.com/2018/04/learn-libco-2/</link>
        <guid isPermaLink="true">http://masutangu.com/2018/04/learn-libco-2/</guid>
        
        
        <category>源码阅读</category>
        
      </item>
    
  </channel>
</rss>
